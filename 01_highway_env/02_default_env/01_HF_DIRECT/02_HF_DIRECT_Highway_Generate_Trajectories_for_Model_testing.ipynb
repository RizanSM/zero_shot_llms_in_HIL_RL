{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/RizanSM/zero_shot_llms_in_HIL_RL/blob/main/01_highway_env/02_default_env/01_HF_DIRECT/02_HF_DIRECT_Highway_Generate_Trajectories_for_Model_testing.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OuwmGGRJrPVF"
      },
      "outputs": [],
      "source": [
        "# Install the required libraries in your Google Colab environment\n",
        "!pip install gymnasium stable-baselines3 highway-env -q"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VZhaXFBUrfBS"
      },
      "outputs": [],
      "source": [
        "# Import the necessary libraries\n",
        "import gymnasium as gym\n",
        "import highway_env\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import pickle\n",
        "import os\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BP5KACM8rlKX"
      },
      "outputs": [],
      "source": [
        "# THE ENVIRONMENT\n",
        "# Step 1.1: Choose the Environment\n",
        "# Initialize the environment.\n",
        "env = gym.make('highway-v0',config={\"vehicles_count\":50})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oilpd3dOz8r_"
      },
      "outputs": [],
      "source": [
        "from stable_baselines3 import PPO\n",
        "from google.colab import drive\n",
        "from google.colab import data_table\n",
        "\n",
        "# Mount Google Drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fnHpE3hDaNom"
      },
      "outputs": [],
      "source": [
        "# Load the all the saved PPO model\n",
        "model = PPO.load('/content/drive/MyDrive/data_rp1/1_trained_models/1_ppo_highway_hf_direct_ideal')                # Update directory location 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8eJ7IUv5j7iS"
      },
      "source": [
        "Trajectory Collection with Additional information (Collision Flag and Lane Index)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# TRAJECTORY COLLECTION WITH ADDTIONNAL INFORMATION\n",
        "# Initialize a list to store trajectory data\n",
        "trajectories = []\n",
        "\n",
        "# FUNCTION TO COLLECT TRAJECTORY DATA (state-action-reward transitions).\n",
        "\n",
        "def collect_trajectory_data(env, model, num_episodes,seed):\n",
        "    \"\"\"\n",
        "    Collect trajectory data for a number of episodes.\n",
        "    Each trajectory contains state-action-reward sequences.\n",
        "    \"\"\"\n",
        "    trajectory_data = []\n",
        "\n",
        "    for episode in range(num_episodes):\n",
        "        state, _ = env.reset(seed=seed)  # Reset the environment at the start of each episode              #  change environment name here\n",
        "        done = False\n",
        "        episode_data = []\n",
        "\n",
        "        while not done:\n",
        "            # Get action from the trained PPO model\n",
        "            action, _states = model.predict(state, deterministic = True)                                       # change model name here\n",
        "\n",
        "            # Take the action and get next state and reward\n",
        "            next_state, reward, terminated, truncated, info = env.step(action)                    #  change environment name here\n",
        "            done = terminated or truncated\n",
        "            # Extract lane index and collision flag\n",
        "            lane_index = int(env.unwrapped.vehicle.lane_index[2])\n",
        "            collision_flag = int(info.get('crashed', 0))\n",
        "\n",
        "            # Store the trajectory: (state, action, reward, next_state)\n",
        "            episode_data.append({\n",
        "                \"state\": state,\n",
        "                \"action\": action,\n",
        "                \"reward\": reward,\n",
        "                \"next_state\": next_state,\n",
        "                \"lane_indices\": lane_index,\n",
        "                \"collision_flags\": collision_flag\n",
        "            })\n",
        "\n",
        "            # Update the state for the next iteration\n",
        "            state = next_state\n",
        "\n",
        "        # Add the episode data to the overall trajectory list\n",
        "        trajectory_data.append(episode_data)\n",
        "\n",
        "    return trajectory_data"
      ],
      "metadata": {
        "id": "WCoPWduUICcu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SsiZnt73xMQd"
      },
      "outputs": [],
      "source": [
        "# FUNCTION TO PREPROCESS TRAJECTORY DATA\n",
        "def preprocess_trajectory_data(trajectory_data):\n",
        "    \"\"\"\n",
        "    Preprocesses the trajectory data into a structured format for further analysis.\n",
        "    Returns a DataFrame with columns: episode, time_step, state, action, reward, next_state, speed, and reward_details.\n",
        "    \"\"\"\n",
        "    processed_data = []\n",
        "\n",
        "    for episode_num, episode_data in enumerate(trajectory_data):\n",
        "        for time_step, step in enumerate(episode_data):\n",
        "            # Flatten the state and next_state for easy interpretation (if they are multi-dimensional)\n",
        "            state = np.array(step['state']).flatten()  # Flatten the state vector (if multi-dimensional)\n",
        "            next_state = np.array(step['next_state']).flatten()  # Flatten the next_state vector\n",
        "\n",
        "            collision_flag = step['collision_flags']\n",
        "            lane_index = step['lane_indices']\n",
        "\n",
        "            # Append the processed data for this step\n",
        "            processed_data.append({\n",
        "                \"episode\": episode_num,\n",
        "                \"time_step\": time_step,\n",
        "                \"state\": state,\n",
        "                \"action\": step['action'],\n",
        "                \"reward\": step['reward'],\n",
        "                \"next_state\": next_state,\n",
        "                \"collision_flag\": collision_flag,\n",
        "                \"lane_index\": lane_index\n",
        "            })\n",
        "\n",
        "    # Convert the list of processed data into a DataFrame\n",
        "    df = pd.DataFrame(processed_data)\n",
        "    return df"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "0. GENERATING TRAJECTORIES FOR TESTING (HUMAN FEEDBACK DIRECT)"
      ],
      "metadata": {
        "id": "qLgAKXgUWiEj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "First Human feedback direct data frame"
      ],
      "metadata": {
        "id": "-n-_2c_tXDTG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Collect data for 100 episodes\n",
        "trajectory_data_1 = collect_trajectory_data(env, model, num_episodes=100,seed=2)"
      ],
      "metadata": {
        "id": "NtUE_W7-WhQj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Preprocess the trajectory data\n",
        "trajectory_df_seed_1 = preprocess_trajectory_data(trajectory_data_1)"
      ],
      "metadata": {
        "id": "YPBCBmGJWvt7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_table.enable_dataframe_formatter()\n",
        "data_table.DataTable(trajectory_df_seed_1)"
      ],
      "metadata": {
        "id": "uVd9HKPZWvnP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the dataframe as a pickle file\n",
        "trajectory_df_seed_1.to_pickle('/content/drive/MyDrive/data_rp1/3_test_trajectories/1_hf_d_ideal/1_hf_d_ideal_df.pkl')           # Update directory location 2\n"
      ],
      "metadata": {
        "id": "KlTviQ7LWvUr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Second Human feedback direct data frame\n"
      ],
      "metadata": {
        "id": "E6yiiseHg8Bh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Collect data for 100 episodes\n",
        "trajectory_data_2 = collect_trajectory_data(env, model, num_episodes=100,seed=10)"
      ],
      "metadata": {
        "id": "N6pxD621hOql"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Preprocess the trajectory data\n",
        "trajectory_df_seed_2 = preprocess_trajectory_data(trajectory_data_2)"
      ],
      "metadata": {
        "id": "tqlWzOemhOcZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_table.enable_dataframe_formatter()\n",
        "data_table.DataTable(trajectory_df_seed_2)"
      ],
      "metadata": {
        "id": "ga44R6BVhORd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the dataframe as a pickle file\n",
        "trajectory_df_seed_2.to_pickle('/content/drive/MyDrive/data_rp1/3_test_trajectories/1_hf_d_ideal/2_hf_d_ideal_df.pkl')          # Update directory location 3"
      ],
      "metadata": {
        "id": "-0ouJiqohOHO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Third Human feedback direct data frame"
      ],
      "metadata": {
        "id": "LNI1Q2aIhAXP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Collect data for 100 episodes\n",
        "trajectory_data_3 = collect_trajectory_data(env, model, num_episodes=100,seed=6)"
      ],
      "metadata": {
        "id": "eJe17vLxhP37"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Preprocess the trajectory data\n",
        "trajectory_df_seed_3 = preprocess_trajectory_data(trajectory_data_3)"
      ],
      "metadata": {
        "id": "L-1wNg9BhPmZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_table.enable_dataframe_formatter()\n",
        "data_table.DataTable(trajectory_df_seed_3)"
      ],
      "metadata": {
        "id": "QvcIR1LAhPgi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the dataframe as a pickle file\n",
        "trajectory_df_seed_3.to_pickle('/content/drive/MyDrive/data_rp1/3_test_trajectories/1_hf_d_ideal/3_hf_d_ideal_df.pkl')             # Update directory location 4"
      ],
      "metadata": {
        "id": "3hYXf2kchPba"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Fourth Human feedback direct data frame"
      ],
      "metadata": {
        "id": "O8UPT7E2hEw4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Collect data for 100 episodes\n",
        "trajectory_data_4 = collect_trajectory_data(env, model, num_episodes=100,seed=20)"
      ],
      "metadata": {
        "id": "XM_zO3mehROZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Preprocess the trajectory data\n",
        "trajectory_df_seed_4 = preprocess_trajectory_data(trajectory_data_4)"
      ],
      "metadata": {
        "id": "pTUEoqhahQ9-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_table.enable_dataframe_formatter()\n",
        "data_table.DataTable(trajectory_df_seed_4)"
      ],
      "metadata": {
        "id": "sE0nYkpChQ6p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the dataframe as a pickle file\n",
        "trajectory_df_seed_4.to_pickle('/content/drive/MyDrive/data_rp1/3_test_trajectories/1_hf_d_ideal/4_hf_d_ideal_df.pkl')             # Update directory location 5"
      ],
      "metadata": {
        "id": "1qCe_JCNhQ22"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Fifth Human feedback direct data frame"
      ],
      "metadata": {
        "id": "GK2JR89NhIeJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Collect data for 100 episodes\n",
        "trajectory_data_5 = collect_trajectory_data(env, model, num_episodes=100,seed=34)"
      ],
      "metadata": {
        "id": "GeZXIUCDg7fA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Preprocess the trajectory data\n",
        "trajectory_df_seed_5 = preprocess_trajectory_data(trajectory_data_5)"
      ],
      "metadata": {
        "id": "RRVMOCvDhSWQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_table.enable_dataframe_formatter()\n",
        "data_table.DataTable(trajectory_df_seed_5)"
      ],
      "metadata": {
        "id": "A4dorT-ahSJ5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the dataframe as a pickle file\n",
        "trajectory_df_seed_5.to_pickle('/content/drive/MyDrive/data_rp1/3_test_trajectories/1_hf_d_ideal/5_hf_d_ideal_df.pkl')           # Update directory location 6"
      ],
      "metadata": {
        "id": "zXgtf5LXhSCc"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMUziZVIXaGSyZbU44IlK7+",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}