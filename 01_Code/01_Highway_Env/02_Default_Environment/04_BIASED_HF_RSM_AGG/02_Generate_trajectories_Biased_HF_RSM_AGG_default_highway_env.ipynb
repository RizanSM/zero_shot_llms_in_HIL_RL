{"cells":[{"cell_type":"markdown","source":["[![Open in Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/RizanSM/zero_shot_llms_in_HIL_RL/blob/main/01_Code/01_Highway_Env/02_Default_Environment/04_BIASED_HF_RSM_AGG/02_Generate_trajectories_Biased_HF_RSM_AGG_default_highway_env.ipynb)"],"metadata":{"id":"u52LXHEp7pJQ"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"OuwmGGRJrPVF","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1750866105568,"user_tz":-330,"elapsed":119072,"user":{"displayName":"Saif Nazir","userId":"15029834638479146606"}},"outputId":"1f4e9908-bae5-4d8c-cdbf-1b3cd2243119"},"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/184.5 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m184.3/184.5 kB\u001b[0m \u001b[31m11.3 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m184.5/184.5 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m105.0/105.0 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m58.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m54.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m43.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m10.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m58.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h"]}],"source":["# Install the required libraries in your Google Colab environment\n","!pip install gymnasium stable-baselines3 highway-env -q"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"VZhaXFBUrfBS"},"outputs":[],"source":["# Import the necessary libraries\n","import gymnasium as gym\n","import highway_env\n","import numpy as np\n","import pandas as pd\n","import pickle\n","import os\n","import matplotlib.pyplot as plt"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"BP5KACM8rlKX"},"outputs":[],"source":["# THE ENVIRONMENT\n","# Step 1.1: Choose the Environment\n","# Initialize the environment.\n","env = gym.make('highway-v0',config={\"vehicles_count\":50})"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"oilpd3dOz8r_","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1750866179771,"user_tz":-330,"elapsed":72599,"user":{"displayName":"Saif Nazir","userId":"15029834638479146606"}},"outputId":"0fa03d20-15e4-44ee-f3a1-0e07e597ec3d"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from stable_baselines3 import PPO\n","from google.colab import drive\n","from google.colab import data_table\n","\n","# Mount Google Drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"fnHpE3hDaNom"},"outputs":[],"source":["# Step A.6.2: Load the all the saved PPO model\n","model = PPO.load('/content/drive/MyDrive/05_zero_shot_llm_3/02_data/01_trained_models/4_ppo_highway_biased_hf_lrs_aggressive')                # Update directory location 1"]},{"cell_type":"markdown","metadata":{"id":"8eJ7IUv5j7iS"},"source":["Trajectory Collection with Additional information (Collision Flag and Lane Index)"]},{"cell_type":"code","source":["# TRAJECTORY COLLECTION WITH ADDTIONNAL INFORMATION\n","# Initialize a list to store trajectory data\n","trajectories = []\n","\n","# FUNCTION TO COLLECT TRAJECTORY DATA (state-action-reward transitions).\n","\n","def collect_trajectory_data(env, model, num_episodes,seed):\n","    \"\"\"\n","    Collect trajectory data for a number of episodes.\n","    Each trajectory contains state-action-reward sequences.\n","    \"\"\"\n","    trajectory_data = []\n","\n","    for episode in range(num_episodes):\n","        state, _ = env.reset(seed=seed)  # Reset the environment at the start of each episode              #  change environment name here\n","        done = False\n","        episode_data = []\n","\n","        while not done:\n","            # Get action from the trained PPO model\n","            action, _states = model.predict(state, deterministic = True)                                       # change model name here\n","\n","            # Take the action and get next state and reward\n","            next_state, reward, terminated, truncated, info = env.step(action)                    #  change environment name here\n","            done = terminated or truncated\n","            # Extract lane index and collision flag\n","            lane_index = int(env.unwrapped.vehicle.lane_index[2])\n","            collision_flag = int(info.get('crashed', 0))\n","\n","            # Store the trajectory: (state, action, reward, next_state)\n","            episode_data.append({\n","                \"state\": state,\n","                \"action\": action,\n","                \"reward\": reward,\n","                \"next_state\": next_state,\n","                \"lane_indices\": lane_index,\n","                \"collision_flags\": collision_flag\n","            })\n","\n","            # Update the state for the next iteration\n","            state = next_state\n","\n","        # Add the episode data to the overall trajectory list\n","        trajectory_data.append(episode_data)\n","\n","    return trajectory_data"],"metadata":{"id":"WCoPWduUICcu"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"SsiZnt73xMQd"},"outputs":[],"source":["# FUNCTION TO PREPROCESS TRAJECTORY DATA\n","def preprocess_trajectory_data(trajectory_data):\n","    \"\"\"\n","    Preprocesses the trajectory data into a structured format for further analysis.\n","    Returns a DataFrame with columns: episode, time_step, state, action, reward, next_state, speed, and reward_details.\n","    \"\"\"\n","    processed_data = []\n","\n","    for episode_num, episode_data in enumerate(trajectory_data):\n","        for time_step, step in enumerate(episode_data):\n","            # Flatten the state and next_state for easy interpretation (if they are multi-dimensional)\n","            state = np.array(step['state']).flatten()  # Flatten the state vector (if multi-dimensional)\n","            next_state = np.array(step['next_state']).flatten()  # Flatten the next_state vector\n","\n","            collision_flag = step['collision_flags']\n","            lane_index = step['lane_indices']\n","\n","            # Append the processed data for this step\n","            processed_data.append({\n","                \"episode\": episode_num,\n","                \"time_step\": time_step,\n","                \"state\": state,\n","                \"action\": step['action'],\n","                \"reward\": step['reward'],\n","                \"next_state\": next_state,\n","                \"collision_flag\": collision_flag,\n","                \"lane_index\": lane_index\n","            })\n","\n","    # Convert the list of processed data into a DataFrame\n","    df = pd.DataFrame(processed_data)\n","    return df"]},{"cell_type":"markdown","source":["0. GENERATING TRAJECTORIES FOR TESTING (BIASED HUMAN FEEDBACK LRS AGGRESSIVE)"],"metadata":{"id":"qLgAKXgUWiEj"}},{"cell_type":"markdown","source":["First BIASED HUMAN FEEDBACK LRS AGGRESSIVE data frame"],"metadata":{"id":"-n-_2c_tXDTG"}},{"cell_type":"code","source":["# Collect data for 100 episodes\n","trajectory_data_1 = collect_trajectory_data(env, model, num_episodes=100,seed=2)"],"metadata":{"id":"NtUE_W7-WhQj"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Preprocess the trajectory data\n","trajectory_df_seed_1 = preprocess_trajectory_data(trajectory_data_1)"],"metadata":{"id":"YPBCBmGJWvt7"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["data_table.enable_dataframe_formatter()\n","data_table.DataTable(trajectory_df_seed_1)"],"metadata":{"id":"uVd9HKPZWvnP","colab":{"base_uri":"https://localhost:8080/","height":2020,"output_embedded_package_id":"1wkCqPvOCrIUznyWMm4ENMiVUfPUaKNan"},"executionInfo":{"status":"ok","timestamp":1750868073849,"user_tz":-330,"elapsed":4998,"user":{"displayName":"Saif Nazir","userId":"15029834638479146606"}},"outputId":"7a8f42b5-48b0-473c-bbe5-a226c703afc9"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}]},{"cell_type":"code","source":["# Save the dataframe as a pickle file\n","trajectory_df_seed_1.to_pickle('/content/drive/MyDrive/05_zero_shot_llm_3/02_data/03_test_trajectories/4_biased_hf_lrs_aggressive/1_biased_hf_lrs_aggressive_df.pkl')      # Update directory location 2\n"],"metadata":{"id":"KlTviQ7LWvUr"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Second BIASED HUMAN FEEDBACK LRS AGGRESSIVE data frame\n"],"metadata":{"id":"E6yiiseHg8Bh"}},{"cell_type":"code","source":["# Collect data for 100 episodes\n","trajectory_data_2 = collect_trajectory_data(env, model, num_episodes=100,seed=10)"],"metadata":{"id":"N6pxD621hOql"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Preprocess the trajectory data\n","trajectory_df_seed_2 = preprocess_trajectory_data(trajectory_data_2)"],"metadata":{"id":"tqlWzOemhOcZ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["data_table.enable_dataframe_formatter()\n","data_table.DataTable(trajectory_df_seed_2)"],"metadata":{"id":"ga44R6BVhORd","colab":{"base_uri":"https://localhost:8080/","height":3029,"output_embedded_package_id":"1n6nWb-efrq5PtuK4VW-xUVBa8JUeTzUa"},"executionInfo":{"status":"ok","timestamp":1750869979566,"user_tz":-330,"elapsed":3325,"user":{"displayName":"Saif Nazir","userId":"15029834638479146606"}},"outputId":"89560766-29a2-4cff-e24b-fa0d5b85dd6d"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}]},{"cell_type":"code","source":["# Save the dataframe as a pickle file\n","trajectory_df_seed_2.to_pickle('/content/drive/MyDrive/05_zero_shot_llm_3/02_data/03_test_trajectories/4_biased_hf_lrs_aggressive/2_biased_hf_lrs_aggressive_df.pkl')     # Update directory location 3"],"metadata":{"id":"-0ouJiqohOHO"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Third BIASED HUMAN FEEDBACK LRS AGGRESSIVE data frame"],"metadata":{"id":"LNI1Q2aIhAXP"}},{"cell_type":"code","source":["# Collect data for 100 episodes\n","trajectory_data_3 = collect_trajectory_data(env, model, num_episodes=100,seed=6)"],"metadata":{"id":"eJe17vLxhP37"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Preprocess the trajectory data\n","trajectory_df_seed_3 = preprocess_trajectory_data(trajectory_data_3)"],"metadata":{"id":"L-1wNg9BhPmZ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["data_table.enable_dataframe_formatter()\n","data_table.DataTable(trajectory_df_seed_3)"],"metadata":{"id":"QvcIR1LAhPgi","colab":{"base_uri":"https://localhost:8080/","height":3046,"output_embedded_package_id":"1KdsifwPKhv3p8MK3DUPMgrdLFGBH-j77"},"executionInfo":{"status":"ok","timestamp":1750871859686,"user_tz":-330,"elapsed":3641,"user":{"displayName":"Saif Nazir","userId":"15029834638479146606"}},"outputId":"d9b8ce3e-fa01-4365-a51a-9657ca65f145"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}]},{"cell_type":"code","source":["# Save the dataframe as a pickle file\n","trajectory_df_seed_3.to_pickle('/content/drive/MyDrive/05_zero_shot_llm_3/02_data/03_test_trajectories/4_biased_hf_lrs_aggressive/3_biased_hf_lrs_aggressive_df.pkl')     # Update directory location 4"],"metadata":{"id":"3hYXf2kchPba"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Fourth BIASED HUMAN FEEDBACK LRS AGGRESSIVE data frame"],"metadata":{"id":"O8UPT7E2hEw4"}},{"cell_type":"code","source":["# Collect data for 100 episodes\n","trajectory_data_4 = collect_trajectory_data(env, model, num_episodes=100,seed=20)"],"metadata":{"id":"XM_zO3mehROZ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Preprocess the trajectory data\n","trajectory_df_seed_4 = preprocess_trajectory_data(trajectory_data_4)"],"metadata":{"id":"pTUEoqhahQ9-"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["data_table.enable_dataframe_formatter()\n","data_table.DataTable(trajectory_df_seed_4)"],"metadata":{"id":"sE0nYkpChQ6p","colab":{"base_uri":"https://localhost:8080/","height":2947,"output_embedded_package_id":"1nbvvn6P-1yy4wQ-RqiB03zwjxvdforW-"},"executionInfo":{"status":"ok","timestamp":1750873754190,"user_tz":-330,"elapsed":3907,"user":{"displayName":"Saif Nazir","userId":"15029834638479146606"}},"outputId":"513552f1-c73f-4001-c8e4-4803cc0f64ef"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}]},{"cell_type":"code","source":["# Save the dataframe as a pickle file\n","trajectory_df_seed_4.to_pickle('/content/drive/MyDrive/05_zero_shot_llm_3/02_data/03_test_trajectories/4_biased_hf_lrs_aggressive/4_biased_hf_lrs_aggressive_df.pkl')      # Update directory location 5"],"metadata":{"id":"1qCe_JCNhQ22"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Fifth BIASED HUMAN FEEDBACK LRS AGGRESSIVE data frame"],"metadata":{"id":"GK2JR89NhIeJ"}},{"cell_type":"code","source":["# Collect data for 100 episodes\n","trajectory_data_5 = collect_trajectory_data(env, model, num_episodes=100,seed=34)"],"metadata":{"id":"GeZXIUCDg7fA"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Preprocess the trajectory data\n","trajectory_df_seed_5 = preprocess_trajectory_data(trajectory_data_5)"],"metadata":{"id":"RRVMOCvDhSWQ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["data_table.enable_dataframe_formatter()\n","data_table.DataTable(trajectory_df_seed_5)"],"metadata":{"id":"A4dorT-ahSJ5","colab":{"base_uri":"https://localhost:8080/","height":3046,"output_embedded_package_id":"1cYHpxoCGTx6j3YQm8AWSpkaQpVuwT64X"},"executionInfo":{"status":"ok","timestamp":1750875636200,"user_tz":-330,"elapsed":3583,"user":{"displayName":"Saif Nazir","userId":"15029834638479146606"}},"outputId":"3e645c88-687f-4047-9ff8-aef328981e3e"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}]},{"cell_type":"code","source":["# Save the dataframe as a pickle file\n","trajectory_df_seed_5.to_pickle('/content/drive/MyDrive/05_zero_shot_llm_3/02_data/03_test_trajectories/4_biased_hf_lrs_aggressive/5_biased_hf_lrs_aggressive_df.pkl')      # Update directory location 6"],"metadata":{"id":"zXgtf5LXhSCc"},"execution_count":null,"outputs":[]}],"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyNdLVvp0HZV2kHZCmMR4hKY"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}