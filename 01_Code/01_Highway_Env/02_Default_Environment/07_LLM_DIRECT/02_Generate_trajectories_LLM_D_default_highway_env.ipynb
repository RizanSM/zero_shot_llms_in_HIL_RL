{"cells":[{"cell_type":"markdown","source":["[![Open in Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/RizanSM/zero_shot_llms_in_HIL_RL/blob/main/01_Code/01_Highway_Env/02_Default_Environment/07_LLM_DIRECT/02_Generate_trajectories_LLM_D_default_highway_env.ipynb)"],"metadata":{"id":"tsuTcp1qHljO"}},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":96807,"status":"ok","timestamp":1750211794173,"user":{"displayName":"Saif Nazir","userId":"15029834638479146606"},"user_tz":-330},"id":"OuwmGGRJrPVF","outputId":"3e44d182-d576-4efe-9a28-07776c9dd7c6"},"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/184.5 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m184.5/184.5 kB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m105.0/105.0 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m84.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m69.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m42.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m14.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m106.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h"]}],"source":["# Install the required libraries in your Google Colab environment\n","!pip install gymnasium stable-baselines3 highway-env -q"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"VZhaXFBUrfBS"},"outputs":[],"source":["# Import the necessary libraries\n","import gymnasium as gym\n","import highway_env\n","import numpy as np\n","import pandas as pd\n","import pickle\n","import os\n","import matplotlib.pyplot as plt"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"BP5KACM8rlKX"},"outputs":[],"source":["# THE ENVIRONMENT\n","# Step 1.1: Choose the Environment\n","# Initialize the environment.\n","env = gym.make('highway-v0',config={\"vehicles_count\":50})"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":52524,"status":"ok","timestamp":1750211847920,"user":{"displayName":"Saif Nazir","userId":"15029834638479146606"},"user_tz":-330},"id":"oilpd3dOz8r_","outputId":"ecb9bac9-cdb5-41be-c460-a6bb4aea8608"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from stable_baselines3 import PPO\n","from google.colab import drive\n","from google.colab import data_table\n","\n","# Mount Google Drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"fnHpE3hDaNom"},"outputs":[],"source":["# Step A.6.2: Load the all the saved PPO model\n","model = PPO.load('/content/drive/MyDrive/05_zero_shot_llm_3/02_data/01_trained_models/7_ppo_highway_llmf_direct_ideal_1')          # Update directory location 1"]},{"cell_type":"markdown","metadata":{"id":"8eJ7IUv5j7iS"},"source":["Trajectory Collection with Additional information (Collision Flag and Lane Index)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"WCoPWduUICcu"},"outputs":[],"source":["# TRAJECTORY COLLECTION WITH ADDTIONNAL INFORMATION\n","# Initialize a list to store trajectory data\n","trajectories = []\n","\n","# FUNCTION TO COLLECT TRAJECTORY DATA (state-action-reward transitions).\n","\n","def collect_trajectory_data(env, model, num_episodes,seed):\n","    \"\"\"\n","    Collect trajectory data for a number of episodes.\n","    Each trajectory contains state-action-reward sequences.\n","    \"\"\"\n","    trajectory_data = []\n","\n","    for episode in range(num_episodes):\n","        state, _ = env.reset(seed=seed)  # Reset the environment at the start of each episode              #  change environment name here\n","        done = False\n","        episode_data = []\n","\n","        while not done:\n","            # Get action from the trained PPO model\n","            action, _states = model.predict(state, deterministic = True)                                       # change model name here\n","\n","            # Take the action and get next state and reward\n","            next_state, reward, terminated, truncated, info = env.step(action)                    #  change environment name here\n","            done = terminated or truncated\n","            # Extract lane index and collision flag\n","            lane_index = int(env.unwrapped.vehicle.lane_index[2])\n","            collision_flag = int(info.get('crashed', 0))\n","\n","            # Store the trajectory: (state, action, reward, next_state)\n","            episode_data.append({\n","                \"state\": state,\n","                \"action\": action,\n","                \"reward\": reward,\n","                \"next_state\": next_state,\n","                \"lane_indices\": lane_index,\n","                \"collision_flags\": collision_flag\n","            })\n","\n","            # Update the state for the next iteration\n","            state = next_state\n","\n","        # Add the episode data to the overall trajectory list\n","        trajectory_data.append(episode_data)\n","\n","    return trajectory_data"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"SsiZnt73xMQd"},"outputs":[],"source":["# FUNCTION TO PREPROCESS TRAJECTORY DATA\n","def preprocess_trajectory_data(trajectory_data):\n","    \"\"\"\n","    Preprocesses the trajectory data into a structured format for further analysis.\n","    Returns a DataFrame with columns: episode, time_step, state, action, reward, next_state, speed, and reward_details.\n","    \"\"\"\n","    processed_data = []\n","\n","    for episode_num, episode_data in enumerate(trajectory_data):\n","        for time_step, step in enumerate(episode_data):\n","            # Flatten the state and next_state for easy interpretation (if they are multi-dimensional)\n","            state = np.array(step['state']).flatten()  # Flatten the state vector (if multi-dimensional)\n","            next_state = np.array(step['next_state']).flatten()  # Flatten the next_state vector\n","\n","            collision_flag = step['collision_flags']\n","            lane_index = step['lane_indices']\n","\n","            # Append the processed data for this step\n","            processed_data.append({\n","                \"episode\": episode_num,\n","                \"time_step\": time_step,\n","                \"state\": state,\n","                \"action\": step['action'],\n","                \"reward\": step['reward'],\n","                \"next_state\": next_state,\n","                \"collision_flag\": collision_flag,\n","                \"lane_index\": lane_index\n","            })\n","\n","    # Convert the list of processed data into a DataFrame\n","    df = pd.DataFrame(processed_data)\n","    return df"]},{"cell_type":"markdown","metadata":{"id":"qLgAKXgUWiEj"},"source":["0. GENERATING TRAJECTORIES FOR TESTING (LLM DIRECT)"]},{"cell_type":"markdown","metadata":{"id":"-n-_2c_tXDTG"},"source":["First LLM feedback direct data frame"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"NtUE_W7-WhQj"},"outputs":[],"source":["# Collect data for 100 episodes\n","trajectory_data_1 = collect_trajectory_data(env, model, num_episodes=100,seed=2)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"YPBCBmGJWvt7"},"outputs":[],"source":["# Preprocess the trajectory data\n","trajectory_df_seed_1 = preprocess_trajectory_data(trajectory_data_1)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":2020,"output_embedded_package_id":"1Y4TYvu3Js3HD_rzP5RjX7SlqfYz5cTrj"},"executionInfo":{"elapsed":5131,"status":"ok","timestamp":1750205302173,"user":{"displayName":"Saif Nazir","userId":"15029834638479146606"},"user_tz":-330},"id":"uVd9HKPZWvnP","outputId":"59be5de9-bc7f-46b2-9fa7-66d6c3ab9156"},"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}],"source":["data_table.enable_dataframe_formatter()\n","data_table.DataTable(trajectory_df_seed_1)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"KlTviQ7LWvUr"},"outputs":[],"source":["# Save the dataframe as a pickle file\n","trajectory_df_seed_1.to_pickle('/content/drive/MyDrive/05_zero_shot_llm_3/02_data/03_test_trajectories/7_llm_d_ideal/1_llmf_d_ideal_df_1.pkl')         # Update directory location 2\n"]},{"cell_type":"markdown","metadata":{"id":"E6yiiseHg8Bh"},"source":["Second LLM feedback direct  data frame\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"N6pxD621hOql"},"outputs":[],"source":["# Collect data for 100 episodes\n","trajectory_data_2 = collect_trajectory_data(env, model, num_episodes=100,seed=10)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"tqlWzOemhOcZ"},"outputs":[],"source":["# Preprocess the trajectory data\n","trajectory_df_seed_2 = preprocess_trajectory_data(trajectory_data_2)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":3029,"output_embedded_package_id":"1Bd-MCaFpbC629LTvF5J7QgxxNC7ZNGng"},"executionInfo":{"elapsed":3421,"status":"ok","timestamp":1750207273338,"user":{"displayName":"Saif Nazir","userId":"15029834638479146606"},"user_tz":-330},"id":"ga44R6BVhORd","outputId":"c8a12156-9871-42ae-f1c8-244ffa7826b9"},"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}],"source":["data_table.enable_dataframe_formatter()\n","data_table.DataTable(trajectory_df_seed_2)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-0ouJiqohOHO"},"outputs":[],"source":["# Save the dataframe as a pickle file\n","trajectory_df_seed_2.to_pickle('/content/drive/MyDrive/05_zero_shot_llm_3/02_data/03_test_trajectories/7_llm_d_ideal/2_llmf_d_ideal_df_1.pkl')         # Update directory location 3"]},{"cell_type":"markdown","metadata":{"id":"LNI1Q2aIhAXP"},"source":["Third LLM feedback direct  data frame"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"eJe17vLxhP37"},"outputs":[],"source":["# Collect data for 100 episodes\n","trajectory_data_3 = collect_trajectory_data(env, model, num_episodes=100,seed=6)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"L-1wNg9BhPmZ"},"outputs":[],"source":["# Preprocess the trajectory data\n","trajectory_df_seed_3 = preprocess_trajectory_data(trajectory_data_3)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"output_embedded_package_id":"1Syil4msgcIHhrsSUYmhF3DRICnpZRU3g"},"id":"QvcIR1LAhPgi","outputId":"7c173554-43a8-4aa6-8f33-08f62ef360a3"},"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}],"source":["data_table.enable_dataframe_formatter()\n","data_table.DataTable(trajectory_df_seed_3)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"3hYXf2kchPba"},"outputs":[],"source":["# Save the dataframe as a pickle file\n","trajectory_df_seed_3.to_pickle('/content/drive/MyDrive/05_zero_shot_llm_3/02_data/03_test_trajectories/7_llm_d_ideal/3_llmf_d_ideal_df_1.pkl')        # Update directory location 4"]},{"cell_type":"markdown","metadata":{"id":"O8UPT7E2hEw4"},"source":["Fourth LLM feedback direct data frame"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"XM_zO3mehROZ"},"outputs":[],"source":["# Collect data for 100 episodes\n","trajectory_data_4 = collect_trajectory_data(env, model, num_episodes=100,seed=20)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"pTUEoqhahQ9-"},"outputs":[],"source":["# Preprocess the trajectory data\n","trajectory_df_seed_4 = preprocess_trajectory_data(trajectory_data_4)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"sE0nYkpChQ6p","colab":{"base_uri":"https://localhost:8080/","height":2947,"output_embedded_package_id":"1Uux_j-NRvbJ75m4mx5FGZsG7ovBnjW5-"},"executionInfo":{"status":"ok","timestamp":1750213185395,"user_tz":-330,"elapsed":4328,"user":{"displayName":"Saif Nazir","userId":"15029834638479146606"}},"outputId":"cf39c3de-af42-4a2a-d75b-3f7afaf2d116"},"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}],"source":["data_table.enable_dataframe_formatter()\n","data_table.DataTable(trajectory_df_seed_4)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"1qCe_JCNhQ22"},"outputs":[],"source":["# Save the dataframe as a pickle file\n","trajectory_df_seed_4.to_pickle('/content/drive/MyDrive/05_zero_shot_llm_3/02_data/03_test_trajectories/7_llm_d_ideal/4_llmf_d_ideal_df_1.pkl')         # Update directory location 5"]},{"cell_type":"markdown","metadata":{"id":"GK2JR89NhIeJ"},"source":["Fifth LLM feedback direct  data frame"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"GeZXIUCDg7fA"},"outputs":[],"source":["# Collect data for 100 episodes\n","trajectory_data_5 = collect_trajectory_data(env, model, num_episodes=100,seed=34)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"RRVMOCvDhSWQ"},"outputs":[],"source":["# Preprocess the trajectory data\n","trajectory_df_seed_5 = preprocess_trajectory_data(trajectory_data_5)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"A4dorT-ahSJ5","colab":{"base_uri":"https://localhost:8080/","height":3079,"output_embedded_package_id":"1yhIgdbpfeBTae95YGUZAa1G1n6_CA0wl"},"executionInfo":{"status":"ok","timestamp":1750214514316,"user_tz":-330,"elapsed":4373,"user":{"displayName":"Saif Nazir","userId":"15029834638479146606"}},"outputId":"227ac8fb-2783-43ea-e273-9db88c7d16ae"},"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}],"source":["data_table.enable_dataframe_formatter()\n","data_table.DataTable(trajectory_df_seed_5)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"zXgtf5LXhSCc"},"outputs":[],"source":["# Save the dataframe as a pickle file\n","trajectory_df_seed_5.to_pickle('/content/drive/MyDrive/05_zero_shot_llm_3/02_data/03_test_trajectories/7_llm_d_ideal/5_llmf_d_ideal_df_1.pkl')         # Update directory location 6"]}],"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyNx8pw4QU47RBpdnxPbMNWn"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}