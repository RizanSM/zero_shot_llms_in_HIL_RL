{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyMdsYMhRY/vRdBGEmkc7hjW"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["# Install the required libraries in your Google Colab environment\n","!pip install stable-baselines3 gymnasium highway-env -q"],"metadata":{"id":"APrU5xhT0nTF","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1750201885712,"user_tz":-330,"elapsed":121105,"user":{"displayName":"Saif Nazir","userId":"15029834638479146606"}},"outputId":"128f88ef-bed0-45d0-d2cb-51c161caa140"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m184.5/184.5 kB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m105.0/105.0 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m50.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m45.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m24.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m12.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m75.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h"]}]},{"cell_type":"code","source":["# Import the necessary libraries\n","import gymnasium as gym\n","import highway_env\n","import numpy as np\n","import pandas as pd\n","import pickle\n","import os\n","import matplotlib.pyplot as plt"],"metadata":{"id":"SQJ0fTEA0m_G","executionInfo":{"status":"ok","timestamp":1750201887902,"user_tz":-330,"elapsed":2183,"user":{"displayName":"Saif Nazir","userId":"15029834638479146606"}}},"execution_count":2,"outputs":[]},{"cell_type":"code","source":["from stable_baselines3 import PPO\n","from stable_baselines3.common.vec_env import DummyVecEnv\n","from stable_baselines3.common.evaluation import evaluate_policy\n","from stable_baselines3.common.monitor import Monitor\n","from google.colab import data_table\n","from google.colab import drive\n","\n","# Mount Google Drive\n","drive.mount('/content/drive')"],"metadata":{"id":"go9u8BAE1Olz","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1750201943914,"user_tz":-330,"elapsed":56014,"user":{"displayName":"Saif Nazir","userId":"15029834638479146606"}},"outputId":"6b4212a9-1d38-4321-c2f0-c74a91127714"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["# Load the dataframe back from the pickle file\n","trajectory_df = pd.read_pickle('/content/drive/MyDrive/05_zero_shot_llm_3/02_data/02_trajectories/0_initial_training/0_initial_trajectory_df.pkl')            # Update directory location 1"],"metadata":{"id":"84qr9aP-nc0d","executionInfo":{"status":"ok","timestamp":1750201946111,"user_tz":-330,"elapsed":2203,"user":{"displayName":"Saif Nazir","userId":"15029834638479146606"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["# Display the data frame\n","data_table.enable_dataframe_formatter()\n","data_table.DataTable(trajectory_df)"],"metadata":{"id":"MHAY3C2LxMel","colab":{"base_uri":"https://localhost:8080/","height":2847,"output_embedded_package_id":"1Arrv85Juclg7CO1XTWBWCceq_N4WPWv4"},"executionInfo":{"status":"ok","timestamp":1750201953533,"user_tz":-330,"elapsed":7394,"user":{"displayName":"Saif Nazir","userId":"15029834638479146606"}},"outputId":"b0221dcc-f41e-4d8d-afa4-8b9d4f5af6a0"},"execution_count":5,"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}]},{"cell_type":"code","source":["# Check the data type of each column\n","print(type(trajectory_df['episode'][0]))\n","print(type(trajectory_df['time_step'][0]))\n","print(type(trajectory_df['state'][0]))\n","print(type(trajectory_df['action'][0]))\n","print(type(trajectory_df['reward'][0]))\n","print(type(trajectory_df['next_state'][0]))\n","print(type(trajectory_df['collision_flag'][0]))\n","print(type(trajectory_df['lane_index'][0]))"],"metadata":{"id":"BPFidEkGlZAC","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1750201953626,"user_tz":-330,"elapsed":10,"user":{"displayName":"Saif Nazir","userId":"15029834638479146606"}},"outputId":"06f4a8c4-6104-448c-a20b-835c624578d7"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["<class 'numpy.int64'>\n","<class 'numpy.int64'>\n","<class 'numpy.ndarray'>\n","<class 'numpy.ndarray'>\n","<class 'numpy.float64'>\n","<class 'numpy.ndarray'>\n","<class 'numpy.int64'>\n","<class 'numpy.int64'>\n"]}]},{"cell_type":"code","source":["trajectory_df.dtypes"],"metadata":{"id":"NYe0lzD3XNwm","colab":{"base_uri":"https://localhost:8080/","height":335},"executionInfo":{"status":"ok","timestamp":1750201953641,"user_tz":-330,"elapsed":13,"user":{"displayName":"Saif Nazir","userId":"15029834638479146606"}},"outputId":"11f637ab-9206-4a19-f1b1-a7e6309cc7d5"},"execution_count":7,"outputs":[{"output_type":"execute_result","data":{"text/plain":["episode             int64\n","time_step           int64\n","state              object\n","action             object\n","reward            float64\n","next_state         object\n","collision_flag      int64\n","lane_index          int64\n","dtype: object"],"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>0</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>episode</th>\n","      <td>int64</td>\n","    </tr>\n","    <tr>\n","      <th>time_step</th>\n","      <td>int64</td>\n","    </tr>\n","    <tr>\n","      <th>state</th>\n","      <td>object</td>\n","    </tr>\n","    <tr>\n","      <th>action</th>\n","      <td>object</td>\n","    </tr>\n","    <tr>\n","      <th>reward</th>\n","      <td>float64</td>\n","    </tr>\n","    <tr>\n","      <th>next_state</th>\n","      <td>object</td>\n","    </tr>\n","    <tr>\n","      <th>collision_flag</th>\n","      <td>int64</td>\n","    </tr>\n","    <tr>\n","      <th>lane_index</th>\n","      <td>int64</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div><br><label><b>dtype:</b> object</label>"]},"metadata":{},"execution_count":7}]},{"cell_type":"markdown","source":["A : HUMAN FEEDBACK IMPLEMENTATION (AGGRESSIVE DRIVER)\n","*   SECTION A.1: FEEDBACK BASED ON LANE CHANGING BEHAVIOUR\n","*   SECTION A.2: FEEDBACK BASED ON COLLISION AVOIDANCE MANUEVERS\n","*   SECTION A.3: FEEDBACK BASED ON SPEED OPTIMIZATION\n","*   SECTION A.4: REWARD MODELLING\n","*   SECTION A.5: MODEL TRAINING\n"],"metadata":{"id":"yK3Yd5Tt2_FU"}},{"cell_type":"markdown","source":["SECTION A.1: FEEDBACK BASED ON LANE CHANGING BEHAVIOUR\n","*   Step A.1.1: FUNCTION TO COUNT LANE CHANGES\n","*   Step A.1.2: FUNCTION TO PROVIDE FEEDBACK BASED ON LANE CHANGE\n"],"metadata":{"id":"V1BC9xeLm_aS"}},{"cell_type":"code","source":["# Step A.1.1: FUNCTION TO COUNT LANE CHANGES\n","def count_lane_changes(df):\n","    df_copy = df.copy()\n","    df_copy['count_lane_change'] = 0\n","\n","    # Group by episode\n","    for episode_id, episode_df in df_copy.groupby('episode'):  # Group by 'episode'\n","        idx = 0\n","        while idx < len(episode_df):  # Iterate within each episode\n","            current_lane_index = episode_df.iloc[idx]['lane_index']\n","\n","            if idx == 0:  # First timestep of the episode\n","                episode_df.at[episode_df.index[idx], 'count_lane_change'] = 0\n","                idx += 1\n","                continue\n","\n","            previous_lane_index = episode_df.iloc[idx - 1]['lane_index']\n","\n","            if current_lane_index == previous_lane_index:\n","                episode_df.at[episode_df.index[idx], 'count_lane_change'] = 0\n","                idx += 1\n","                continue\n","\n","            change = current_lane_index - previous_lane_index\n","            count = 1\n","            consecutive_indices = [idx]\n","\n","            lookahead_idx = idx + 1\n","            while lookahead_idx < len(episode_df) and (episode_df.iloc[lookahead_idx]['lane_index'] - episode_df.iloc[lookahead_idx - 1]['lane_index'] == change):\n","                count += 1\n","                consecutive_indices.append(lookahead_idx)\n","                lookahead_idx += 1\n","\n","            for i in consecutive_indices:\n","                episode_df.at[episode_df.index[i], 'count_lane_change'] = count\n","\n","            idx = lookahead_idx\n","\n","        df_copy.loc[episode_df.index, 'count_lane_change'] = episode_df['count_lane_change'].values # Update original df\n","\n","    return df_copy"],"metadata":{"id":"l6ogHDaMcSXf","executionInfo":{"status":"ok","timestamp":1750201953645,"user_tz":-330,"elapsed":2,"user":{"displayName":"Saif Nazir","userId":"15029834638479146606"}}},"execution_count":8,"outputs":[]},{"cell_type":"code","source":["# Call the function and save the updated dataframe as \"lane_feedback_df\"\n","lane_feedback_df = count_lane_changes(trajectory_df)"],"metadata":{"id":"ytNuI-8zdYHn","executionInfo":{"status":"ok","timestamp":1750201953651,"user_tz":-330,"elapsed":3,"user":{"displayName":"Saif Nazir","userId":"15029834638479146606"}}},"execution_count":9,"outputs":[]},{"cell_type":"code","source":["data_table.enable_dataframe_formatter()\n","data_table.DataTable(lane_feedback_df)"],"metadata":{"id":"dclcOqjRdbKg","colab":{"base_uri":"https://localhost:8080/","height":3558,"output_embedded_package_id":"17tKw3EdPbspkCcYdN8tAAGL6WsrlCe3a"},"executionInfo":{"status":"ok","timestamp":1750201953920,"user_tz":-330,"elapsed":266,"user":{"displayName":"Saif Nazir","userId":"15029834638479146606"}},"outputId":"34cd8117-8967-478c-c542-2f32349af582"},"execution_count":10,"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}]},{"cell_type":"code","source":["# Step A.1.2: FUNCTION TO PROVIDE FEEDBACK BASED ON LANE CHANGE\n","# Define the lane_change_behaviour function\n","def lane_change_behaviour(df):\n","    # Create a copy of the dataframe to avoid modifying the original one\n","    df_copy = df.copy()\n","\n","    # Create 'Lane_feedback' and 'Lane_change_score' columns\n","    df_copy['Lane_feedback'] = \"\"\n","    df_copy['Lane_change_score'] = 0\n","    df_copy['Lane_change_score'] = df_copy['Lane_change_score'].astype(float)\n","\n","    # Iterate through the dataframe to apply the lane change behavior logic\n","    for i, row in df_copy.iterrows():\n","        lane_change_number = row['count_lane_change']\n","\n","        if lane_change_number == 0:\n","            df_copy.at[i, 'Lane_feedback'] = \"No lane change is observed\"\n","            df_copy.at[i, 'Lane_change_score'] = -2                                 # Bias value 1\n","        elif lane_change_number == 1:\n","            df_copy.at[i, 'Lane_feedback'] = \"One lane change is observed\"\n","            df_copy.at[i, 'Lane_change_score'] = +1                                 # Bias value 2\n","        elif lane_change_number == 2:\n","            df_copy.at[i, 'Lane_feedback'] = \"Two lane change is observed\"\n","            df_copy.at[i, 'Lane_change_score'] = +2                                 # Bias value 3\n","        elif lane_change_number == 3:\n","            df_copy.at[i, 'Lane_feedback'] = \"Three lane change is observed\"\n","            df_copy.at[i, 'Lane_change_score'] = +2                                 # Bias value 4\n","\n","\n","    # Return the updated dataframe\n","    return df_copy"],"metadata":{"id":"5VbJbsKqecVO","executionInfo":{"status":"ok","timestamp":1750201954021,"user_tz":-330,"elapsed":3,"user":{"displayName":"Saif Nazir","userId":"15029834638479146606"}}},"execution_count":11,"outputs":[]},{"cell_type":"code","source":["# Apply the lane_change_behaviour function to the lane_feedback_df\n","lane_behaviour_feedback_df = lane_change_behaviour(lane_feedback_df)"],"metadata":{"id":"N_idiuM3exV_","executionInfo":{"status":"ok","timestamp":1750201954024,"user_tz":-330,"elapsed":1,"user":{"displayName":"Saif Nazir","userId":"15029834638479146606"}}},"execution_count":12,"outputs":[]},{"cell_type":"code","source":["data_table.enable_dataframe_formatter()\n","data_table.DataTable(lane_behaviour_feedback_df)"],"metadata":{"id":"q4h9suvHesrz","colab":{"base_uri":"https://localhost:8080/","height":5063,"output_embedded_package_id":"1d6Fve97wpwlZpNmqgfBYL-gJuZcwOmU7"},"executionInfo":{"status":"ok","timestamp":1750201955814,"user_tz":-330,"elapsed":1788,"user":{"displayName":"Saif Nazir","userId":"15029834638479146606"}},"outputId":"f1ea1a63-7ead-463b-c51c-275b2fd177da"},"execution_count":13,"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}]},{"cell_type":"markdown","source":["SECTION A.2: FEEDBACK BASED ON COLLISION AVOIDANCE MANUEVERS\n","*   Step A.2.1: FUNCTION TO CALCULATE LANE CHANGE\n","*   Step A.2.2: FUNCTION TO CALCULATE TIME TO COLLISION(TTC)\n","*   Step A.2.3: FUNCTION TO CALCULATE RELATIVE POSITION, RELATIVE VELOCITY AND TIME TO COLLISION\n","*   Step A.2.4: FUNCTION TO IMPLEMENT COLLISION AVOIDANCE FEEDBACK"],"metadata":{"id":"oINoG120nF9v"}},{"cell_type":"code","source":["def calculate_lane_changes(df):\n","    df_copy = df.copy()\n","    df_copy['Lane_change_collision_fb'] = 0\n","\n","    # Group by episode\n","    for episode_id, episode_df in df_copy.groupby('episode'):  # Group by 'episode'\n","        idx = 0\n","        while idx < len(episode_df):  # Iterate within each episode\n","            current_lane_index = episode_df.iloc[idx]['lane_index']\n","\n","            if idx == 0:  # First timestep of the episode\n","                episode_df.at[episode_df.index[idx], 'Lane_change_collision_fb'] = 0\n","                idx += 1\n","                continue\n","\n","            previous_lane_index = episode_df.iloc[idx - 1]['lane_index']\n","\n","            if current_lane_index != previous_lane_index:\n","                episode_df.at[episode_df.index[idx], 'Lane_change_collision_fb'] = 1\n","                idx += 1\n","                continue\n","\n","            else:\n","                episode_df.at[episode_df.index[idx], 'Lane_change_collision_fb'] = 0\n","                idx += 1\n","\n","        df_copy.loc[episode_df.index, 'Lane_change_collision_fb'] = episode_df['Lane_change_collision_fb'].values # Update original df\n","        # df_copy.loc[episode_df.index, 'count_lane_change'] = episode_df['count_lane_change'].values\n","\n","    return df_copy"],"metadata":{"id":"3gE7sFDx7JGx","executionInfo":{"status":"ok","timestamp":1750201955844,"user_tz":-330,"elapsed":2,"user":{"displayName":"Saif Nazir","userId":"15029834638479146606"}}},"execution_count":14,"outputs":[]},{"cell_type":"code","source":["# Call the function and save the updated dataframe as \"lane_feedback_df\"\n","lane_change_collision_fb_df = calculate_lane_changes(trajectory_df)"],"metadata":{"id":"xKboQ065Xe1T","executionInfo":{"status":"ok","timestamp":1750201955848,"user_tz":-330,"elapsed":1,"user":{"displayName":"Saif Nazir","userId":"15029834638479146606"}}},"execution_count":15,"outputs":[]},{"cell_type":"code","source":["data_table.enable_dataframe_formatter()\n","data_table.DataTable(lane_change_collision_fb_df)"],"metadata":{"id":"mxC64v2KXmh5","colab":{"base_uri":"https://localhost:8080/","height":3592,"output_embedded_package_id":"1kzgdTvWFq1ODmd5T-V9q5cTGkDrjPL03"},"executionInfo":{"status":"ok","timestamp":1750201958018,"user_tz":-330,"elapsed":2167,"user":{"displayName":"Saif Nazir","userId":"15029834638479146606"}},"outputId":"c6080de4-f5ff-4472-9e68-5b45cd712381"},"execution_count":16,"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}]},{"cell_type":"code","source":[" # Step A.2.2: FUNCTION TO CALCULATE TIME TO COLLISION(TTC)\n","def calculate_ttc(ego_vehicle, other_vehicles):\n","    if not other_vehicles:\n","        return np.inf, -1  # No other vehicles\n","\n","    min_ttc = np.inf\n","    nearest_vehicle_index = -1\n","\n","    ego_x = ego_vehicle[\"x\"]\n","    ego_y = ego_vehicle[\"y\"]\n","    ego_vx = ego_vehicle[\"vx\"]\n","    ego_vy = ego_vehicle[\"vy\"]\n","\n","    for i, other in enumerate(other_vehicles):\n","        other_x = other[\"x\"]\n","        other_y = other[\"y\"]\n","        other_vx = other[\"vx\"]\n","        other_vy = other[\"vy\"]\n","\n","        dx = other_x - ego_x\n","        dy = other_y - ego_y\n","\n","\n","        dvx = other_vx - ego_vx\n","        dvy = other_vy - ego_vy\n","\n","        # Calculate TTC (constant velocity assumption)\n","        dot_product = dx * dvx + dy * dvy\n","        if dot_product < 0:  # Vehicles are getting closer\n","            distance = np.sqrt(dx**2 + dy**2)\n","            relative_speed = np.sqrt(dvx**2 + dvy**2)  # Magnitude of relative speed\n","            if relative_speed > 0:\n","              ttc = distance / relative_speed\n","            else:\n","              ttc = np.inf # Relative speed is zero, no collision\n","        else:\n","            ttc = np.inf  # Vehicles are moving apart\n","\n","\n","        if ttc < min_ttc and ttc > 0: # Only consider positive TTCs (collisions)\n","            min_ttc = ttc\n","            nearest_vehicle_index = i\n","\n","    return min_ttc, nearest_vehicle_index"],"metadata":{"id":"NdQ9A6ZbMIm_","executionInfo":{"status":"ok","timestamp":1750201958099,"user_tz":-330,"elapsed":2,"user":{"displayName":"Saif Nazir","userId":"15029834638479146606"}}},"execution_count":17,"outputs":[]},{"cell_type":"code","source":["#  Step A.2.3: FUNCTION TO CALCULATE RELATIVE POSITION, RELATIVE VELOCITY AND ACCELARATION\n","\n","def calculate_collision_parameters_1(trajectory_df):\n","    # Create a copy of the original dataframe\n","    df_copy = trajectory_df.copy()\n","\n","    df_copy['Nearest vehicle id'] = None\n","    df_copy['TTC'] = 0.0\n","    # Create a new column for storing collision parameters\n","    df_copy['Collision_Parameters'] = None\n","\n","    # Group by episode\n","    for episode_id, episode_df in df_copy.groupby('episode'):\n","        # Iterate through each timestep in the episode\n","        for idx, row in episode_df.iterrows():\n","            # Get the agent's state and new state\n","            agent_state = row['state']\n","            agent_new_state = row['next_state']\n","\n","            agent_position = np.array([agent_state[1], agent_state[2]])  # x, y\n","            agent_velocity = np.array([agent_state[3], agent_state[4]])  # vx, vy\n","            agent_new_position = np.array([agent_new_state[1], agent_new_state[2]])  # new x, new y\n","            agent_new_velocity = np.array([agent_new_state[3], agent_new_state[4]])  # new vx, new vy\n","\n","            # Find the nearest vehicle\n","            nearest_vehicle_distance = float('inf')\n","            nearest_vehicle_idx = None\n","            other_vehicles = [] # Initialize list to store other vehicles' data\n","            for vehicle_idx, vehicle_row in episode_df.iterrows():\n","                if vehicle_idx != idx:  # Skip the agent itself\n","                    vehicle_state = vehicle_row['state']\n","                    vehicle_position = np.array([vehicle_state[1], vehicle_state[2]])\n","                    vehicle_velocity = np.array([vehicle_state[3], vehicle_state[4]]) # Added to store velocity\n","                    distance = np.linalg.norm(agent_position - vehicle_position)\n","                    if distance < nearest_vehicle_distance:\n","                        nearest_vehicle_distance = distance\n","                        nearest_vehicle_idx = vehicle_idx\n","                    other_vehicles.append({\"x\": vehicle_position[0], \"y\": vehicle_position[1], \"vx\":vehicle_velocity[0], \"vy\":vehicle_velocity[1]}) # Added other vehicles\n","\n","            # print(f\"Episode {episode_id}, Time step {row['time_step']}: Nearest vehicle is {nearest_vehicle_idx}\")\n","\n","            if nearest_vehicle_idx is None:\n","                collision_data = {\n","                    'Vehicle_number': None,\n","                    'Relative_position': None,\n","                    'Relative_velocity': None,\n","                    'Relative_speed': None,\n","                    'TTC': None,\n","                    'Agent_acceleration': None\n","                }\n","                df_copy.at[row.name, 'Collision_Parameters'] = collision_data\n","                continue\n","\n","            # --- TTC Calculation Logic (Modified) ---\n","            ego_vehicle = {\"x\": agent_position[0], \"y\": agent_position[1], \"vx\": agent_velocity[0], \"vy\": agent_velocity[1]}\n","            ttc, _ = calculate_ttc(ego_vehicle, other_vehicles) # Call the function\n","\n","            # --- End of TTC Calculation Logic ---\n","\n","            nearest_vehicle_state = episode_df.loc[nearest_vehicle_idx, 'state']\n","            nearest_vehicle_position = np.array([nearest_vehicle_state[1], nearest_vehicle_state[2]])\n","            nearest_vehicle_velocity = np.array([nearest_vehicle_state[3], nearest_vehicle_state[4]])\n","\n","            relative_position = nearest_vehicle_position - agent_position\n","            relative_velocity = nearest_vehicle_velocity - agent_velocity\n","            relative_speed = np.linalg.norm(relative_velocity)\n","\n","\n","            acceleration = agent_new_velocity - agent_velocity\n","\n","            collision_data = {\n","                'Vehicle_number': nearest_vehicle_idx,\n","                'Relative_position': relative_position.tolist(),\n","                'Relative_velocity': relative_velocity.tolist(),\n","                'Relative_speed': relative_speed,\n","                'TTC': ttc,\n","                'Agent_acceleration': acceleration.tolist()\n","            }\n","            df_copy.at[row.name, 'Collision_Parameters'] = collision_data\n","            df_copy.at[row.name, 'Nearest vehicle id'] = nearest_vehicle_idx\n","            df_copy.at[row.name, 'TTC'] = ttc\n","\n","    return df_copy"],"metadata":{"id":"HPpCX1PzMLZv","executionInfo":{"status":"ok","timestamp":1750201958102,"user_tz":-330,"elapsed":2,"user":{"displayName":"Saif Nazir","userId":"15029834638479146606"}}},"execution_count":18,"outputs":[]},{"cell_type":"code","source":["collision_parameters_df_1 = calculate_collision_parameters_1(lane_change_collision_fb_df)"],"metadata":{"id":"TqYFw2pib_zY","executionInfo":{"status":"ok","timestamp":1750201968433,"user_tz":-330,"elapsed":10330,"user":{"displayName":"Saif Nazir","userId":"15029834638479146606"}}},"execution_count":19,"outputs":[]},{"cell_type":"code","source":["data_table.enable_dataframe_formatter()\n","data_table.DataTable(collision_parameters_df_1)"],"metadata":{"id":"h-FlnywacKHX","colab":{"base_uri":"https://localhost:8080/","height":9843,"output_embedded_package_id":"11MjXR9BRcedDZGKK8nzqxldARWUyFjN_"},"executionInfo":{"status":"ok","timestamp":1750201973220,"user_tz":-330,"elapsed":4784,"user":{"displayName":"Saif Nazir","userId":"15029834638479146606"}},"outputId":"c4bd55cd-c89b-4003-a055-d6285a58fc21"},"execution_count":20,"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}]},{"cell_type":"code","source":["## Time to collision list for each episode\n","# Group the data by 'episode'\n","# episode_data = collision_parameters_df_1.groupby('episode')\n","## Loop through each episode\n","# for episode, data in episode_data:\n","#    # Extract lane indices\n","#     ttc_list = data['TTC'].tolist()\n","\n","#    # Count the total number of time steps in the episode\n","#     total_timesteps = data['time_step'].max() + 1  # Assuming time_step starts from 0\n","\n","#     print(f\"Episode {episode}:Total timesteps {total_timesteps}: {ttc_list}\")"],"metadata":{"id":"-oWAV3EZcqu-","executionInfo":{"status":"ok","timestamp":1750201973259,"user_tz":-330,"elapsed":3,"user":{"displayName":"Saif Nazir","userId":"15029834638479146606"}}},"execution_count":21,"outputs":[]},{"cell_type":"code","source":["## Nearest vehicle list for each episode\n","## Group the data by 'episode'\n","# episode_data = collision_parameters_df_1.groupby('episode')\n","## Loop through each episode\n","# for episode, data in episode_data:\n","#    # Extract lane indices\n","#     nearest_vehicle_list = data['Nearest vehicle id'].tolist()\n","\n","#    # Count the total number of time steps in the episode\n","#     total_timesteps = data['time_step'].max() + 1  # Assuming time_step starts from 0\n","\n","#     print(f\"Episode {episode}:Total timesteps {total_timesteps}: {nearest_vehicle_list}\")"],"metadata":{"id":"mZsgFYSpigoO","executionInfo":{"status":"ok","timestamp":1750201973261,"user_tz":-330,"elapsed":1,"user":{"displayName":"Saif Nazir","userId":"15029834638479146606"}}},"execution_count":22,"outputs":[]},{"cell_type":"code","execution_count":23,"metadata":{"id":"8Ee2reKxpTB6","executionInfo":{"status":"ok","timestamp":1750201973264,"user_tz":-330,"elapsed":2,"user":{"displayName":"Saif Nazir","userId":"15029834638479146606"}}},"outputs":[],"source":["# Step A.2.4: Function to implement collision avoidance feedback\n","def implement_collision_feedback(df):\n","    # Create a copy of the dataframe to avoid modifying the original dataframe\n","    df_copy = df.copy()\n","\n","    # Create new columns for Collision Feedback and Collision Reward\n","    df_copy['Collision_Feedback'] = None\n","    df_copy['Collision_score'] = 0.0\n","\n","    # Iterate through each timestep in the dataframe\n","    for idx, row in df_copy.iterrows():\n","        collision_data = row['Collision_Parameters']\n","        ttc = collision_data['TTC']\n","        agent_acceleration = collision_data['Agent_acceleration']\n","        lane_change = row['Lane_change_collision_fb']\n","\n","        # Initialize feedback and reward\n","        feedback = ''\n","        feedback_1 = ''\n","        score = 0.0\n","\n","        # Logic for Time to Collision (TTC)\n","        if  0.5 <= ttc <=2.0 :\n","            feedback_1 = 'Potential collision risk'\n","            if agent_acceleration[0] < 0:\n","                feedback = 'Avoided collision by slowing down'\n","                score = -2                                                          # Bias Value 5\n","            elif agent_acceleration[0] > 0:\n","                feedback = 'Avoided collision by speeding up'\n","                score = +2                                                          # Bias Value 6\n","            elif lane_change == 1:\n","                feedback = 'Avoided collision by lane change'\n","                score = +1                                                          # Bias Value 7\n","        elif ttc < 0.5:\n","            feedback_1 = 'Immediate collision risk'\n","            # Check if agent_acceleration is not [0, 0] using any\n","            # Modified: Check if any element in agent_acceleration is not 0\n","            if any(x != 0 for x in agent_acceleration):\n","            # if agent_acceleration != [0, 0]:\n","                feedback = 'Emergency avoidance'\n","                score = -1                                                          # Bias Value 8\n","            else:\n","                score = 0.0\n","        else:\n","            feedback = 'Safe Path'\n","            score = -2                                                              # Bias Value 9\n","\n","        # Update the feedback and reward columns\n","        df_copy.at[idx, 'Collision_Feedback'] = feedback_1, feedback\n","        df_copy.at[idx, 'Collision_score'] = score\n","\n","    return df_copy"]},{"cell_type":"code","source":["# Call the function to process collision feedback and reward\n","Collision_feedback_df = implement_collision_feedback(collision_parameters_df_1)"],"metadata":{"id":"uVDzc0QMqYdO","executionInfo":{"status":"ok","timestamp":1750201973267,"user_tz":-330,"elapsed":2,"user":{"displayName":"Saif Nazir","userId":"15029834638479146606"}}},"execution_count":24,"outputs":[]},{"cell_type":"code","source":["data_table.enable_dataframe_formatter()\n","data_table.DataTable(Collision_feedback_df)"],"metadata":{"id":"mvv1exBGqcb6","colab":{"base_uri":"https://localhost:8080/","height":10321,"output_embedded_package_id":"1uKHZ8Hg3vCgMXBnDQhDXP6e0ps8oElkk"},"executionInfo":{"status":"ok","timestamp":1750201976817,"user_tz":-330,"elapsed":3549,"user":{"displayName":"Saif Nazir","userId":"15029834638479146606"}},"outputId":"a678ea84-a473-4e28-e36b-c212eb232bbc"},"execution_count":25,"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}]},{"cell_type":"markdown","source":["SECTION A.3: FEEDBACK BASED ON SPEED OPTIMIZATION\n","*   Step A.3.1: FUNCTION TO CALCULATE AGENT SPEED AND TRAFFIC DENSITY SCORE\n","*   Step A.3.2: FUNCTION TO IMPLEMENT SPEED OPTIMIZATION FEEDBACK"],"metadata":{"id":"-cVuPczPnjiy"}},{"cell_type":"code","execution_count":26,"metadata":{"id":"Oxh0zhuHzx75","executionInfo":{"status":"ok","timestamp":1750201976860,"user_tz":-330,"elapsed":2,"user":{"displayName":"Saif Nazir","userId":"15029834638479146606"}}},"outputs":[],"source":["# Step A.3.1: FUNCTION TO CALCULATE AGENT SPEED AND TRAFFIC DENSITY SCORE\n","# Define the function to calculate agent speed and traffic density score\n","def calculate_speed_and_traffic_density(trajectory_df):\n","    # Create a copy of the input dataframe to avoid modifying the original\n","    df = trajectory_df.copy()\n","\n","    df['Average_distance'] = 0.0\n","    df['Traffic_density_score'] = 0\n","    df['Agent_Speed'] = 0\n","    # Initialize the Speed_Optimization_Parameters column\n","    df['Speed_Optimization_Parameters'] = None\n","\n","\n","    # Function to calculate agent speed based on vx and vy (longitudinal and lateral velocities)\n","    def calculate_speed(vx, vy):\n","        return np.sqrt(vx**2 + vy**2)\n","\n","    # Iterate through the rows of the dataframe to calculate the required values\n","    for index, row in df.iterrows():\n","        # Extract agent state and next state\n","        state = row['state']\n","        next_state = row['next_state']\n","\n","        # Extract agent vehicle's (ego vehicle) longitudinal and lateral velocity\n","        agent_vx = state[3]  # vx of agent\n","        agent_vy = state[4]  # vy of agent\n","\n","        # Calculate agent speed\n","        agent_speed = calculate_speed(agent_vx, agent_vy)\n","\n","        # Extract other vehicles' state\n","        # The original state is a flattened array of shape (25,).\n","        # We need to reshape it to (5, 5) to represent 5 vehicles, each with 5 attributes.\n","        # Then we can select the other vehicles (excluding the ego vehicle at index 0).\n","\n","        state_reshaped = state.reshape(5, 5)  # Reshape to 5 vehicles, 5 features each\n","        other_vehicles_state = state_reshaped[1:]  # Exclude ego vehicle (index 0)\n","\n","\n","        # Extract other vehicles' state\n","        # other_vehicles_state = state[1:].reshape(-1, 5)  # Extract all other vehicles' states\n","\n","        # Calculate the distances between the agent and other vehicles\n","        distances = []\n","        for vehicle in other_vehicles_state:\n","            # Calculate the distance between the agent and other vehicles using x and y positions\n","            vehicle_x, vehicle_y = vehicle[1], vehicle[2]\n","            agent_x, agent_y = state[1], state[2]\n","            distance = np.sqrt((vehicle_x - agent_x)**2 + (vehicle_y - agent_y)**2)\n","            distances.append(distance)\n","            # print(f\"Distance between agent and vehicle {index}: {distance}\")\n","\n","        # Determine traffic density score based on the distance\n","        traffic_density_score = 1  # Default low traffic density (1)\n","        avg_distance = np.mean(distances)\n","        #print(f\"Average distance between agent and other vehicles: {avg_distance}\")\n","\n","        if avg_distance < 0.8:  # High traffic density\n","            traffic_density_score = 3\n","        elif avg_distance < 1.0:  # Medium traffic density\n","            traffic_density_score = 2\n","\n","        df.at[index, 'Average_distance'] = avg_distance\n","        df.at[index, 'Traffic_density_score'] = traffic_density_score\n","        df.at[index, 'Agent_Speed'] = agent_speed\n","        # Add the agent speed and traffic density score to the 'Speed_Optimization_Parameters' column\n","        df.at[index, 'Speed_Optimization_Parameters'] = {'Agent_Speed': agent_speed, 'Traffic_Density_Score': traffic_density_score}\n","\n","\n","    return df\n"]},{"cell_type":"code","source":["# Call the function to calculate speed and traffic density\n","Speed_parameters_df = calculate_speed_and_traffic_density(trajectory_df)"],"metadata":{"id":"S7dIIMD0qkJJ","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1750201976869,"user_tz":-330,"elapsed":8,"user":{"displayName":"Saif Nazir","userId":"15029834638479146606"}},"outputId":"eaea097d-e2e6-4bc6-cbe2-c7e35e93103c"},"execution_count":27,"outputs":[{"output_type":"stream","name":"stderr","text":["<ipython-input-26-2084209440>:65: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '0.3125' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n","  df.at[index, 'Agent_Speed'] = agent_speed\n"]}]},{"cell_type":"code","source":["data_table.enable_dataframe_formatter()\n","data_table.DataTable(Speed_parameters_df)"],"metadata":{"id":"mLRhQOJNqnU4","colab":{"base_uri":"https://localhost:8080/","height":10256,"output_embedded_package_id":"1cDigAXB5rYeJg5gsW4Lg1cjSftGysbL_"},"executionInfo":{"status":"ok","timestamp":1750201980336,"user_tz":-330,"elapsed":3466,"user":{"displayName":"Saif Nazir","userId":"15029834638479146606"}},"outputId":"e5d83afe-3117-4836-ca73-b78c077ec566"},"execution_count":28,"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}]},{"cell_type":"code","source":["## Traffic density score for each episode\n","## Group the data by 'episode'\n","# episode_data = Speed_parameters_df.groupby('episode')\n","## Loop through each episode\n","# for episode, data in episode_data:\n","#    # Extract lane indices\n","#     traffic_density_score_list = data['Traffic_density_score'].tolist()\n","\n","#    # Count the total number of time steps in the episode\n","#     total_timesteps = data['time_step'].max() + 1  # Assuming time_step starts from 0\n","\n","#     print(f\"Episode {episode}:Total timesteps {total_timesteps}: {traffic_density_score_list}\")"],"metadata":{"id":"-yUUPrMLERDu","executionInfo":{"status":"ok","timestamp":1750201980405,"user_tz":-330,"elapsed":4,"user":{"displayName":"Saif Nazir","userId":"15029834638479146606"}}},"execution_count":29,"outputs":[]},{"cell_type":"code","source":["## Agent's speed list for each episode\n","## Group the data by 'episode'\n","# episode_data = Speed_parameters_df.groupby('episode')\n","## Loop through each episode\n","# for episode, data in episode_data:\n","#    # Extract lane indices\n","#     agent_speed_list = data['Agent_Speed'].tolist()\n","\n","#    # Count the total number of time steps in the episode\n","#     total_timesteps = data['time_step'].max() + 1  # Assuming time_step starts from 0\n","\n","#     print(f\"Episode {episode}:Total timesteps {total_timesteps}: {agent_speed_list}\")"],"metadata":{"id":"yko_9mnTF50A","executionInfo":{"status":"ok","timestamp":1750201980411,"user_tz":-330,"elapsed":3,"user":{"displayName":"Saif Nazir","userId":"15029834638479146606"}}},"execution_count":30,"outputs":[]},{"cell_type":"code","execution_count":31,"metadata":{"id":"uOHlfCEsp81h","executionInfo":{"status":"ok","timestamp":1750201980417,"user_tz":-330,"elapsed":3,"user":{"displayName":"Saif Nazir","userId":"15029834638479146606"}}},"outputs":[],"source":["# Step A.3.2: FUNCTION TO IMPLEMENT SPEED OPTIMIZATION FEEDBACK\n","def implement_speed_optimization_feedback(Speed_parameters_df):\n","    # Create a copy of the dataframe to avoid modifying the original\n","    df_copy = Speed_parameters_df.copy()\n","\n","    # Define the threshold_speed range\n","    threshold_speed_min = 0.25  # Example minimum threshold speed\n","    threshold_speed_max = 0.30  # Example maximum threshold speed\n","    threshold_speed = (threshold_speed_min, threshold_speed_max)  # Tuple representing min and max speeds\n","\n","    # Initialize columns for feedback and reward\n","    speed_optimization_feedback = []\n","    speed_optimization_score = []\n","\n","    # Iterate through the dataframe to calculate feedback and rewards\n","    for i in range(len(df_copy)):\n","        # Extract the agent speed and traffic density from the Speed_Optimization_Parameters\n","        # agent_speed = df_copy['Speed_Optimization_Parameters']['Agent_Speed']\n","        # traffic_density = df_copy['Speed_Optimization_Parameters']['Traffic_density_score']\n","        agent_speed = df_copy['Speed_Optimization_Parameters'][i]['Agent_Speed']\n","        traffic_density = df_copy['Speed_Optimization_Parameters'][i]['Traffic_Density_Score']\n","\n","        feedback = \"\"\n","        score = 0.0\n","\n","        # Check traffic density and apply corresponding logic\n","        if traffic_density == 1:  # Low traffic density\n","            if agent_speed > threshold_speed[1]:\n","                feedback = \"Low risk, High Speed-Optimization\"\n","                score = +2                                                          # Bias Value 10\n","            elif threshold_speed[0] <= agent_speed <= threshold_speed[1]:\n","                feedback = \"Low risk, moderate Speed-Optimization\"\n","                score = +1                                                          # Bias Value 11\n","            else:  # agent_speed < threshold_speed[0]\n","                feedback = \"Low risk, Low Speed-Optimization\"\n","                score = -2                                                          # Bias Value 12\n","\n","        elif traffic_density == 2:  # Medium traffic density\n","            if agent_speed > threshold_speed[1]:\n","                feedback = \"Moderate risk, High Speed-Optimization\"\n","                score = +1                                                          # Bias Value 13\n","            elif threshold_speed[0] <= agent_speed <= threshold_speed[1]:\n","                feedback = \"Moderate risk, moderate Speed-Optimization\"\n","                score = 0                                                           # Bias Value 14\n","            else:  # agent_speed < threshold_speed[0]\n","                feedback = \"Moderate risk, Low Speed-Optimization\"\n","                score = -1                                                          # Bias Value 15\n","\n","        elif traffic_density == 3:  # High traffic density\n","            if agent_speed > threshold_speed[1]:\n","                feedback = \"High risk, High Speed-Optimization\"\n","                score = +2                                                          # Bias Value 16\n","            elif threshold_speed[0] <= agent_speed <= threshold_speed[1]:\n","                feedback = \"High risk, moderate Speed-Optimization\"\n","                score = +1                                                          # Bais Value 17\n","            else:  # agent_speed < threshold_speed[0]\n","                feedback = \"High risk, Low Speed-Optimization\"\n","                score = -2                                                          # Bias Value 18\n","\n","        # Append the feedback and reward to the respective lists\n","        speed_optimization_feedback.append(feedback)\n","        speed_optimization_score.append(score)\n","\n","    # Add the new columns to the dataframe\n","    df_copy['Speed_Optimization_Feedback'] = speed_optimization_feedback\n","    df_copy['Speed_Optimization_score'] = speed_optimization_score\n","\n","    return df_copy"]},{"cell_type":"code","source":["Speed_optimization_feedback_df = implement_speed_optimization_feedback(Speed_parameters_df)"],"metadata":{"id":"LbwS2giIqvqG","executionInfo":{"status":"ok","timestamp":1750201980423,"user_tz":-330,"elapsed":3,"user":{"displayName":"Saif Nazir","userId":"15029834638479146606"}}},"execution_count":32,"outputs":[]},{"cell_type":"code","source":["data_table.enable_dataframe_formatter()\n","data_table.DataTable(Speed_optimization_feedback_df)"],"metadata":{"id":"HMaW6U2yq0Vg","colab":{"base_uri":"https://localhost:8080/","height":10321,"output_embedded_package_id":"19A9e4PJAPaSx_Mdv8FhN6J9nGveKUZlg"},"executionInfo":{"status":"ok","timestamp":1750201982469,"user_tz":-330,"elapsed":2042,"user":{"displayName":"Saif Nazir","userId":"15029834638479146606"}},"outputId":"9a78601a-f5dd-42aa-b766-d969d7abc86a"},"execution_count":33,"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}]},{"cell_type":"markdown","source":["SECTION- A.4: REWARD MODELLING(HUMAN FEEDBACK)\n","*   Step A.4.1: COMBINING HUMAN FEEDBACK AND CALCULATING ADJUSTED REWARDS\n","*   Step A.4.2: RECALIBRATE REWARDS BASED ON SIMULATED HUMAN FEEDBACK"],"metadata":{"id":"RMguIvy_oi5x"}},{"cell_type":"code","execution_count":34,"metadata":{"id":"kJWJEkepqldb","executionInfo":{"status":"ok","timestamp":1750201982539,"user_tz":-330,"elapsed":4,"user":{"displayName":"Saif Nazir","userId":"15029834638479146606"}}},"outputs":[],"source":["# Step A.4.1: COMBINING HUMAN FEEDBACK AND CALCULATING ADJUSTED REWARDS\n","# Function to combine data from four dataframes and merge with trajectory_df\n","def combine_feedback_and_rewards(trajectory_df, collision_feedback_df, speed_optimization_feedback_df, lane_behaviour_feedback_df):\n","    # Create a copy of the trajectory_df to avoid modifying the original one\n","    df_copy = trajectory_df.copy()\n","\n","    # Convert the 'Collision_Feedback' column to strings\n","    #collision_feedback_df['Collision_Feedback'] = collision_feedback_df['Collision_Feedback'].apply(lambda x:''.join(map(str, x)))\n","    collision_feedback_df['Collision_Feedback'] = collision_feedback_df['Collision_Feedback'].astype(str)\n","\n","\n","    # Combine the 'Feedback' columns from the four dataframes and add to the 'Simulated_human_feedback' column\n","    df_copy['Simulated_human_feedback'] = (\n","        collision_feedback_df['Collision_Feedback'] + \";\" +\n","        speed_optimization_feedback_df['Speed_Optimization_Feedback'] + \";\" +\n","        lane_behaviour_feedback_df['Lane_feedback']\n","    )\n","\n","    # Add the values of the 'Reward' columns from the four dataframes and store the result in 'Adjusted_score' column\n","    df_copy['Adjusted_score'] = (\n","        collision_feedback_df['Collision_score'] +\n","        speed_optimization_feedback_df['Speed_Optimization_score'] +\n","        lane_behaviour_feedback_df['Lane_change_score']\n","    )\n","\n","    # Return the updated dataframe\n","    return df_copy"]},{"cell_type":"code","source":["# Call the function to combine feedback and calculate adjusted rewards\n","simulated_human_feedback_df = combine_feedback_and_rewards(\n","    trajectory_df,\n","    Collision_feedback_df,\n","    Speed_optimization_feedback_df,\n","    lane_behaviour_feedback_df\n",")"],"metadata":{"id":"pDDBxP6Mq6zJ","executionInfo":{"status":"ok","timestamp":1750201982545,"user_tz":-330,"elapsed":3,"user":{"displayName":"Saif Nazir","userId":"15029834638479146606"}}},"execution_count":35,"outputs":[]},{"cell_type":"code","source":["data_table.enable_dataframe_formatter()\n","data_table.DataTable(simulated_human_feedback_df)"],"metadata":{"id":"T7M6IqIfq8pl","colab":{"base_uri":"https://localhost:8080/","height":5030,"output_embedded_package_id":"1gTlF9ai5h-43GnNHffuXVreAHbSXNdKM"},"executionInfo":{"status":"ok","timestamp":1750201984264,"user_tz":-330,"elapsed":1715,"user":{"displayName":"Saif Nazir","userId":"15029834638479146606"}},"outputId":"c59ec674-b272-4773-8c34-9de17a31fe3e"},"execution_count":36,"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}]},{"cell_type":"code","source":["# Step A.4.2: RECALIBRATE REWARDS BASED ON SIMULATED HUMAN FEEDBACK\n","# Function to recalibrate the rewards\n","def recalibrate_rewards(df):\n","    # Create a copy of the dataframe\n","    df_copy = df.copy()\n","\n","    # Create the 'Recalibrated_rewards' column\n","    df_copy['Recalibrated_rewards'] = df_copy['reward'] + df_copy['Adjusted_score']\n","\n","    # Get the list of recalibrated rewards\n","    recalibrated_rewards_list = df_copy['Recalibrated_rewards'].tolist()\n","\n","    return df_copy, recalibrated_rewards_list"],"metadata":{"id":"E_vUgUJ2rJ7t","executionInfo":{"status":"ok","timestamp":1750201984329,"user_tz":-330,"elapsed":3,"user":{"displayName":"Saif Nazir","userId":"15029834638479146606"}}},"execution_count":37,"outputs":[]},{"cell_type":"code","source":["# Apply the function to recalibrate rewards\n","recalibrated_df, recalibrated_rewards_list = recalibrate_rewards(simulated_human_feedback_df)"],"metadata":{"id":"1tqZXWwmrNFI","executionInfo":{"status":"ok","timestamp":1750201984336,"user_tz":-330,"elapsed":3,"user":{"displayName":"Saif Nazir","userId":"15029834638479146606"}}},"execution_count":38,"outputs":[]},{"cell_type":"code","source":["data_table.enable_dataframe_formatter()\n","data_table.DataTable(recalibrated_df)"],"metadata":{"id":"hj6UZ7E3AdWc","colab":{"base_uri":"https://localhost:8080/","height":5675,"output_embedded_package_id":"1e9kVp29oVMosEVKaYzB_8XYo53P6FRxv"},"executionInfo":{"status":"ok","timestamp":1750201986210,"user_tz":-330,"elapsed":1871,"user":{"displayName":"Saif Nazir","userId":"15029834638479146606"}},"outputId":"9de6ac55-6897-4bd7-c0d6-550f34c0c97f"},"execution_count":39,"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}]},{"cell_type":"code","source":["recalibrated_df.to_pickle('/content/drive/MyDrive/05_zero_shot_llm_3/02_data/02_trajectories/1_human_feedback/2_Biased_Hf_D_Aggressive_df.pkl')             # Update directory location 2"],"metadata":{"id":"IPloIhcwM2_-","executionInfo":{"status":"ok","timestamp":1750201986279,"user_tz":-330,"elapsed":5,"user":{"displayName":"Saif Nazir","userId":"15029834638479146606"}}},"execution_count":40,"outputs":[]},{"cell_type":"code","source":["episode_data = recalibrated_df.groupby('episode')\n","# Loop through each episode\n","for episode, data in episode_data:\n","    # Extract lane indices\n","     recalibrated_reward_l = data['Recalibrated_rewards'].tolist()\n","\n","     # Count the total number of time steps in the episode\n","     total_timesteps = data['time_step'].max() + 1  # Assuming time_step starts from 0\n","\n","     print(f\"Episode {episode}:Total timesteps {total_timesteps}: {recalibrated_reward_l}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8-tZ7W9nInxk","executionInfo":{"status":"ok","timestamp":1750201986328,"user_tz":-330,"elapsed":44,"user":{"displayName":"Saif Nazir","userId":"15029834638479146606"}},"outputId":"520e8d39-eb1a-4d65-a314-c60242fd1525"},"execution_count":41,"outputs":[{"output_type":"stream","name":"stdout","text":["Episode 0:Total timesteps 40: [-0.20000000000000007, -1.0894517646168187, -1.0705603718311516, -0.1778802904515615, 2.8245128840260194, -2.177143511327331, -1.288215715870427, 0.6687138988604007, -2.3326880225258266, -2.333219316175332, -2.222765574211536, -0.31443860390794354, -1.3301044463764384, -1.3327815545414454, -1.333239040829683, -1.3333172198538463, -1.33333057972927, -1.333332862774796, -1.3333332529204158, -1.3333333195917119, -1.333333330985052, -1.3333333329320398, -1.3333333332647572, -0.3333333333216143, -0.33333333333133064, -0.3333333333329911, -0.333333333333275, -0.3333333333333234, -0.3333333333333316, -0.3333333333333329, -0.3333333333333329, -0.3333333333333329, -0.3333333333333329, -0.3333333333333329, -0.3333333333333329, -0.3333333333333329, -0.3333333333333329, -0.3333333333333329, 1.688888888888889, 2.6666666666666665]\n","Episode 1:Total timesteps 40: [-2.266103790938737, -2.2849951837244036, -2.2882235004871756, 0.7333333333333334, 1.7333333333333334, 1.7333364176553143, -2.26666610160967, -2.2666665697210644, -2.2666666500959294, -0.26666666383488347, -0.2666666661827478, -0.26666666658397065, -0.2666666666525349, 0.7111111111111111, -1.2888888888888888, -0.2666666666666666, 1.7333333333333334, 1.7333333333333334, 1.7333333333333334, -0.2666666666666666, -0.2666666666666666, -0.2666666666666666, 0.7111111111111111, -1.2888888888888888, -0.311111111111111, -1.311111111111111, 1.688888888888889, -1.311111111111111, -0.311111111111111, -0.311111111111111, 0.6666666666666666, 1.6666666666666665, 0.6666666666666666, 0.6666666666666666, -0.311111111111111, 1.688888888888889, -1.311111111111111, 0.6666666666666666, 1.6666666666666665, 0.6666666666666666]\n","Episode 2:Total timesteps 40: [-1.2438815687165148, -1.2627729615021814, -1.266001278264953, -1.1560047242341756, -0.13720760730089732, -0.24454363655528966, -1.2628861011063526, -1.2660206124921762, -1.1560080282261338, -0.24775640729743176, 1.7124745239921375, -1.1778039641625688, 2.8614025534746927, 2.8660063458276013, -0.24399260300178094, -1.2627919226315547, -1.2660045183579092, -1.2665535133096713, -1.2666473300892331, -1.2666633622730852, -1.266666101984681, -1.2666665701691588, -1.1561184147931964, -0.13722703567982208, -0.13399872125348455, 2.842843349048082, -0.04503451915341439, -0.13666750418733142, -0.2628760417459737, -1.2844435993429237, -1.2881292412057688, -1.2887590740373804, 1.688888888888889, 0.688888888888889, 0.6888893005952523, -3.311111002791537, -3.3111110922167595, -0.28888888888888886, -1.2888888888888888, -1.2888888888888888]\n","Episode 3:Total timesteps 40: [-1.3105482353831812, -3.3294396281688483, -2.33266794493162, -2.333219626284024, -2.333313902136412, 0.688888888888889, 1.688888888888889, 1.688888888888889, 0.7111111111111111, 0.7111111111111111, -0.311111111111111, -1.311111111111111, 1.688888888888889, 1.688888888888889, 0.7111111111111111, 0.7111111111111111, -0.28888888888888886, 0.7111111111111111, -1.2888888888888888, -0.2666666666666666, 1.7333333333333334, -1.2666666666666666, -1.2666666666666666, -1.15611843129926, -0.2477752738811012, 1.7124713021543485, -3.2883604719709854, -0.311111111111111, 1.688888888888889, 0.6666666666666666, 1.6666666666666665, 1.6666666666666665, -1.3333333220291874, -1.333333331010035, -1.3333333329323582, -1.3333333332647714, -1.3333333333216166, -1.333333333331331, -1.333333333332991, -1.3333333333332749]\n","Episode 4:Total timesteps 40: [-2.266103790938737, -3.2849951837244036, -2.2882235004871756, -2.288775181839579, -2.288869457691968, 0.7333333333333334, 1.7333333333333334, -1.2666666666666666, 1.7111111111111112, 4.733333333333333, 1.7333333333333334, -1.2666666666666666, -1.2666666666666666, -1.2666666666666666, -1.2666666666664512, -1.2666666666665982, -1.2666666666666546, -0.2666666666666645, -0.2666666666666663, -0.2666666666666663, -0.2666666666666663, -0.2666666666666663, -0.2666666666666663, -0.2666666666666663, -0.2666666666666663, -0.2666666666666663, 1.8438815687165149, -0.13722703849781848, -0.24454695711822827, -1.262886668551491, -1.2660207094618743, -1.2665562801802954, -1.2666478029148842, -1.1561152076902448, -0.24777472300684178, -1.263438255765983, -1.2661149692272007, -1.2665723880651885, -1.2666505555628973, -1.156115678085404]\n","Episode 5:Total timesteps 20: [-1.3105482353831812, -2.3294396281688483, -2.33266794493162, -2.333219626284024, -2.333313902136412, -2.3333300127703946, -2.2227845305050136, -1.3144418435779688, 1.6902490937161394, 1.7111111111111112, 1.7111774938381124, -1.1783247308853504, 2.8168485189980887, 1.9320979807194725, -1.0484517884889741, 1.9314145197316366, -1.06678995524679, -1.066686677941878, -1.177218319535899, 1.0222222222222221]\n","Episode 6:Total timesteps 40: [-1.1777777777777776, -2.1777777777777776, -2.1777777777777776, 0.8429569908025046, 1.9549849060220486, -0.13666418365523947, -0.2628754743014504, -1.1738952669896783, -0.1586895964659426, -0.2666393616571584, 1.7352674937746126, -1.2660402387508967, -1.266555873268043, -1.2666476946435599, -1.1561151887875116, -0.24777471977393706, 1.7124713968908707, -1.2883604557984158, -1.2887948504790598, 1.7333333333333334, -1.2666666666666666, -1.26666643181462, -1.266666588647583, -1.266666652951102, -1.2666666643189735, 1.7111111111111112, -1.2888888888888888, 1.7333333333333334, -1.2666666666666666, -1.2666666666666666, -1.2666666666666666, -1.2666666666666666, -1.2666666666666666, -1.156118431283487, -0.24777527388099962, -1.263438349903895, 1.7111111111111112, 1.7333333333333334, 1.7333333333333334, 1.7111111111111112]\n","Episode 7:Total timesteps 23: [-1.288326013160959, -1.3072174059466257, -3.3104457227093977, -0.33333333333333337, 0.6666666666666666, -1.333330249011352, -2.3333327682763363, -2.333333236387731, -2.222785081379331, -0.20389370233270032, -1.3112136233009761, -2.329553335135462, -2.332687376114409, 0.688888888888889, -2.311111111111111, 0.6666666666666666, 0.6666666666666666, -2.3333333333333335, -2.3333333195854746, -2.333333330607845, 0.688888888888889, -2.311111111111111, 0.04444444444444443]\n","Episode 8:Total timesteps 40: [-1.288326013160959, -2.3072174059466257, -2.3104457227093977, -2.3109974040618018, -2.31109167991419, -2.3111077905481725, -2.3111105436659725, 0.7111111111111111, 0.7111111111111111, 0.7111111111111111, -0.2666666666666666, 1.8438662425033225, -0.1372271059576331, -0.24454695754812594, -1.2628866685555362, -1.2660207094618494, -1.2665562801802839, -1.266647802914882, -1.1561152076902443, -0.24777472300684167, -1.263438255765983, -1.2661149692272007, 1.7111111111111112, 4.733333333333333, 1.7333333333333334, -1.2666663876700945, -1.2666665882018098, -1.2666666529466073, -1.2666666643189286, -1.2666666662654342, -1.156118431214919, -0.1372270384861013, -0.24454695711622587, -1.262886668551149, -1.2660207094618157, -1.1560080447971042, -0.24775641012921568, -1.2634351263106542, -1.2661144344401047, -1.2665722966763657]\n","Episode 9:Total timesteps 40: [0.8666666666666667, 0.8666666666666667, -0.24388156871651467, -1.2627729615021814, -1.266001278264953, -1.266552959617357, -1.2666472354697458, -1.2666633461037282, 1.7111111111111112, 1.7111111111111112, 1.7111111111111112, 1.7111111115562854, -0.2888888884290499, -0.2888888888064357, 0.7333333333333334, -1.1561337267591831, -0.247775377204832, -1.2634383509656377, -1.2661149853251135, -1.2665723908143862, -1.266650556032685, -1.2666639135488666, -1.2666661961912262, -1.2666665862679491, -1.266666652927472, -1.2666666643187998, -1.2666666662654436, -1.2666666665981023, -1.2666666666549498, -0.26666666666466454, -0.26666666666632455, -0.2666666666666083, -0.26666666666665684, -0.26666666666666494, -0.2666666666666663, -0.2666666666666663, -0.2666666666666663, -0.2666666666666663, -0.2666666666666663, -0.2666666666666663]\n","Episode 10:Total timesteps 40: [0.7999999999999999, -2.310548235383181, -3.3294396281688483, -3.33266794493162, -3.333219626284024, -3.333313902136412, -3.3333300127703946, -3.3333327658881946, -3.3333332363636354, -3.333333316762353, -1.3333333305015476, 0.7772149025337668, -2.2038937050817893, 0.8200697691586533, -2.288456294424905, 0.7130800762218333, 1.7333333333333334, 1.7334185130076714, -1.266647619785651, -1.266663365579233, -1.266666102082619, -1.2666665701811834, -1.2666666501783852, -1.266666663849013, 1.7111111111111112, -1.2888888888888888, 0.7333333333333334, 1.7333333333333334, -1.2666666666666666, -1.156118432816036, -0.13722703850420181, -0.24454695711826646, -1.262886668551491, -1.2660207094618743, -1.2665562801802954, -1.2666478029148842, -1.2666634430734263, -1.2666661157925088, -1.2666665725287545, -1.2666666505796051]\n","Episode 11:Total timesteps 40: [-1.3105482353831812, -3.3294396281688483, -3.33266794493162, -3.333219626284024, -3.333313902136412, -3.3333300127703946, -3.3333327658881946, -0.311111111111111, 0.688888888888889, 0.688888888888889, 0.688888888888889, -1.3111111110524951, -1.3111111110972224, -0.28888888888888886, 0.7111111111111111, -0.2666666666666666, -1.2666666666666666, -1.2666666666666666, -4.266666666666667, 1.7111111111111112, 1.7111111111111112, -0.28888888888888886, 0.7111111111111111, -1.2888888888888888, -0.2666666666666666, 1.7333333333333334, -1.2666666666666666, -1.2666666666666666, -1.2666666666666666, -1.2666666666666666, -1.2666666666666666, -1.2666666666666662, -0.2666666666666663, 1.8438815687165149, -0.24777527388099962, -1.263438349903895, -1.2661149853142626, -1.2665723908142783, -1.2666505560326842, -1.2666639135488666]\n","Episode 12:Total timesteps 11: [-1.1570430091974955, -2.2661204243912874, -2.2849953679717263, -2.2882235023917814, -2.2887751818588904, 0.7333333333333334, 1.7333333333333334, -1.2666663353456262, -1.1561183358776814, -0.24777525732008476, -1.9333333333333333]\n","Episode 13:Total timesteps 40: [-1.2438815687165148, -2.2627729615021814, -1.266001278264953, -1.266552959617357, -1.2666472354697458, -1.2666633461037282, -1.2666660992215282, 2.7111111111111112, 1.688888888888889, 0.688888888888889, -0.28888888888888886, -0.28888888888888886, 0.7111111111111111, 1.7111111111111112, -0.28888888888888886, -0.2666666666666666, 1.7333333333333334, 1.7333333333333334, -1.2666666666666666, -1.2666666666666666, -1.2666666666666666, -1.2666666666666666, -1.2666666666666662, -0.2666666666666663, -0.2666666666666663, -0.2666666666666663, -0.2666666666666663, -0.2666666666666663, -0.2666666666666663, -0.2666666666666663, -0.2666666666666663, -0.2666666666666663, -0.2666666666666663, -0.2666666666666663, -0.2666666666666663, -0.2666666666666663, -0.2666666666666663, -0.2666666666666663, -0.2666666666666663, -0.2666666666666663]\n","Episode 14:Total timesteps 12: [-0.15555555555555556, -1.266103790938737, -1.1744469483412225, -0.2693321077015085, 1.690362803935161, -3.3105632741171047, -0.28888888888888886, 0.7111111111111111, -2.1783379553379136, -0.1594487743109544, 2.8645141717095046, -1.9247994633619077]\n","Episode 15:Total timesteps 40: [-0.20000000000000007, -1.3105482353831812, -2.3294396281688483, -2.33266794493162, -2.333219626284024, -2.333313902136412, -2.3333300127703946, -2.3333327658881946, -2.3333332363636354, -2.333333316762353, -1.3333333305015476, 0.7772149025337668, -1.2038937050817893, -1.2006653883875815, 1.820621126746027, -1.2883620677043854, 0.7130961231914793, 0.688888888888889, 0.68898395157994, -3.311091887902278, 0.6666666666666666, 0.6666666666666666, -2.3333333333333335, -1.3333333191674472, -2.333333330528087, -2.3333333328500707, -2.3333333332507102, -2.3333333333192137, -2.3333333333309203, -2.333333333332921, 0.688888888888889, -3.311111111111111, -2.311111111111111, -2.311111111111111, -2.311111111111111, 0.6666666666666666, 0.6666666666666666, -2.3333333333333335, -2.3333333333333335, -2.3333333333333335]\n","Episode 16:Total timesteps 40: [-1.2438815687165148, -2.2627729615021814, -2.266001278264953, -2.266552959617357, -2.266647235469746, -2.266663346103728, -2.266666099221528, -2.2666665696969686, -2.266666650095686, -0.266666663834881, -0.2666666661827478, -0.26666666658397065, -0.2666666666525349, -0.26666666666425176, -0.26666666666625405, -0.2666666666665961, -0.2666666666666546, -0.2666666666666645, -0.2666666666666663, -0.2666666666666663, -0.2666666666666663, -0.2666666666666663, -0.2666666666666663, 0.7111111111111111, -0.28888888888888886, 0.7111111111111111, 0.7111111111111111, -1.2888888888888888, -1.2888888888888888, -0.311111111111111, 1.688888888888889, 1.688888888888889, 1.688888888888889, -0.311111111111111, -0.311111111111111, -0.311111111111111, -0.3111111111111108, -0.3111111111111108, -0.3111111111111108, -0.3111111111111108]\n","Episode 17:Total timesteps 6: [-1.266103790938737, -3.2849951837244036, -0.2666666666666666, 0.7111111111111111, 0.7111119717798654, -0.9333333333333333]\n","Episode 18:Total timesteps 40: [0.8666666666666667, -0.24388156871651467, -1.2627729615021814, -1.266001278264953, -1.266552959617357, -1.2666472354697458, -1.2666633461037282, -1.2666660992215282, -1.2666665696969686, -2.266666650095686, -0.266666663834881, -0.2666666661827478, -0.26666666658397065, -0.2666666666525349, -0.26666666666425176, -0.26666666666625405, -0.2666666666665961, 0.7111111111111111, -1.2888888888888888, 0.7111111111111111, 0.7111111111111111, -0.2666666666666666, 1.7333333333333334, -4.266666666666667, -1.2666666666666666, -1.2666666666666666, -1.2666666666666666, -1.2666666666666666, -1.2666666666666662, -0.2666666666666663, -0.2666666666666663, -0.2666666666666663, -0.2666666666666663, -0.2666666666666663, -0.2666666666666663, 0.7111111111111111, -0.28888888888888886, 0.7111111111111111, 0.7111111111111111, -1.2888888888888888]\n","Episode 19:Total timesteps 40: [2.9327704576054034, 1.9726526706793113, -0.13344462394292567, -0.041227354494347224, -0.025469970225943883, 2.9537666581708635, -1.155096498199732, -1.2844485904932577, -2.306554788046424, -2.3103324889757184, 0.7111111111111111, -2.178333221191079, 1.816867463233364, 1.9320982386674221, -1.1589999983380799, 1.8017191409412923, -1.1994632919840447, -1.3104546152337155, -2.329423615348362, -2.3326652083779416, -2.333219158637641, -2.3333138222211316, -2.3333299991138134, -2.333332763554446, -2.333333235964825, -2.3333333166942007, 0.688888888888889, -0.33333333333333337, -2.3333333333333335, -2.3333333333333335, -2.3333333333333335, -2.3333333333333335, 0.688888888888889, -2.311111111111111, -2.2005630306694752, -1.1816714835921966, -1.1784431661821593, -1.1778914848270983, -1.2883454443578803, -2.3072207265095646]\n","Episode 20:Total timesteps 3: [-1.1777777777777776, -1.0672295423945966, -2.9095426098241726]\n","Episode 21:Total timesteps 6: [-1.1777777777777776, -2.1777777777777776, -2.1777777777777776, -2.0672295423945966, -2.158886384992111, 0.0]\n","Episode 22:Total timesteps 26: [0.8666666666666667, -1.2438815687165148, -1.1522247261190004, -0.24710988547928636, -1.2633246428545855, -1.2660955541173418, -1.26656907025134, -1.2666499885875457, -1.2666638165791686, -1.2666661796202456, -1.2666665834361637, -1.2666666524435528, -0.26666666423610386, -0.2666666662513121, -0.2666666665956874, -0.2666666666545372, -0.2666666666645937, -0.26666666666631234, -0.2666666666666061, -1.156118431283475, -0.026678803114635552, 2.9719878197959346, -1.1335582914172457, 1.8689549054019614, -1.1327022839803598, 2.0444444444444443]\n","Episode 23:Total timesteps 40: [-1.288326013160959, -3.3072174059466257, 0.8001025126737838, -2.2921060112761347, 0.7124907338871383, 1.7333333333333334, -1.2665997176036092, -1.2666507457060776, -1.266663899875239, -1.2666661933886734, -1.2666665857843253, -1.266666652844779, -1.2666666643046685, -1.266666666263029, -1.2666666665976898, -1.2666666666548791, -1.2666666666646522, 1.7111111111111112, -4.288888888888889, -1.2888888888888888, 1.7333333333333334, 1.7111111111111112, -4.288888888888889, -1.1783407792278147, -0.1594492612477567, 2.8645143273930476, -0.2440118490358857, -1.262792576142998, -1.266004600723909, -1.1560052916919155, 2.8390851589132486, -0.26678216032147695, 1.7352824035167003, 0.7111111111111111, -1.288797106609333, -1.2888702144799602, -1.288885666757373, -1.2888883379520548, 2.688888888888889, 0.6666666666666666]\n","Episode 24:Total timesteps 11: [-1.288326013160959, -2.3072174059466257, 1.7111111111111112, 1.7333333333333334, -1.2666666666666666, 1.7111111111111112, -1.1783550467777273, 5.861307899673263, 2.84253697636131, 2.8652977583077712, 2.0508293364718435]\n","Episode 25:Total timesteps 40: [-1.3105482353831812, -2.3294396281688483, 1.688888888888889, 1.7111111111111112, 0.7111111111111111, 0.688888888888889, 0.688888888888889, 0.688888888888889, 0.6888889031253598, -1.31111110830288, -1.3111111106274298, -1.3111111110284175, -1.3111111110969795, -1.3111111111086964, -1.3111111111106983, -1.3111111111110407, -0.33333333333333337, -0.33333333333333337, -2.3333333333333335, -2.3333333333333335, -2.3333333333333335, -2.3333333333333335, -2.3333333333333335, -2.333333333333333, -2.333333333333333, -2.333333333333333, -2.333333333333333, -2.333333333333333, -2.333333333333333, -2.333333333333333, -2.333333333333333, -2.333333333333333, -0.311111111111111, -3.311111111111111, 0.688888888888889, 0.688888888888889, -0.28888888888888886, 0.7111111111111111, 0.7111111111111111, 0.7111111111111111]\n","Episode 26:Total timesteps 40: [2.977214902049848, -0.11444194054766632, -0.13010501657056173, -0.022233416597747913, -0.003799429312096536, -0.11119751315091231, -0.24009881748353912, -1.2621265338219483, -1.2658908113798648, -1.26653408212638, -1.2666440095286382, -1.2666627948283473, -1.2666660050150513, 1.7111111111111112, -1.2888888888888888, -1.2888888888888888, -1.2888888888888888, -1.2888888888165435, -2.2888888888726537, -2.2888888888860754, -2.288888888888408, -2.2888888888888066, -2.288888888888875, 0.7333333333333334, -4.266666666666667, -1.2666666666666666, -1.1561184328471779, 2.839066018473814, -0.26678546108151, -1.285109070332704, -1.2882429335386067, -2.2887785024213176, -2.288870025137296, -2.28888566529565, -2.288888338014731, -2.2888887947509766, 0.7333333333333334, -1.2666666666666666, -1.2666666666666666, 1.7111111111111112]\n","Episode 27:Total timesteps 40: [-2.1348207869752733, -0.13334476734494272, -0.2438816552680385, -1.2627729624175852, -1.2660012782743704, -1.2665529596174525, -1.2666472354697467, 1.7111111111111112, 1.7111111111111112, -2.2888888888888888, -2.288888874704557, 0.7333333333333334, 1.7111111111111112, 1.7111111111111112, -2.2888888888888888, -2.178340654771889, -1.269997496110975, -2.28566057212613, -2.2883372075364736, 0.7333333333333334, -1.2666666666666666, -1.2666641497648312, -1.266666198579105, -1.1561183509005506, -0.026678789375483625, -0.11510732660151335, -0.24076695860182973, -1.2622407112781344, -1.2659103229637862, -1.266537416426511, -1.2666445793213015, -1.2666628921992098, -1.156117786271405, -0.13722692827284266, -0.24454693828207663, -1.2628866653326143, -1.2660207089118058, -1.2665562800862955, -1.2666478028988206, -1.266663443070681]\n","Episode 28:Total timesteps 40: [-2.1348207869752733, 1.843205951665599, -1.2661181406232296, 0.690879817421883, -0.28888888888888886, 1.688888888888889, 0.6666666666666666, 0.6666666666666666, -2.333333046716775, -2.2227850028400606, -1.203893688601264, -1.2006653855699598, -1.310661941948572, -2.329459059283073, -2.3326712654804265, -2.222671958343566, -1.3144226063200306, -2.219553477195352, 1.8173954463973883, -1.2889133627508813, -2.307315166116632, -2.310462399832672, 0.6666666666666666, 0.6666666666666666, -2.3333303321819296, -2.3333327824965826, -2.3333332388178785, -2.222785081794615, -1.2038937024036676, -1.2006653879299223, -1.3106619423518673, -2.3294590593519917, -2.2221230301090222, -1.314328800943093, 0.6902684146786418, 0.6666666666666666, 0.6667429254612198, -2.333317317957177, -2.333330565666227, -2.3333328600598033]\n","Episode 29:Total timesteps 40: [-2.310548235383181, -2.3294396281688483, 1.688888888888889, 1.7111111111111112, 0.7111111111111111, -0.2666666666666666, 1.7333333333333334, -1.2666666666666666, -1.2666666525350552, -1.266666663859493, -1.2666666661829962, -1.2666666665839732, -1.2666666666525348, -1.2666666666642517, -1.266666666666254, -1.266666666666596, -1.2666666666666546, -1.2666666666666644, 1.7111111111111112, -0.28888888888888886, -0.311111111111111, 1.7111111111111112, 0.7111111111111111, 0.7111111111111111, -0.2666666666666666, -1.2666666666666666, -1.2666666666666666, -1.1561184328500014, -0.24777527389108212, -1.1528901145207815, -0.1366753571454148, -0.24445268126583963, -1.2628705579175086, -1.2660179563440743, -1.266555809704855, -1.2666477225161668, -1.2666634293342312, -1.1561178780614605, -0.1372269439586833, -0.023450470196239692]\n","Episode 30:Total timesteps 40: [0.8666666666666667, -0.24388156871651467, -1.2627729615021814, 1.7111111111111112, 1.7333333333333334, 1.7333341940020879, -1.266663537641314, -1.266666101158231, -1.2666665697165098, -1.2666666500958832, -1.266666663834883, -1.266666666182748, -1.2666666665839705, 1.7111111111111112, -4.288888888888889, -1.1783408084496672, -0.269997497105117, -1.2856605721363383, 1.7333333333333334, 1.7334046091624487, -1.2666507928324582, -1.2666639159428925, -1.1561179608238685, -0.24777519348238408, -1.2634383361647012, -1.2661149829663958, -1.2665723904130552, -1.26665055596412, -1.2666639135371498, -1.2666661961892238, -1.2666665862676072, 1.7111111111111112, 1.7333333333333334, 1.7333333333333334, -1.2666666666666666, -1.2666666666666666, -1.2666666666666666, 1.7111111111111112, -2.2888888888888888, -2.178340808447245]\n","Episode 31:Total timesteps 35: [-1.2438815687165148, -1.2627729615021814, -1.266001278264953, -1.266552959617357, -1.2666472354697458, 1.7111111111111112, 1.7333333333333334, 1.7333333333333334, -1.2666666666666666, -1.266666665771007, -1.266666666202283, -1.2666666665841677, 1.7111111111111112, -4.288888888888889, -2.2888888888888888, -2.2888888888888888, -2.2888888888888888, -1.2888888888888888, -1.2888888888888888, -1.2888888888888883, -1.2888888888888883, -0.2666666666666666, -1.1561337267927407, -0.2477753772054493, -1.2634383509657106, 1.7111111111111112, -1.2888176102153395, -2.288873015025725, -2.2888861381648224, 0.688888888888889, -1.2005780939702877, -0.07112327656222395, 2.9275429330606295, 1.9325481526155155, -3.0]\n","Episode 32:Total timesteps 40: [-1.3105482353831812, -2.3294396281688483, 0.688888888888889, -2.2004645155911895, -1.292200390946527, -2.30787947485257, -2.310558862324487, -2.311016738289135, -2.311094983906149, -2.3111083551615255, -2.311110640151752, -1.3111110306296974, -1.3111110973577844, -1.3111111087608296, 1.6666666666666665, -0.33333333333333337, -2.3333333333333335, 0.688888888888889, -1.311111111111111, -1.311111111111111, 2.7111111111111112, 0.7333333333333334, -1.1561369285717369, -0.1372271195228304, -0.2445469576365461, -1.2628866685568343, -1.266020709461929, -1.2665562801802963, -1.2666478029148842, -1.2666634430734263, -1.2666661157925088, -1.2666665725287545, 1.7111111111111112, 0.8216440537328498, -1.2699975989578967, -2.2856605731076516, -2.288337207533629, -2.288794613034266, 0.688888888888889, 1.688888888888889]\n","Episode 33:Total timesteps 40: [-2.1792652314197176, -1.2883426466135095, -2.307217590193949, -2.3104457246140035, 0.6666666666666666, -2.3333333333333335, 1.688888888888889, 1.7111111111111112, 4.688888888888889, 0.6666666666666666, 0.6666666666666666, 0.6666666666666666, 0.6666666666666666, -1.3333333333333335, -1.3333333333312063, -1.3333333333329236, -0.311111111111111, -4.311111111111111, -1.311111111111111, -1.311111111111111, -1.311111111111111, -1.311111111111111, -1.311111111111111, -1.311111111111111, -1.311111111111111, -1.311111111111111, -1.311111111111111, 1.6666666666666665, -4.333333333333333, 1.688888888888889, -1.311111111111111, -1.311111111111111, -1.311111111111111, -1.311111111111111, -1.311111111111111, -1.311111111111111, -1.311111111111111, 2.7111111111111112, -0.2666666666666666, 0.7111111111111111]\n","Episode 34:Total timesteps 40: [-2.310548235383181, -2.3294396281688483, -2.33266794493162, -0.311111111111111, 0.688888888888889, 0.68889197321087, -3.311110546054114, -3.3111110141655087, -0.28888888888888886, 1.7111111111111112, 1.7111111111111112, 1.7111111111111112, -0.28888888888888886, 0.688888888888889, 0.688888888888889, 0.688888888888889, 0.688888888888889, -0.33333333333333337, 3.688888888888889, 1.688888888888889, 1.688888888888889, 1.688888888888889, -0.311111111111111, -0.311111111111111, -0.311111111111111, -0.3111111111111108, -0.3111111111111108, -0.3111111111111108, -0.3111111111111108, 1.7111111111111112, -0.2666666666666666, 1.7333333333333334, 1.7333333333333334, 1.7333333333333334, -0.2666666666666666, -0.2666666666666666, -0.2666666666666666, -0.2666666666666663, -0.2666666666666663, 1.8438815687165149]\n","Episode 35:Total timesteps 40: [-2.266103790938737, -2.2849951837244036, 0.7333333333333334, -1.1560200711467448, -0.24775594650208266, -1.2634350304081252, -1.2661144178800425, -1.2665722938446908, -1.266650539461705, -1.2666639107170812, -1.266666195707307, -1.266666586185253, -1.2666666529133401, -1.2666666643163849, -1.266666666265031, -1.2666666665980317, -1.2666666666549378, -0.2666666666646623, 1.7111111111111112, -1.2888888888888888, 0.7333333333333334, 1.7333333333333334, -1.2666666666666666, -1.2666666666666666, -1.2666666666666666, -1.2666666666666666, -1.2666666666666666, -1.2666666666666662, 1.7111111111111112, 2.7333333333333334, 1.7333333333333334, -1.2666666666666666, 1.7111111111111112, -0.28888888888888886, -2.2888888888888888, -2.2888888888888888, 0.7333333333333334, -1.1561337237051816, -0.24777537718516773, 1.7124741227310074]\n","Episode 36:Total timesteps 11: [-1.3105482353831812, -2.218891392785667, -1.3137765521459528, -2.3299913095212523, 0.688888888888889, -2.200480618956502, -1.071106612404947, 1.9275466690492458, -1.067451360284962, 1.9541961256325227, -1.9777777777777779]\n","Episode 37:Total timesteps 40: [-2.266103790938737, 0.7353590351349295, -1.2660246074762829, -1.266553200664155, -1.2666472379085292, -1.2666633461283383, -1.2666660992217764, -1.2666665696969712, -1.266666650095686, -1.2666666638348811, -1.266666666182748, -1.2666666665839705, -1.2666666666525348, -1.2666666666642517, -1.266666666666254, -1.266666666666596, -1.2666666666666546, -0.2666666666666645, -0.2666666666666663, -0.2666666666666663, -0.2666666666666663, 1.7111111111111112, -1.2888888888888888, 0.7333333333333334, -1.2666666666666666, -1.2666666666666666, -1.2666666666666666, -1.156118431298946, -0.2477752738810991, -1.263438349903896, -1.2661149853142626, -1.2665723908142783, -1.2666505560326842, -1.2666639135488666, -1.2666661961912262, -1.2666665862679491, -1.266666652927472, -1.2666666643187998, -0.26666666626544366, -0.26666666659810245]\n","Episode 38:Total timesteps 40: [-1.1570430091974955, 2.865428173887821, -0.13334322533871923, -0.24388164422073944, -1.2627729623016206, -1.2660012782731784, -1.2665529596174405, -1.2666472354697462, -1.2666633461037282, -1.2666660992215282, -1.2666665696969686, -1.266666650095686, -1.2666666638348811, -1.266666666182748, 1.7111111111111112, -4.288888888888889, 0.7333333333333334, -1.2666666666666666, -1.2666666666666666, -1.2666666666666666, -1.1561184312989439, -0.13722703849788254, -0.2445469571182287, -1.15233843316831, -0.2471293166762073, -1.2633279634175238, 1.7111111111111112, 1.7333333333333334, -1.2666666666666666, -1.2666640109410525, -1.2666661820407845, -1.1561183481484787, -0.24777525967210023, -1.1528901120925665, -0.13667535673047249, -0.13390444581174987, -0.1334309297365429, -0.24389824679356498, -1.2627758115893255, -1.2660017653113136]\n","Episode 39:Total timesteps 36: [-2.1348207869752733, -0.022792871755729194, -0.0038937180440926644, -0.11121362380049471, -0.12955333521819423, -0.24323561151172235, -1.2626625750158107, -1.2659824145131706, -1.2665497360241167, -1.2666466845955875, -1.2666632519658156, -1.2666660831344667, -1.2666665669478792, -1.2666666496258991, -0.2666666637545999, -0.2666666661690287, -0.2666666665816262, 1.7111111111111112, -4.288888888888889, 0.688888888888889, -3.311111111111111, -2.311111111111111, -0.28888888888888886, -1.2888888888888888, 0.7333333333333334, -1.2666666666666666, -1.2666666666666666, -4.266666666666667, -1.2666666666666666, -1.1561184312836477, 3.8390658231385504, 3.819800453623861, -1.1779044980730489, -1.1777972737402402, 1.842954984724725, -0.9555555555555556]\n","Episode 40:Total timesteps 40: [-1.266103790938737, 1.7353590351349295, -1.2660246074762829, -1.266553200664155, -1.2666472379085292, -1.2666633461283383, -1.2666660992217764, -1.2666665696969712, -1.266666650095686, -0.266666663834881, 1.8438815692004336, -0.026678803031941256, -0.11510732893524833, -0.24076695900063771, -1.2622407113462857, -1.2659103229754325, -1.266537416428501, -1.2666445793216417, -1.266662892199268, -1.2666660216545962, -1.2666665564416926, -2.2666666478305157, -0.2666666634477902, -0.2666666661165986, -0.26666666657266636, -0.2666666666506031, 0.7111111111111111, 1.7333333333333334, -1.2666666666666666, -1.2666666666666666, 1.7111111111111112, -1.2888888888888888, 0.7333333333333334, -1.2666666666666666, -1.2666666666666666, -1.2666666666666666, -1.2666666666666666, -1.2666666666666666, -1.2666666666666666, -1.2666666666666662]\n","Episode 41:Total timesteps 40: [-2.1570430091974955, -1.2661204243912874, -1.2849953679717263, -1.2882235023917814, -1.2887751818588904, -1.2888694576921629, -1.2888855683259521, -1.2888883214437503, -1.2888887919191911, -1.2888888723179086, 1.7333333333333334, -1.1561337263090756, -0.24777537712275555, -1.2634383509515787, -1.266114985322711, -1.2665723908139754, -1.266650556032615, -1.2666639135488547, -1.1561179608080425, -0.24777519348228194, 1.7124713131062839, 0.7333333333333334, 1.7334090280006054, -1.2666507477061688, -1.2666639154761108, -1.1561179608188588, -0.2477751934820227, -1.2634383361646426, -1.266114982966386, -1.2665723904130535, -1.2666505559641195, -1.2666639135371498, -1.2666661961892238, -1.2666665862676072, -1.2666666529274133, -1.26666666431879, -0.2666666662654421, -0.26666666659810223, -0.26666666665494976, -0.26666666666466454]\n","Episode 42:Total timesteps 14: [-2.1792652314197176, -1.2883426466135095, -1.307217590193949, 1.7111111111111112, 0.7112017646624281, -0.311111111111111, -1.2005745465365023, -0.07112272202933623, -1.0490034410798992, -1.1557717587076808, -1.1740172080277378, 1.7991548245737259, 2.8000983411240012, -1.9525720051028306]\n","Episode 43:Total timesteps 40: [0.7999999999999999, -0.20000000000000007, -1.3105482353831812, -2.3294396281688483, -2.33266794493162, -2.333219626284024, -2.333313902136412, -2.2227817773872136, -1.314441373102528, -2.330104919600864, -2.332781635409949, -2.3332390546491593, 0.688888888888889, -2.311111111111111, -2.3111108767370827, -2.3111110330968003, -2.3111110973955857, -2.311111108763417, -2.3111111107098785, -1.3111111110425449, -0.31111111109939393, 1.7994371242740725, -0.1816714829419207, -1.288991401562614, 0.668578638397419, -3.3327106943009395, -2.3332231877506286, -2.3333144720188246, -2.333330109764688, -2.3333327824594234, -2.3333332391954236, -2.3333333172462716, -2.3333333305842436, -2.333333332863546, -2.3333333332530524, -2.3333333333196142, -2.333333333330989, 0.688888888888889, -4.311111111111111, -1.311111111111111]\n","Episode 44:Total timesteps 40: [-1.3105482353831812, 0.6909145906904851, -2.310469051920727, -0.28888888888888886, 1.7111111111111112, -1.2888858093657367, 1.688888888888889, 0.688888888888889, 1.688888888888889, 1.688888889338899, 0.7111111111111111, 3.688888888888889, 1.688888888888889, 1.688888888888889, 0.7111111111111111, -0.17835592131185685, 1.86126794521171, -1.2445634065441764, -1.2628868498946821, -1.2660207113347428, -1.15600804480956, -0.13720817474608793, -0.13399549814180656, -0.24399472489166607, -1.2627922985611901, -1.26600458274083, -1.266553524313406, -1.2666473319696565, -1.2666633625944277, -1.2666661020395944, 1.7111111111111112, 1.7111111111111112, -2.2888888888888888, 0.7333333333333334, 1.7333333333333334, -1.2666666666666666, -1.2666666666666666, -1.2666666666666666, -1.2666666666666666, -1.2666666666666573]\n","Episode 45:Total timesteps 40: [-1.2438815687165148, -1.2627729615021814, -1.266001278264953, -1.266552959617357, -1.2666472354697458, -1.2666633461037282, -1.2666660992215282, -1.2666665696969686, -2.266666650095686, -0.266666663834881, -0.2666666661827478, -0.26666666658397065, -0.2666666666525349, -0.26666666666425176, -0.26666666666625405, -0.2666666666665961, -0.2666666666666546, -0.2666666666666645, -0.2666666666666663, -0.2666666666666663, -0.2666666666666663, -0.2666666666666663, -0.2666666666666663, -0.2666666666666663, -0.2666666666666663, -0.2666666666666663, -0.2666666666666663, -0.2666666666666663, -0.2666666666666663, 0.7111111111111111, -1.2888888888888888, -0.2666666666666666, 1.7333333333333334, -1.2666666666666666, -1.2666666666666666, -1.2666666666666666, -1.2666666666666666, -1.2666666666666666, -1.2666666666666662, -0.2666666666666663]\n","Episode 46:Total timesteps 40: [-1.2438815687165148, 1.8477752738809996, -1.1365616500961049, -1.1338850146857373, -1.1334276091857216, -1.2438976793504972, -2.2627757146199814, -2.266001748740394, -2.2665530400160745, -2.2666472492089405, -2.266663348451595, -2.266666099622751, -2.266666569765533, -2.266666650107403, -0.2666666638368834, -0.26666666618309, -0.26666666658402904, -0.2666666666525449, -0.2666666666642534, -0.2666666666662544, -0.26666666666659633, -0.26666666666665473, 1.8438815687165167, -1.2477752738809995, -2.263438349903895, -2.2661149853142626, 0.7111111111111111, 1.7111111111111112, -0.311111111111111, 1.688888888888889, 1.688888888888889, 1.6888889001935201, -0.3111111087878081, 0.7111111111111111, 3.688888888888889, 1.688888888888889, 0.7111111111111111, 0.7111111111111111, -0.28888888888888886, 0.7333333333333334]\n","Episode 47:Total timesteps 12: [-2.310548235383181, -3.3294396281688483, -3.33266794493162, 0.7773286090991576, -2.0933260385843826, -2.071222439669927, -1.0674451946725512, -2.1773479433263807, 1.824603817198744, 1.8433421699239951, 2.8445443211181938, -1.9555555555555555]\n","Episode 48:Total timesteps 40: [-2.1348207869752733, -0.24389820216906521, -1.2627731457495042, -1.2660012801695588, -1.2665529596366683, -1.2666472354699407, -1.26666334610373, -1.2666660992215282, -1.2666665696969686, 1.7111111111111112, -1.2888888888888888, 1.688888888888889, -0.311111111111111, 1.688888888888889, -2.2888888888888888, 0.7111111111111111, -2.2888888888888888, -2.2888888888888888, -2.1783406535214476, 1.8612880235545428, -0.2445632406396815, -1.2628868481294035, -1.2660207113165796, -1.2665562801990973, -1.2666478029150738, -1.266663443073428, -1.2666661157925088, -1.2666665725287545, -1.2666666505796051, -1.2666666639175772, -1.2666666661968797, -1.2666666665863855, -1.1561184312697663, -0.13722703849547413, -0.13399872173464622, -0.13344704038257438, -0.24390099991342395, 1.7131334916679828, -1.2882473968214234, -1.2887755198518969]\n","Episode 49:Total timesteps 5: [-2.0450073201723744, -1.0261159273867073, -1.1334358460071172, -1.1517755574403798, 1.0222222222222221]\n","Episode 50:Total timesteps 40: [-1.288326013160959, 0.6686923684682627, -3.3326912741429497, -3.333219867330822, -0.311111111111111, 0.688888888888889, 0.7111111111111111, 0.7111111111111111, -2.2888888888888888, -2.2888888884915777, -2.1783406530378793, -1.2699974960206295, -1.2856605721119867, -1.2883372075340698, -1.2887946130360879, 1.7333333333333334, -1.2666666666666666, -1.2666664323067676, -2.2666665886547706, -2.266666652951554, -0.26666666431904285, -0.2666666662654462, -0.26666666659810245, -0.26666666665494976, -0.26666666666466454, 0.7111111111111111, -1.2888888888888888, -2.2888888888888888, -2.2888888888888888, -2.2888888888888888, -2.2888888888888888, 0.7333333333333334, -4.266666666666667, -1.2666666666666666, 1.7333333333333334, -0.2666666666666666, -0.2666666666666666, -0.2666666666666666, -0.2666666666666663, 0.7111111111111111]\n","Episode 51:Total timesteps 40: [2.977214902049848, -0.11444194054766632, -0.24065325195374287, 1.7136886154176678, 1.7333333333333334, -1.266555435956806, -1.2666446741924804, -1.266662877568335, -1.2666660188423862, -1.266666555957971, -1.2666666477478215, -1.266666663433658, -0.26666666611418355, -0.2666666665722538, 1.8438815687326486, -0.2477752738782426, -1.2634383499034239, -1.2661149853141822, -1.2665723908142645, -1.2666505560326815, -1.2666639135488662, -1.2666661961912258, -1.2666665862679491, -2.266666652927472, -0.26666666431879993, -0.26666666626544366, -0.26666666659810245, -0.26666666665494976, -0.26666666666466454, -0.26666666666632455, 1.843881568716573, -0.24777527388098974, -1.2634383499038933, 1.7111111111111112, 1.7333333333333334, -1.2666666666666666, -1.2666641050774765, -1.2666661981278295, -1.266666586287489, -1.2666666529276687]\n","Episode 52:Total timesteps 40: [-2.266103790938737, 0.7353590351349295, -2.266024607476283, -1.266553200664155, -1.2666472379085292, -1.2666633461283383, -1.2666660992217764, -1.2666665696969712, -1.266666650095686, -0.266666663834881, -0.2666666661827478, -0.26666666658397065, -0.2666666666525349, -0.26666666666425176, -0.26666666666625405, 1.843881568716585, -0.24777527388098786, -1.2634383499038933, -1.2661149853142621, -1.2665723908142783, -1.2666505560326842, -1.2666639135488666, -1.2666661961912262, -1.156118350884768, -0.1372270247586237, -0.1339987193871801, -0.24399527536460142, -1.2627923926305384, -1.266004598816175, -1.2665535270604935, -1.2666473324391014, -1.2666633626746502, -1.2666661020533039, -1.266666570180886, -2.266666650178382, -0.2666666638490126, -0.26666666618516277, -0.2666666665843834, -0.2666666666526055, -0.26666666666426364]\n","Episode 53:Total timesteps 40: [-2.1348207869752733, 2.843205951665599, -0.15556544756094148, -0.2661038664429616, -1.2849951845238428, -1.2882235004954006, -1.2887751818396627, -1.2888694576919688, -1.2888855683259504, -1.2888883214437503, -1.2888887919191911, 1.7333333333333334, -1.2666666666666666, -1.2666666666666666, -1.2666666666666666, -1.2666666666666666, -1.2666666666644946, -1.2666666666662563, -1.266666666666596, -1.2666666666666546, 1.7111111111111112, -4.288888888888889, -1.2888888888888888, 0.7333333333333334, -1.2666666666666666, -1.2666666666666666, -1.2666666666666666, -1.2666666666666666, 1.7111111111111112, -1.2888888888888888, -2.2888888888888888, 0.7333333333333334, -1.2666666666666666, -1.2666666666666666, -1.2666666666666666, -1.2666666666666666, -1.156118431283644, -0.13722703849781903, -0.1339987217350469, -0.022898804999461397]\n","Episode 54:Total timesteps 6: [-2.0894517646168187, -1.0705603718311516, -1.06733205506838, -1.066780373715976, 1.9543018468103859, -2.8649797808181017]\n","Episode 55:Total timesteps 40: [-2.266103790938737, -1.2849951837244036, -1.2882235004871756, -1.2887751818395792, 1.7333333333333334, -1.2666666666666666, -1.2666663353413394, -2.2666665720838353, -2.2666666501197685, -0.26666666383512394, -0.26666666618275014, -0.26666666658397065, -0.2666666666525349, -0.26666666666425176, 0.7111111111111111, 1.7333333333333334, 1.7333333333333334, 1.7333333333333334, 1.7333333333333334, 0.7111111111111111, -1.2888888888888888, -4.288888888888889, -1.2888888888888888, -1.2888888888888888, 1.7333333333333334, -1.2666666666666666, -1.2666666666666666, 1.7333333333333334, -0.2666666666666666, -0.2666666666666666, -0.2666666666666666, -0.2666666666666663, -0.2666666666666663, 0.7111111111111111, 1.7333333333333334, 1.7333333333333334, 1.7333333333333334, 1.7333333333333334, -0.2666666666666666, -0.2666666666666666]\n","Episode 56:Total timesteps 40: [-0.20000000000000007, -0.20000000000000007, -1.3105482353831812, 0.6909145906904851, -2.310469051920727, -2.3109976451086, -2.2005434461290814, -1.292216397772795, -2.307882226903306, -2.31055933278901, -2.311016818687742, -2.311094997645343, 0.6666666666666666, 0.6666666666666666, -2.3333333333333335, 0.688888888888889, -1.311111111111111, -1.311111111111111, -1.311111111111111, -1.311111111111111, -1.311111111109351, -1.3111111111107712, -1.3111111111110527, -1.3111111111111011, 1.7111111111111112, 0.688888888888889, 1.6666666666666665, -1.3333333333333335, -2.2227852818623486, -1.2038937059355552, -1.311213623789759, -2.3295533352182076, -2.332687376128541, 0.688888888888889, -1.311111111111111, -1.200559807174836, 2.839064400629356, -1.2667853847848072, -2.285109054435409, 0.7333333333333334]\n","Episode 57:Total timesteps 40: [-2.1792652314197176, 1.8426842960918286, -0.15556864593923436, -0.15555562080974472, -0.1555555558464431, -0.2661037909406474, -1.2849951837244236, -1.2882235004871756, 1.688888888888889, -2.2005587488404585, -1.1816682297790195, -1.0678943635296396, -1.0484517596887053, -1.0451292474720986, -0.15510970460808837, -1.2844523061546145, -2.306555434994853, -2.3103325996620754, -2.310978072663949, 0.6666666666666666, 0.6666666666666666, -2.333332905540593, -2.2227849860584774, -1.31444192116951, -2.3301050132574455, -2.33278165141474, -2.3332390573841897, -2.3333172226828163, -2.333330580212708, -2.33333286285741, -2.3333332529345334, -2.333333319594124, -2.333333330985464, 0.688888888888889, -3.311111111111111, -2.311111111111111, 0.7111111111111111, -1.2888888888888888, -1.2888888888888888, -1.2888888888888888]\n","Episode 58:Total timesteps 40: [-1.3105482353831812, 0.6909145906904851, -3.310469051920727, -3.3109976451086, -3.311091682352974, -0.28888888888888886, 1.8216446150483883, -0.1594492311078901, -0.2667691632010456, 1.7352451250364451, -1.2660440291966912, 1.7111111111111112, 1.7111111111111112, 1.7333333333333334, -1.2666666666666666, -1.2666666666666666, -1.2666666529192723, -1.2666666639411814, -1.2666666661971173, -1.2666666665863882, -1.1561184312697663, -0.13722703849547413, -0.24454695711782737, -1.2628866685514226, -1.2660207094618623, -1.2665562801802936, -1.2666478029148838, -1.2666634430734263, -1.2666661157925088, -1.2666665725287545, -2.266666650579605, -0.2666666639175771, -0.26666666619687973, -0.2666666665863856, -0.2666666666529477, -0.26666666666432226, -0.26666666666626604, -0.2666666666665982, -0.26666666666665495, -0.26666666666666483]\n","Episode 59:Total timesteps 40: [0.7999999999999999, -0.20000000000000007, -1.3105482353831812, -2.3294396281688483, -2.33266794493162, 1.7773286090991576, 2.8168630158579258, -1.289004366126985, -0.2870132563678002, -2.2882665671137756, -2.2887787309682706, -2.2888700247853717, 0.7333333333333334, 1.7333333333333334, -1.2666666666666666, 1.7111111111111112, 0.7111111111111111, 0.7111111111111111, -0.2666666666666666, -1.2666666666666666, -1.2666666666666666, -1.2666666666666666, 1.7111111111111112, 0.7111111111111111, -0.28888888888888886, -0.311111111111111, 1.688888888888889, 0.6666666666666666, 0.6666666666666666, -2.3333333333333335, 0.688888888888889, 2.7111111111111112, 0.7333333333333334, 1.7333333333333334, -1.15611862192686, -0.24777527511313158, -1.2634383499164779, -1.2661149853143914, -1.2665723908142796, -1.2666505560326842]\n","Episode 60:Total timesteps 40: [-1.288326013160959, -2.3072174059466257, -2.1998974873262163, -1.2921060112761347, -2.197315127768237, 1.7951759781692256, -1.3111351142636716, -2.329537307860765, -2.3326846083016033, 0.688888888888889, -2.311111111111111, 1.7111111111111112, 0.7333333333333334, 1.7333333333333334, 1.7333333333333334, 1.7333333333333334, -0.26666666622401936, 0.7111111111111111, 1.7111111111111112, 1.7111111111111112, 0.7111111111111111, -1.2888888888888888, -0.2666666666666666, 1.7333333333333334, 0.7111111111111111, 1.7111111111111112, 0.7111111111111111, -0.311111111111111, 1.688888888888889, 1.6666666666666665, -1.3333333333333335, -1.3333333333333335, -4.333333333333333, 1.688888888888889, -1.311111111111111, -4.311111111111111, -1.311111111111111, -1.311111111111111, -1.311111111111111, -1.311111111111111]\n","Episode 61:Total timesteps 17: [0.8666666666666667, -1.2438815687165148, -2.2627729615021814, -2.266001278264953, -2.266552959617357, -2.266647235469746, -2.266663346103728, -2.266666099221528, -2.2666665696969686, -2.266666650095686, -0.266666663834881, -0.2666666661827478, 1.8438815687992105, -1.1372270384836867, -1.244546957115813, -2.2628866685510785, -2.9333333333333336]\n","Episode 62:Total timesteps 35: [-1.2438815687165148, -2.2627729615021814, -2.266001278264953, -2.266552959617357, 1.7111111111111112, 0.688888888888889, 3.7111111111111112, -0.311111111111111, 0.688888888888889, -0.33333333333333337, 0.6666666666666666, -2.3333333333333335, -3.3333333333333335, -2.3333333333333335, -2.333333333333168, -2.333333333333265, -2.3333333333333215, -2.22278509795015, -1.203893705164485, -1.2006653884017133, -1.3106619424324908, -2.2189108239825877, -1.3137798727088916, -2.2194436415832093, -1.3138709249680391, -2.3300074367262154, -2.332764976733594, -2.333236207877366, -2.3333167357356257, -2.333330496999162, -2.333332848637194, -2.3333332505044657, -2.333333319178854, 1.688888888888889, -0.9555555555555556]\n","Episode 63:Total timesteps 5: [-1.2438815687165148, -2.2627729615021814, -2.266001278264953, 1.8439952757658244, -1.9333333333333333]\n","Episode 64:Total timesteps 7: [-1.1333333333333333, -1.1333333333333333, -1.1333333333333333, -1.1333333333333333, 1.8429569908025045, 2.844433010432835, 1.0666666666666667]\n","Episode 65:Total timesteps 40: [0.8666666666666667, -1.2438815687165148, -2.2627729615021814, 1.7111111111111112, 0.688888888888889, 1.688888888888889, 1.6888919238029638, -2.31111054655299, -3.3111110141705415, -3.3111110945404243, -1.3111111082793285, -1.3111111106271922, -1.3111111110284153, -1.3111111110969795, -0.33333333333333337, -0.33333333333333337, 0.6666666666666666, 0.6666666666666666, -1.3333333333333335, -1.3333333333333335, -1.3333333333333335, -1.333333333333333, -1.333333333333333, -1.333333333333333, -1.333333333333333, -1.333333333333333, -1.333333333333333, -1.333333333333333, -1.333333333333333, -1.333333333333333, -1.333333333333333, -1.333333333333333, -1.333333333333333, -1.333333333333333, -1.333333333333333, -1.333333333333333, -1.333333333333333, -1.333333333333333, -1.333333333333333, -1.333333333333333]\n","Episode 66:Total timesteps 3: [-1.1333333333333333, -1.1333333333333333, 1.0444444444444445]\n","Episode 67:Total timesteps 40: [-1.2000000000000002, 0.8207347685802825, 1.8222107882106129, -1.2883260997124828, -2.3072174068620295, -2.310445722718815, 0.7111111111111111, 1.7111111111111112, 1.711114195430091, 0.7333333333333334, 1.7333333333333334, -1.2666666666666666, -1.2666666662262847, -1.1561184308153725, -0.13722703841518846, -0.24454695710409702, -1.262886668549076, -1.2660207094614617, -1.2665562801802253, -1.2666478029148718, -1.266663443073424, -1.2666661157925083, 1.7111111111111112, 1.7333333333333334, 1.7333333333333334, -1.2666666666666666, -1.1561184324717728, -0.13722703848939355, -0.244546957115917, -1.2628866685510909, -1.2660207094618054, -1.2665562801802839, 1.7111111111111112, -1.2888888888888888, 1.7111114258661875, -2.2888887971378353, 0.7333333333333334, 1.7333333333333334, -4.266666666666667, -1.2666666666666666]\n","Episode 68:Total timesteps 40: [-1.2438815687165148, -1.2627729615021814, -1.266001278264953, -1.1560047242341756, -0.13720760730089732, -0.1339954011721084, -0.13344647293750445, -0.24390090294373767, -1.2627762654941392, -1.266001842878306, -1.2665530561031364, -1.2666472519580299, 1.7111111111111112, 1.7333333333333334, -1.2666666666666666, -1.2666666666666666, -1.1561184297226728, -0.13722703801960423, -0.24454695703563578, -1.1523384331541902, -0.0260328459074316, 3.9720981162012627, 3.953381927080197, -1.1551323995149878, -1.2844545898163013, -2.306555812292141, -2.310332663996931, 0.7111111111111111, 1.7111111111111112, -1.2888852403790652, -1.2888882274153213, 1.688888888888889, 0.7111111111111111, 1.7111111111111112, 1.688888888888889, -2.311111111111111, -3.311111111111111, 0.7111111111111111, -1.2888888888888888, 1.7333333333333334]\n","Episode 69:Total timesteps 2: [-1.1792652314197176, -1.8393577200874809]\n","Episode 70:Total timesteps 3: [-1.266103790938737, -0.2646409648650705, -2.9333333333333336]\n","Episode 71:Total timesteps 19: [-2.266103790938737, 0.6909145906904851, 0.8000869196709545, 4.794714595209795, 1.799342757627401, -1.2001104426352418, -1.2000188640017617, -1.310551458978063, -2.329440179043023, -2.3326680390695325, -2.3332196423710854, -2.3333139048855016, -2.333330013240182, -2.2227845305852947, -1.203893608208506, -1.2006653718330775, -0.3106619396011059, -1.3294590588819188, -1.8887896966953592]\n","Episode 72:Total timesteps 12: [-1.266103790938737, -2.2849951837244036, -2.2882235004871756, 0.7333333333333334, 1.7333333333333334, -1.2666635823446857, -1.2666661016096699, -1.2666665697210644, -1.2666666500959294, -1.2666666638348834, -1.1561184307995664, 2.0444444444444443]\n","Episode 73:Total timesteps 40: [-1.1570430091974955, 1.844433010432835, -0.26610387749026065, -1.2849951846398073, -1.288223500496593, 1.7333333333333334, 1.7333333333333334, -1.2666635823476868, -1.2666661016097, -1.2666665697210644, -1.2666666500959294, -1.2666666638348834, -1.266666666182748, -0.26666666658397065, -0.2666666666525349, -0.26666666666425176, 1.8438815687169274, -0.24777527388092935, -1.263438349903883, -1.2661149853142608, -1.2665723908142779, -1.2666505560326842, -1.2666639135488666, -1.2666661961912262, -1.2666665862679491, -2.266666652927472, -0.26666666431879993, -0.26666666626544366, -0.26666666659810245, -0.26666666665494976, -0.26666666666466454, -0.26666666666632455, -0.2666666666666083, -0.26666666666665684, -0.26666666666666494, -0.2666666666666663, -0.2666666666666663, -0.2666666666666663, -0.2666666666666663, -0.2666666666666663]\n","Episode 74:Total timesteps 40: [-1.3105482353831812, -3.3294396281688483, -3.33266794493162, 0.7773286090991576, -2.3144225093507456, -3.330101696007623, 0.688888888888889, 0.7111111111111111, 0.7111111111111111, 0.7111135814555718, -0.2666666666666666, 1.7333333333333334, -1.2666666666666666, -1.2666666666666666, -1.2666666662891641, -1.2666666665982755, -1.2666666666549404, -1.2666666666646624, -0.2666666666663241, -0.2666666666666081, -0.2666666666666567, -0.26666666666666494, -0.2666666666666663, -0.2666666666666663, -0.2666666666666663, -0.2666666666666663, -0.2666666666666663, -0.2666666666666663, 1.8438815687165149, -0.13722703849781848, -0.24454695711822827, -1.262886668551491, -1.2660207094618743, -1.2665562801802954, -1.2666478029148842, -1.1561152076902448, -0.24777472300684178, -1.263438255765983, -1.2661149692272007, -1.2665723880651885]\n","Episode 75:Total timesteps 40: [-2.1792652314197176, -1.1777892117893871, -1.1777778352366215, 1.7985137846576715, -2.3105648583539464, -2.3294398123040385, -2.3326679468350706, -2.333219626303323, -2.333313902136607, 0.688888888888889, -2.311111111111111, -2.2005629337052044, -1.2922197027564475, -2.307882791526787, -2.310559429274893, -2.3110168351760274, 0.7111111111111111, 1.7111111111111112, 1.7111113454713895, -2.288888810876923, -2.2888888751737637, -0.288888886541263, -0.28888888848766825, -0.2888888888203245, 0.7333333333333334, 1.7111111111111112, 1.7111111111111112, 1.7111111111111112, 0.7333333333333334, -1.2666666666666666, 1.7333333333333334, 0.7111111111111111, 1.7333333333333334, -1.2666666666666666, 1.7333333333333334, 1.7333333333333334, -0.2666666666666666, 0.7111111111111111, 1.7111111111111112, 1.7111111111111112]\n","Episode 76:Total timesteps 40: [-2.266103790938737, -2.2849951837244036, 0.7333333333333334, -1.2665759712930984, -1.1560991556075009, -0.24777195432407328, -1.2634377824690315, -1.2661148883446698, -1.2665723742432986, -1.2666505532008987, -1.266663913064948, -1.2666661961085302, -1.2666665862538173, -1.266666652925057, -1.2666666643183873, -1.2666666662653734, -1.2666666665980904, -0.26666666665494765, -0.2666666666646639, 1.7111111111111112, -1.2888888888888888, -2.2888888888888888, -2.2888888888888888, -2.1783406535214818, -1.2699974961033234, -2.2856605721261185, -2.2883372075364847, -2.2887946130365004, -2.178324542871725, 1.8612907944493076, -0.24456277025246764, -1.2628867677322888, -1.2660206975774022, -1.266556277851231, -1.2666478025138512, -1.2666634430048638, -1.266666115780792, -1.266666572526752, -1.2666666505792628, -1.2666666639175186]\n","Episode 77:Total timesteps 32: [0.8666666666666667, -0.24388156871651467, -1.2627729615021814, 1.7111111111111112, -1.2887981935153205, -1.2888696946405669, -1.1783373345123827, 2.861288808105049, -0.24456314193808615, -1.2628868315401536, -1.2660207084846062, -1.2665562797151768, -1.2666478028323778, -1.2666634430592962, -1.2666661157900938, -1.2666665725283415, -1.2666666505795345, -1.2666666639175652, -1.2666666661968775, -1.266666666586385, 1.7111111111111112, -1.2666666666666666, -1.2666666666666666, -1.2666666666666666, -1.156118432552042, -0.026678803117970662, -0.11510732894938502, 2.846070010355761, 2.9555169926448963, -0.1365732291470868, -0.26285993111824546, 1.0222222222222221]\n","Episode 78:Total timesteps 3: [-2.1792652314197176, 0.7987615072211544, -2.7561251808526834]\n","Episode 79:Total timesteps 40: [-0.20000000000000007, -0.20000000000000007, -2.310548235383181, -3.3294396281688483, -3.33266794493162, -3.333219626284024, -3.333313902136412, -3.3333300127703946, -3.3333327658881946, -3.3333332363636354, -3.333333316762353, -1.3333333305015476, -1.3333333328494144, -1.3333333332506374, -1.3333333333192017, -1.3333333333309185, -1.3333333333329205, -1.3333333333332629, -1.3333333333333215, -1.3333333333333313, -0.311111111111111, -0.311111111111111, 1.688888888888889, 1.688888888888889, -0.311111111111111, -0.311111111111111, -0.311111111111111, -0.3111111111111108, -0.3111111111111108, -0.3111111111111108, 0.7111111111111111, -1.2888888888888888, 0.7111111111111111, -0.311111111111111, 1.688888888888889, 1.688888888888889, 1.688888888888889, 0.6666666666666666, 3.688888888888889, 1.688888888888889]\n","Episode 80:Total timesteps 40: [1.9549926798276256, -0.13666416276988846, -1.2628754741759654, -2.2844435023719996, 1.8224190107483946, 5.861417766174858, -1.2445410679710638, -1.2628830572461687, -1.2660200634743806, -1.2665561694902219, -1.266647783996227, -1.2666634398404195, 2.7111111111111112, 2.688888888888889, 0.688888888888889, 0.6666666666666666, 0.6666666666666666, -2.3333333333333335, -3.3333333333333335, -2.3333333333333335, -2.3333333333331807, -2.3333333333332673, -2.2227850979501405, -1.3144419405476646, -2.3301050165705615, -2.3327816519809295, -2.3332390574809447, -2.333317222699351, -2.3333305802155335, -2.3333328628578927, -2.3333332529346156, -2.3333333195941384, -1.3333333309854667, -1.3333333329321104, -1.3333333332647692, -2.222785097938435, -1.3144419405456644, -2.3301050165702195, -2.332781651980871, 0.688888888888889]\n","Episode 81:Total timesteps 40: [-1.266103790938737, -1.2849951837244036, 0.688888888888889, 0.688979584262457, -3.311091916862789, -0.28888888888888886, 0.7111111111111111, 1.7333333333333334, 1.7333333333333334, -1.2666666666666666, -1.2666666666666666, -1.2666666666085336, -1.2666666666527826, -1.2666666666642543, -1.266666666666254, -0.2666666666665961, -0.2666666666666546, -0.2666666666666645, -0.2666666666666663, -0.2666666666666663, -0.2666666666666663, -0.2666666666666663, -0.2666666666666663, -0.2666666666666663, -0.2666666666666663, -0.2666666666666663, -0.2666666666666663, 1.8438815687165149, -0.13722703849781848, -0.24454695711822827, -1.262886668551491, -1.2660207094618743, -1.2665562801802954, 1.7111111111111112, 3.7333333333333334, 1.7333333333333334, -1.2666666666666666, -1.2666666525157448, -1.2666666639371127, -1.266666666197077]\n","Episode 82:Total timesteps 19: [-1.2438815687165148, -2.2627729615021814, 1.844546957118228, -1.24766156683169, -2.263418918706974, -2.266111664751324, -2.2665718233691394, -2.266650459062986, -2.266663896977886, 1.7111111111111112, 1.688888888888889, 0.688888888888889, 0.688888888888889, -0.28888888888888886, 1.7111111111111112, 1.7111111111111112, 1.7111111111111112, -0.28888888888888886, 0.022222222222222216]\n","Episode 83:Total timesteps 13: [-2.1348207869752733, 2.866655232655057, -0.022785135287955782, -0.0038937052076825074, -0.11121362378492206, -0.2401015706013392, -1.262127004297389, -1.2658908917785823, -1.2665340958655746, -1.266644011876505, -1.26666279522957, -1.2666660050836156, 1.0444444444444445]\n","Episode 84:Total timesteps 40: [-1.1570430091974955, 1.8209837294433764, -1.1777876697831635, -1.1777778279439381, -0.1777777780026243, 2.798512470304827, 1.8209837338908796, -1.0672362919471339, 1.9726451198722725, -1.1334446459730319, -1.2623238656759028, 1.691563125148527, 2.6666666666666665, -2.3332286952756975, -3.333310965650389, -3.3333294647984255, -0.311111111111111, -1.311111111111111, -1.311111111111111, -1.3111111101956205, -1.3111111105709856, -1.311111111014939, -1.3111111110946374, -1.2005628757251143, -0.29221971832496296, 1.668026854923017, -1.3328049164465114, -2.3332392976889267, 0.688888888888889, -1.311111111111111, 1.7111111111111112, -2.2888888888888888, -2.2888888888888888, -2.2888888888888888, -2.1783406531205753, 1.8612880234052716, -1.2445632406297564, -1.2628868481274202, -1.2660207113162376, -1.266556280199039]\n","Episode 85:Total timesteps 40: [-0.15555555555555556, 1.8651792130247267, -0.24389820216906521, 1.7131738126960565, -1.288246413696637, -1.2887754186341889, -1.2888694600877795, -1.288885568350127, -1.2888883214439941, -1.2888887919191934, -1.2888888723179086, 0.7333333333333334, -1.2888888888888888, 1.7111111111111112, 1.688888888888889, -0.311111111111111, 0.688888888888889, -0.28888888888888886, 0.7333333333333334, -1.2666666666666666, -1.2666666666666666, -1.2666666666666666, -1.2666666666666666, -1.2666666666666666, -1.2666666666666666, -1.2666666666666662, -1.2666666666666662, -1.2666666666666662, -1.2666666666666662, 1.7111111111111112, -4.288888888888889, -2.2888888888888888, 0.7333333333333334, -1.2666666666666666, -1.2666666666666666, -1.2666666666666666, -1.2666666666666666, -1.2666666666666666, -1.2666666666666666, -1.2666666666666662]\n","Episode 86:Total timesteps 6: [-1.2438815687165148, -1.2627729615021814, 1.7111111111111112, 0.7112018064846793, -2.178321377829723, -1.9555555555555555]\n","Episode 87:Total timesteps 40: [-1.1570430091974955, -2.2661204243912874, -2.2849953679717263, -2.2882235023917814, 0.7333333333333334, 1.7333333333333334, 1.7333364176126205, -1.2666661016101006, -2.2666665697210684, -2.2666666500959294, -0.26666666383488347, -0.2666666661827478, -0.26666666658397065, -0.2666666666525349, -0.26666666666425176, 0.7111111111111111, 1.7333333333333334, 1.7333333333333334, 1.7333333333333334, 1.7333333333333334, -0.2666666666666666, 0.7111111111111111, 0.7111111111111111, 0.7111111111111111, 0.7333333333333334, 1.7333333333333334, 1.7333333333333334, 1.7111111111111112, -0.28888888888888886, -0.2666666666666666, 1.7333333333333334, 1.7333333333333334, 1.7333333333333334, -0.2666666666666666, -0.2666666666666666, -0.2666666666666666, -0.2666666666666663, -0.2666666666666663, -0.2666666666666663, -0.2666666666666663]\n","Episode 88:Total timesteps 40: [-1.3105482353831812, -2.3294396281688483, -2.33266794493162, 0.688888888888889, 1.6666666666666665, 0.6666666666666666, -2.33333295738231, -2.3333332382998577, -2.3333333167818893, -2.3333333305017447, -2.3333333328494166, -2.3333333332506374, -2.3333333333192017, -2.3333333333309185, -2.3333333333329205, -2.333333333333263, -2.3333333333333215, -2.3333333333333313, -2.333333333333333, 0.688888888888889, -4.311111111111111, 1.688888888888889, 1.688888888888889, 1.7111111111111112, 0.7333333333333334, 4.711111111111111, 0.7111111111111111, 0.7111111111111111, 0.7111111111111111, -1.2888888888888888, -1.2888888888888888, -1.2888888888888888, -0.2666666666666666, 1.7111111111111112, -0.2666666666666666, 1.7333333333333334, 1.7333333333333334, 1.7333333333333334, -0.2666666666666666, -0.2666666666666666]\n","Episode 89:Total timesteps 17: [-1.1570430091974955, 1.844433010432835, 1.865160634442419, -0.13334487463124, -0.2438816560211725, -1.2627729624254682, -1.2660012782744516, -1.2665529596174534, -1.2666472354697467, -1.2666633461037282, 1.7111111111111112, 4.733333333333333, -1.2666666666666666, -1.1561185541460115, -0.13722703854149954, -0.1339987216545172, -0.9333333333333333]\n","Episode 90:Total timesteps 40: [0.8666666666666667, -1.2438815687165148, -2.2627729615021814, 1.844546957118228, 1.8391794450510157, -1.2667660418461577, -1.2851057499243685, -1.2882423660951123, -1.178230170061973, -0.15943038039732915, 1.8200729925163763, -1.177902322014273, 1.842956070511538, -1.2661235685257246, -1.2849959309412409, 1.688888888888889, -2.3110203906300515, -2.311091919257277, -2.3111077934210593, -2.3111105437723958, -2.3111110141557196, 0.6666666666666666, -2.3333333333333335, -2.3333333333333335, -2.2227850994311638, -1.3144419405436012, -2.33010501656825, -2.332781651980518, -2.3332390574808746, -2.3333172226993386, -2.3333305802155313, -2.3333328628578927, -2.3333332529346156, -2.3333333195941384, -2.222785095602285, -1.0933454693800813, -1.1817739955474824, -1.1968853902748209, -0.31001598522569607, -1.329348672879056]\n","Episode 91:Total timesteps 40: [-1.2438815687165148, -1.2627729615021814, -1.266001278264953, -1.266552959617357, 1.7111111111111112, -1.1783526299565485, -0.2699970319969598, 1.7346964424231905, 1.7111111111111112, 1.711186805403874, 1.7333333333333334, -1.2666666666666666, -1.2666664280558706, -1.2666665886095787, -1.2666666529507098, -1.2666666643189681, -1.2666666662654342, -1.2666666665981001, -0.2666666666549494, -0.26666666666466454, -0.26666666666632455, 0.7111111111111111, -4.288888888888889, -2.2888888888888888, -2.2888888888888888, -2.2888888888888888, -2.1783406535058667, -1.159449260720041, -1.2667691793404505, -1.2851088907737132, -1.2882429316840964, -1.2887785024025176, 1.7333333333333334, 1.7111111111111112, 0.7333333333333334, 1.7333333333333334, 1.7111111111111112, 4.733333333333333, 1.7333333333333334, -1.2666666666666666]\n","Episode 92:Total timesteps 40: [-0.15555555555555556, -1.266103790938737, 1.6909145906904852, -3.310469051920727, -3.3109976451086, -3.311091682352974, -3.311107790572783, -3.3111105436662207, -3.3111110141414155, -2.3111110945401308, -2.3111111082793254, -2.311111110627192, -2.3111111110284153, 1.7111111111111112, -0.2666666666666666, 1.7333333333333334, -1.2666666666666666, -1.2666666666666666, -1.2666666666666666, -1.2666666666666666, -1.2666666666666666, -1.2666666666666662, -1.2666666666666662, -1.2666666666666662, -1.2666666666666662, -1.2666666666666662, 1.7111111111111112, -0.17835594901499408, -1.2699975994276715, -2.2856605731879327, -2.288337207547348, -2.2887946130366106, -2.2888727782549076, -2.288886135771089, 0.7333333333333334, 1.843866353569727, -0.1372270921014005, -0.24454695520184222, -1.2628866681547177, -1.2660207093933558]\n","Episode 93:Total timesteps 21: [2.9327704576054034, 2.9726526706793113, -1.1334446239429257, -1.1517756064398026, -0.26545783408401613, -1.2848847972417148, -1.288204636735431, -1.2887719582463393, -1.2888689068178096, -1.2888854741880378, -1.2888883053566889, 1.688888888888889, -2.311111111111111, -2.311111111111111, -2.200562876793985, -1.2922197182504682, 0.7124713271630059, -1.2883604716896269, -1.2887948532408955, -1.2888727806847382, 1.0666666666666667]\n","Episode 94:Total timesteps 3: [-1.0227850979501518, -1.1144419405476662, -1.7913391290368645]\n","Episode 95:Total timesteps 40: [-1.288326013160959, -1.3072174059466257, -1.3104457227093977, -1.3109974040618018, -1.31109167991419, -1.3111077905481725, 1.7111111111111112, 0.7111111111111111, -0.2666666666666666, 1.7333333333333334, 1.7333333333333334, -1.2666666666666666, 0.7111111111111111, 1.7111111111111112, -0.28888888888888886, 0.7111111111111111, -1.2888888888888888, -0.2666666666666666, 1.7333333333333334, 1.7333333333333334, 1.7333333333333334, -0.2666666666666666, -0.2666666666666666, -0.2666666666666666, -0.2666666666666663, -0.2666666666666663, -0.2666666666666663, 0.7111111111111111, 2.7333333333333334, 1.7333333333333334, 1.7333333333333334, 1.7333333333333334, -0.2666666666666666, -0.2666666666666666, 0.7111111111111111, -0.28888888888888886, 0.7111111111111111, 0.7111111111111111, -0.28888888888888886, 0.7333333333333334]\n","Episode 96:Total timesteps 19: [0.8666666666666667, -0.24388156871651467, -1.2627729615021814, -2.266001278264953, 0.7111111111111111, 0.7111111111111111, 0.7111141954330923, -3.288888323831892, -3.2888887919432865, -0.311111111111111, -0.28888888888888886, 0.7111111111111111, 0.7111111111111111, 0.7111111111111111, -1.2888888888888888, -1.2888888888886734, -0.2666666666666666, 1.7333333333333334, -1.9333333333333333]\n","Episode 97:Total timesteps 40: [0.8222222222222223, -1.288326013160959, 0.6686923684682627, 0.7778646974487322, -1.2037800674062158, 1.8200905059609198, -1.2884529645978948, 0.668710412093933, 0.7778617500566499, -1.3143288887354352, -2.3300856805857464, -2.332778347516045, -2.333238492785007, -2.333317126199441, 0.688888888888889, -2.311111111111111, -2.311111111111111, -2.3111110996762614, -2.3111111087732614, 0.7111111111111111, 1.7111111111111112, 1.7111111111111112, 0.7333333333333334, 1.7333333333333334, 1.7333333333333334, 1.7333333333333334, -0.2666666666666666, -0.2666666666666666, -0.2666666666666666, -0.2666666666666663, -0.2666666666666663, -0.2666666666666663, -0.2666666666666663, -0.2666666666666663, -0.2666666666666663, 0.7111111111111111, 1.7333333333333334, 1.7333333333333334, 1.7333333333333334, 1.7333333333333334]\n","Episode 98:Total timesteps 40: [-1.3105482353831812, -1.3294396281688483, -2.33266794493162, -2.333219626284024, -2.333313902136412, -2.3333300127703946, -2.3333327658881946, -2.3333332363636354, -2.333333316762353, -1.3333333305015476, -1.3333333328494144, -1.3333333332506374, -1.3333333333192017, -1.3333333333309185, -1.3333333333329205, -1.3333333333332629, -1.3333333333333215, -2.22278509795015, -2.314441940547666, -3.330105016570562, -2.3327816519809295, -2.3332390574809447, -2.333317222699351, -2.3333305802155335, 0.688888888888889, 0.799421909125071, -1.2922198079110485, -2.307882793062292, 0.7111111111111111, -2.288817616454955, -2.288873015078224, -2.2888861381634684, -2.288888418437265, -2.288888808490357, -2.178340639766504, -1.1594492583721725, -1.156220943556046, -1.0451210271531193, -1.0261353585719117, -0.022890931184872065]\n","Episode 99:Total timesteps 40: [-1.2438815687165148, -1.2627729615021814, -1.266001278264953, -2.266552959617357, -2.266647235469746, -2.266663346103728, -2.266666099221528, -2.2666665696969686, -2.266666650095686, -0.266666663834881, -0.2666666661827478, -0.26666666658397065, -0.2666666666525349, -0.26666666666425176, -0.26666666666625405, -0.2666666666665961, -0.2666666666666546, -0.2666666666666645, -0.2666666666666663, -0.2666666666666663, -0.2666666666666663, -0.2666666666666663, 1.8438815687165149, -0.24777527388099962, -1.263438349903895, -1.2661149853142626, -2.2665723908142783, 0.7111111111111111, 1.7111111111111112, 1.7111113454710085, -2.288888810876993, -2.288888875173776, -0.288888886541265, -0.28888888848766836, -0.2888888888203246, -0.288888888877172, 0.7333333333333334, -1.2666666666666666, -1.2666666666666666, -1.2666666666666666]\n"]}]},{"cell_type":"code","source":["# To access the reward for a specific step:\n","#for i, feedback in enumerate(recalibrated_rewards_list):\n","#    human_recalibrated_reward_for_step = recalibrated_rewards_list[i]\n","#    print(f\"Recalibrated reward for step {i}: {human_recalibrated_reward_for_step}\")"],"metadata":{"id":"9ghTAsxHrRBv","executionInfo":{"status":"ok","timestamp":1750201986335,"user_tz":-330,"elapsed":3,"user":{"displayName":"Saif Nazir","userId":"15029834638479146606"}}},"execution_count":42,"outputs":[]},{"cell_type":"markdown","source":["SECTION A.5: MODEL TRAINING(HUMAN FEEDBACK - AGGRESSIVE DRIVER)\n","*   Step A.5.1: CUSTOM REWARD FUNCTION\n","*   Step A.5.2: LOAD THE SAVED INITIALLY TRAINED PPO MODEL FROM GOOGLE DRIVE\n","*   Step A.5.3: TRAIN/UPDATE PPO MODEL WITH RECALIBRATED REWARD\n","*   Step A.5.4: SAVE THE TRAINED MODEL FOR TESTING"],"metadata":{"id":"XBMjLEJEo-Ah"}},{"cell_type":"code","execution_count":43,"metadata":{"id":"7q52Lb46CuhD","executionInfo":{"status":"ok","timestamp":1750201986346,"user_tz":-330,"elapsed":4,"user":{"displayName":"Saif Nazir","userId":"15029834638479146606"}}},"outputs":[],"source":["# Step A.5.1: CUSTOM REWARD FUNCTION\n","def custom_reward(self, env, state, action, next_state, reward, done):\n","    # Access and recalculate the reward using human_feedback_data or recalibrate_rewards_human function\n","    global step_counter\n","    try:\n","        step_counter\n","    except NameError:\n","        step_counter = 0\n","\n","    reward = recalibrated_rewards_list[step_counter]\n","    step_counter += 1\n","    return reward\n","\n","# Create a new environment class that wraps your original environment and overrides the default reward function with your custom function\n","class CustomRewardWrapper(gym.Wrapper):\n","    def __init__(self, env):\n","        super(CustomRewardWrapper, self).__init__(env)\n","\n","    def step(self, action):\n","        next_state, reward, terminated, truncated, info = self.env.step(action)\n","        done = terminated or truncated\n","        reward = custom_reward(self, self.env, self.last_obs, action, next_state, reward, done)\n","        # custom_reward should be defined and accessible to your class\n","        self.last_obs = next_state\n","        return next_state, reward, terminated, truncated, info\n","\n","    def reset(self, **kwargs):\n","        global step_counter\n","        step_counter = 0\n","        self.last_obs = self.env.reset(**kwargs)[0]  # Assuming Gymnasium env returns (obs, info)\n","        return self.last_obs, {}  # Assuming Gymnasium env requires (obs, info)\n","# Create and wrap the environment with your custom reward wrapper\n","env_human = CustomRewardWrapper(gym.make('highway-v0'))"]},{"cell_type":"markdown","source":["PPO training and Training logs"],"metadata":{"id":"ZcS1aMmXrPaJ"}},{"cell_type":"code","source":["drive_log_dir = \"/content/drive/MyDrive/05_zero_shot_llm_3/02_data/00_training_logs/3_log_dir/3_ppo_highway_biased_hf_direct_aggressive\"                   # Update directory location 3"],"metadata":{"id":"fnlkRy87rHRp","executionInfo":{"status":"ok","timestamp":1750201986354,"user_tz":-330,"elapsed":3,"user":{"displayName":"Saif Nazir","userId":"15029834638479146606"}}},"execution_count":44,"outputs":[]},{"cell_type":"code","source":["# Train PPO with Custom Rewards\n","def train_ppo_with_custom_rewards(log_dir=drive_log_dir, total_timesteps=10000):\n","    os.makedirs(log_dir, exist_ok=True)\n","    env = CustomRewardWrapper(gym.make(\"highway-v0\"))\n","    env = Monitor(env, log_dir)\n","    model = PPO(\"MlpPolicy\", env, verbose=1, tensorboard_log=log_dir)\n","    model.learn(total_timesteps=total_timesteps)\n","    model.save('/content/drive/MyDrive/05_zero_shot_llm_3/02_data/01_trained_models/3_ppo_highway_biased_hf_direct_aggressive')           # Update directory location 4\n","    return model, log_dir"],"metadata":{"id":"UtGUSeFYrHMH","executionInfo":{"status":"ok","timestamp":1750201986362,"user_tz":-330,"elapsed":3,"user":{"displayName":"Saif Nazir","userId":"15029834638479146606"}}},"execution_count":45,"outputs":[]},{"cell_type":"code","source":["# log_path = os.path.join(drive_log_dir, \"monitor.csv\")\n","# df = pd.read_csv(log_path, skiprows=1)\n","## Ensure episodes are logged correctly\n","# df.reset_index(inplace=True)\n","# df.rename(columns={\"index\": \"episode\", \"r\": \"reward\", \"l\": \"length\", \"t\": \"time_step\"}, inplace=True)"],"metadata":{"id":"7V0Zu_0kLhA7","executionInfo":{"status":"ok","timestamp":1750201986371,"user_tz":-330,"elapsed":4,"user":{"displayName":"Saif Nazir","userId":"15029834638479146606"}}},"execution_count":46,"outputs":[]},{"cell_type":"code","source":["# data_table.enable_dataframe_formatter()\n","# data_table.DataTable(df)"],"metadata":{"id":"lXwpFjQLLh8D","executionInfo":{"status":"ok","timestamp":1750201986379,"user_tz":-330,"elapsed":4,"user":{"displayName":"Saif Nazir","userId":"15029834638479146606"}}},"execution_count":47,"outputs":[]},{"cell_type":"code","source":["# Execute Training and Convergence Tracking\n","model, log_dir = train_ppo_with_custom_rewards(total_timesteps=10000)"],"metadata":{"id":"OjCzz4cHLubx","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1750207039442,"user_tz":-330,"elapsed":5053058,"user":{"displayName":"Saif Nazir","userId":"15029834638479146606"}},"outputId":"da24e114-650b-4ff7-c4dc-6c5e22e24a2c"},"execution_count":48,"outputs":[{"output_type":"stream","name":"stdout","text":["Using cpu device\n","Wrapping the env in a DummyVecEnv.\n","Logging to /content/drive/MyDrive/05_zero_shot_llm_3/02_data/00_training_logs/3_log_dir/3_ppo_highway_biased_hf_direct_aggressive/PPO_1\n","---------------------------------\n","| rollout/           |          |\n","|    ep_len_mean     | 14.8     |\n","|    ep_rew_mean     | -11.6    |\n","| time/              |          |\n","|    fps             | 2        |\n","|    iterations      | 1        |\n","|    time_elapsed    | 1012     |\n","|    total_timesteps | 2048     |\n","---------------------------------\n","-----------------------------------------\n","| rollout/                |             |\n","|    ep_len_mean          | 11          |\n","|    ep_rew_mean          | -8.47       |\n","| time/                   |             |\n","|    fps                  | 2           |\n","|    iterations           | 2           |\n","|    time_elapsed         | 2023        |\n","|    total_timesteps      | 4096        |\n","| train/                  |             |\n","|    approx_kl            | 0.014300266 |\n","|    clip_fraction        | 0.149       |\n","|    clip_range           | 0.2         |\n","|    entropy_loss         | -1.6        |\n","|    explained_variance   | 0.00181     |\n","|    learning_rate        | 0.0003      |\n","|    loss                 | 14.3        |\n","|    n_updates            | 10          |\n","|    policy_gradient_loss | -0.0159     |\n","|    value_loss           | 29.7        |\n","-----------------------------------------\n","-----------------------------------------\n","| rollout/                |             |\n","|    ep_len_mean          | 9.5         |\n","|    ep_rew_mean          | -6.91       |\n","| time/                   |             |\n","|    fps                  | 2           |\n","|    iterations           | 3           |\n","|    time_elapsed         | 3030        |\n","|    total_timesteps      | 6144        |\n","| train/                  |             |\n","|    approx_kl            | 0.013222925 |\n","|    clip_fraction        | 0.155       |\n","|    clip_range           | 0.2         |\n","|    entropy_loss         | -1.57       |\n","|    explained_variance   | 0.0167      |\n","|    learning_rate        | 0.0003      |\n","|    loss                 | 12.6        |\n","|    n_updates            | 20          |\n","|    policy_gradient_loss | -0.0177     |\n","|    value_loss           | 28.4        |\n","-----------------------------------------\n","-----------------------------------------\n","| rollout/                |             |\n","|    ep_len_mean          | 9.23        |\n","|    ep_rew_mean          | -6.49       |\n","| time/                   |             |\n","|    fps                  | 2           |\n","|    iterations           | 4           |\n","|    time_elapsed         | 4040        |\n","|    total_timesteps      | 8192        |\n","| train/                  |             |\n","|    approx_kl            | 0.014393173 |\n","|    clip_fraction        | 0.176       |\n","|    clip_range           | 0.2         |\n","|    entropy_loss         | -1.51       |\n","|    explained_variance   | 0.0662      |\n","|    learning_rate        | 0.0003      |\n","|    loss                 | 15.6        |\n","|    n_updates            | 30          |\n","|    policy_gradient_loss | -0.0215     |\n","|    value_loss           | 27.1        |\n","-----------------------------------------\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/highway_env/envs/common/observation.py:228: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  df[feature] = utils.lmap(df[feature], [f_range[0], f_range[1]], [-1, 1])\n","/usr/local/lib/python3.11/dist-packages/highway_env/envs/common/observation.py:230: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  df[feature] = np.clip(df[feature], -1, 1)\n","/usr/local/lib/python3.11/dist-packages/highway_env/envs/common/observation.py:228: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  df[feature] = utils.lmap(df[feature], [f_range[0], f_range[1]], [-1, 1])\n","/usr/local/lib/python3.11/dist-packages/highway_env/envs/common/observation.py:230: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  df[feature] = np.clip(df[feature], -1, 1)\n","/usr/local/lib/python3.11/dist-packages/highway_env/envs/common/observation.py:228: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  df[feature] = utils.lmap(df[feature], [f_range[0], f_range[1]], [-1, 1])\n","/usr/local/lib/python3.11/dist-packages/highway_env/envs/common/observation.py:230: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  df[feature] = np.clip(df[feature], -1, 1)\n","/usr/local/lib/python3.11/dist-packages/highway_env/envs/common/observation.py:228: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  df[feature] = utils.lmap(df[feature], [f_range[0], f_range[1]], [-1, 1])\n","/usr/local/lib/python3.11/dist-packages/highway_env/envs/common/observation.py:230: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  df[feature] = np.clip(df[feature], -1, 1)\n"]},{"output_type":"stream","name":"stdout","text":["-----------------------------------------\n","| rollout/                |             |\n","|    ep_len_mean          | 7.48        |\n","|    ep_rew_mean          | -4.48       |\n","| time/                   |             |\n","|    fps                  | 2           |\n","|    iterations           | 5           |\n","|    time_elapsed         | 5045        |\n","|    total_timesteps      | 10240       |\n","| train/                  |             |\n","|    approx_kl            | 0.013266023 |\n","|    clip_fraction        | 0.137       |\n","|    clip_range           | 0.2         |\n","|    entropy_loss         | -1.45       |\n","|    explained_variance   | -0.00509    |\n","|    learning_rate        | 0.0003      |\n","|    loss                 | 11.3        |\n","|    n_updates            | 40          |\n","|    policy_gradient_loss | -0.0128     |\n","|    value_loss           | 25.5        |\n","-----------------------------------------\n"]}]}]}