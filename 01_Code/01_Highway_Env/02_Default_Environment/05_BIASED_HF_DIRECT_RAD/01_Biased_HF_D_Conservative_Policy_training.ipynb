{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyOI0Kp8HL+rlJNAvvSTsMx7"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["# Install the required libraries in your Google Colab environment\n","!pip install stable-baselines3 gymnasium highway-env -q"],"metadata":{"id":"APrU5xhT0nTF","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1750253441606,"user_tz":-330,"elapsed":143478,"user":{"displayName":"Saif Nazir","userId":"15029834638479146606"}},"outputId":"ac675599-79f9-46c4-8378-de572196ae8d"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/184.5 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m184.3/184.5 kB\u001b[0m \u001b[31m24.6 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m184.5/184.5 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m105.0/105.0 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m62.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m35.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m50.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m1.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m11.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m89.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h"]}]},{"cell_type":"code","source":["# Import the necessary libraries\n","import gymnasium as gym\n","import highway_env\n","import numpy as np\n","import pandas as pd\n","import pickle\n","import os\n","import matplotlib.pyplot as plt"],"metadata":{"id":"SQJ0fTEA0m_G","executionInfo":{"status":"ok","timestamp":1750253443318,"user_tz":-330,"elapsed":1702,"user":{"displayName":"Saif Nazir","userId":"15029834638479146606"}}},"execution_count":2,"outputs":[]},{"cell_type":"code","source":["from stable_baselines3 import PPO\n","from stable_baselines3.common.vec_env import DummyVecEnv\n","from stable_baselines3.common.evaluation import evaluate_policy\n","from stable_baselines3.common.monitor import Monitor\n","from google.colab import data_table\n","from google.colab import drive\n","\n","# Mount Google Drive\n","drive.mount('/content/drive')"],"metadata":{"id":"go9u8BAE1Olz","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1750253480994,"user_tz":-330,"elapsed":37652,"user":{"displayName":"Saif Nazir","userId":"15029834638479146606"}},"outputId":"1a3bc266-210b-4ccf-e6ba-c712cd3a88bd"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["# Load the dataframe back from the pickle file\n","trajectory_df = pd.read_pickle('/content/drive/MyDrive/05_zero_shot_llm_3/02_data/02_trajectories/0_initial_training/0_initial_trajectory_df.pkl')           # Update directory location 1"],"metadata":{"id":"84qr9aP-nc0d","executionInfo":{"status":"ok","timestamp":1750253482931,"user_tz":-330,"elapsed":1940,"user":{"displayName":"Saif Nazir","userId":"15029834638479146606"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["# Display the data frame\n","data_table.enable_dataframe_formatter()\n","data_table.DataTable(trajectory_df)"],"metadata":{"id":"MHAY3C2LxMel","colab":{"base_uri":"https://localhost:8080/","height":2847,"output_embedded_package_id":"1Nv8EILcOoIfVyZ9upcc71Tfq3l1d3jNv"},"executionInfo":{"status":"ok","timestamp":1750253487702,"user_tz":-330,"elapsed":4768,"user":{"displayName":"Saif Nazir","userId":"15029834638479146606"}},"outputId":"a6e7e8a3-0f9f-42fb-ba1f-a09cc900c428"},"execution_count":5,"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}]},{"cell_type":"code","source":["# Check the data type of each column\n","print(type(trajectory_df['episode'][0]))\n","print(type(trajectory_df['time_step'][0]))\n","print(type(trajectory_df['state'][0]))\n","print(type(trajectory_df['action'][0]))\n","print(type(trajectory_df['reward'][0]))\n","print(type(trajectory_df['next_state'][0]))\n","print(type(trajectory_df['collision_flag'][0]))\n","print(type(trajectory_df['lane_index'][0]))"],"metadata":{"id":"BPFidEkGlZAC","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1750253487751,"user_tz":-330,"elapsed":15,"user":{"displayName":"Saif Nazir","userId":"15029834638479146606"}},"outputId":"49a94b07-0a9b-461d-88d0-e7622d74eec6"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["<class 'numpy.int64'>\n","<class 'numpy.int64'>\n","<class 'numpy.ndarray'>\n","<class 'numpy.ndarray'>\n","<class 'numpy.float64'>\n","<class 'numpy.ndarray'>\n","<class 'numpy.int64'>\n","<class 'numpy.int64'>\n"]}]},{"cell_type":"code","source":["trajectory_df.dtypes"],"metadata":{"id":"NYe0lzD3XNwm","colab":{"base_uri":"https://localhost:8080/","height":335},"executionInfo":{"status":"ok","timestamp":1750253487809,"user_tz":-330,"elapsed":56,"user":{"displayName":"Saif Nazir","userId":"15029834638479146606"}},"outputId":"a77f2572-4020-4501-d30a-6ffdf993aac9"},"execution_count":7,"outputs":[{"output_type":"execute_result","data":{"text/plain":["episode             int64\n","time_step           int64\n","state              object\n","action             object\n","reward            float64\n","next_state         object\n","collision_flag      int64\n","lane_index          int64\n","dtype: object"],"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>0</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>episode</th>\n","      <td>int64</td>\n","    </tr>\n","    <tr>\n","      <th>time_step</th>\n","      <td>int64</td>\n","    </tr>\n","    <tr>\n","      <th>state</th>\n","      <td>object</td>\n","    </tr>\n","    <tr>\n","      <th>action</th>\n","      <td>object</td>\n","    </tr>\n","    <tr>\n","      <th>reward</th>\n","      <td>float64</td>\n","    </tr>\n","    <tr>\n","      <th>next_state</th>\n","      <td>object</td>\n","    </tr>\n","    <tr>\n","      <th>collision_flag</th>\n","      <td>int64</td>\n","    </tr>\n","    <tr>\n","      <th>lane_index</th>\n","      <td>int64</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div><br><label><b>dtype:</b> object</label>"]},"metadata":{},"execution_count":7}]},{"cell_type":"markdown","source":["A : HUMAN FEEDBACK IMPLEMENTATION (EFFICIENCY-ORIENTED DRIVER)\n","*   SECTION A.1: FEEDBACK BASED ON LANE CHANGING BEHAVIOUR\n","*   SECTION A.2: FEEDBACK BASED ON COLLISION AVOIDANCE MANUEVERS\n","*   SECTION A.3: FEEDBACK BASED ON SPEED OPTIMIZATION\n","*   SECTION A.4: REWARD MODELLING\n","*   SECTION A.5: MODEL TRAINING\n"],"metadata":{"id":"yK3Yd5Tt2_FU"}},{"cell_type":"markdown","source":["SECTION A.1: FEEDBACK BASED ON LANE CHANGING BEHAVIOUR\n","*   Step A.1.1: FUNCTION TO COUNT LANE CHANGES\n","*   Step A.1.2: FUNCTION TO PROVIDE FEEDBACK BASED ON LANE CHANGE\n"],"metadata":{"id":"V1BC9xeLm_aS"}},{"cell_type":"code","source":["# Step A.1.1: FUNCTION TO COUNT LANE CHANGES\n","def count_lane_changes(df):\n","    df_copy = df.copy()\n","    df_copy['count_lane_change'] = 0\n","\n","    # Group by episode\n","    for episode_id, episode_df in df_copy.groupby('episode'):  # Group by 'episode'\n","        idx = 0\n","        while idx < len(episode_df):  # Iterate within each episode\n","            current_lane_index = episode_df.iloc[idx]['lane_index']\n","\n","            if idx == 0:  # First timestep of the episode\n","                episode_df.at[episode_df.index[idx], 'count_lane_change'] = 0\n","                idx += 1\n","                continue\n","\n","            previous_lane_index = episode_df.iloc[idx - 1]['lane_index']\n","\n","            if current_lane_index == previous_lane_index:\n","                episode_df.at[episode_df.index[idx], 'count_lane_change'] = 0\n","                idx += 1\n","                continue\n","\n","            change = current_lane_index - previous_lane_index\n","            count = 1\n","            consecutive_indices = [idx]\n","\n","            lookahead_idx = idx + 1\n","            while lookahead_idx < len(episode_df) and (episode_df.iloc[lookahead_idx]['lane_index'] - episode_df.iloc[lookahead_idx - 1]['lane_index'] == change):\n","                count += 1\n","                consecutive_indices.append(lookahead_idx)\n","                lookahead_idx += 1\n","\n","            for i in consecutive_indices:\n","                episode_df.at[episode_df.index[i], 'count_lane_change'] = count\n","\n","            idx = lookahead_idx\n","\n","        df_copy.loc[episode_df.index, 'count_lane_change'] = episode_df['count_lane_change'].values # Update original df\n","\n","    return df_copy"],"metadata":{"id":"l6ogHDaMcSXf","executionInfo":{"status":"ok","timestamp":1750253487816,"user_tz":-330,"elapsed":3,"user":{"displayName":"Saif Nazir","userId":"15029834638479146606"}}},"execution_count":8,"outputs":[]},{"cell_type":"code","source":["# Call the function and save the updated dataframe as \"lane_feedback_df\"\n","lane_feedback_df = count_lane_changes(trajectory_df)"],"metadata":{"id":"ytNuI-8zdYHn","executionInfo":{"status":"ok","timestamp":1750253487825,"user_tz":-330,"elapsed":2,"user":{"displayName":"Saif Nazir","userId":"15029834638479146606"}}},"execution_count":9,"outputs":[]},{"cell_type":"code","source":["data_table.enable_dataframe_formatter()\n","data_table.DataTable(lane_feedback_df)"],"metadata":{"id":"dclcOqjRdbKg","colab":{"base_uri":"https://localhost:8080/","height":3558,"output_embedded_package_id":"1Q4cyzg6vgkabBTyxKz323NOL0cetMqJB"},"executionInfo":{"status":"ok","timestamp":1750253489871,"user_tz":-330,"elapsed":2042,"user":{"displayName":"Saif Nazir","userId":"15029834638479146606"}},"outputId":"d2ce5528-9897-4cf0-d8b5-bf5eda20dcf4"},"execution_count":10,"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}]},{"cell_type":"code","source":["# Step A.1.2: FUNCTION TO PROVIDE FEEDBACK BASED ON LANE CHANGE\n","# Define the lane_change_behaviour function\n","def lane_change_behaviour(df):\n","    # Create a copy of the dataframe to avoid modifying the original one\n","    df_copy = df.copy()\n","\n","    # Create 'Lane_feedback' and 'Lane_change_reward' columns\n","    df_copy['Lane_feedback'] = \"\"\n","    df_copy['Lane_change_score'] = 0\n","    df_copy['Lane_change_score'] = df_copy['Lane_change_score'].astype(float)\n","\n","    # Iterate through the dataframe to apply the lane change behavior logic\n","    for i, row in df_copy.iterrows():\n","        lane_change_number = row['count_lane_change']\n","\n","        if lane_change_number == 0:\n","            df_copy.at[i, 'Lane_feedback'] = \"No lane change is observed\"\n","            df_copy.at[i, 'Lane_change_score'] = -2                                 # Bias value 1\n","        elif lane_change_number == 1:\n","            df_copy.at[i, 'Lane_feedback'] = \"One lane change is observed\"\n","            df_copy.at[i, 'Lane_change_score'] = 0                                 # Bias value 2\n","        elif lane_change_number == 2:\n","            df_copy.at[i, 'Lane_feedback'] = \"Two lane change is observed\"\n","            df_copy.at[i, 'Lane_change_score'] =  +1                               # Bias value 3\n","        elif lane_change_number == 3:\n","            df_copy.at[i, 'Lane_feedback'] = \"Three lane change is observed\"\n","            df_copy.at[i, 'Lane_change_score'] =  +1                                # Bias value 4\n","\n","\n","    # Return the updated dataframe\n","    return df_copy"],"metadata":{"id":"5VbJbsKqecVO","executionInfo":{"status":"ok","timestamp":1750253489910,"user_tz":-330,"elapsed":2,"user":{"displayName":"Saif Nazir","userId":"15029834638479146606"}}},"execution_count":11,"outputs":[]},{"cell_type":"code","source":["# Apply the lane_change_behaviour function to the lane_feedback_df\n","lane_behaviour_feedback_df = lane_change_behaviour(lane_feedback_df)"],"metadata":{"id":"N_idiuM3exV_","executionInfo":{"status":"ok","timestamp":1750253489916,"user_tz":-330,"elapsed":2,"user":{"displayName":"Saif Nazir","userId":"15029834638479146606"}}},"execution_count":12,"outputs":[]},{"cell_type":"code","source":["data_table.enable_dataframe_formatter()\n","data_table.DataTable(lane_behaviour_feedback_df)"],"metadata":{"id":"q4h9suvHesrz","colab":{"base_uri":"https://localhost:8080/","height":5063,"output_embedded_package_id":"1pwrzzufoSKS7X1x3d2HbvFRyj3HA2Nzz"},"executionInfo":{"status":"ok","timestamp":1750253492849,"user_tz":-330,"elapsed":2931,"user":{"displayName":"Saif Nazir","userId":"15029834638479146606"}},"outputId":"a60ecee5-d6ec-498d-8037-69673e2bc9a5"},"execution_count":13,"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}]},{"cell_type":"markdown","source":["SECTION A.2: FEEDBACK BASED ON COLLISION AVOIDANCE MANUEVERS\n","*   Step A.2.1: FUNCTION TO CALCULATE LANE CHANG\n","*   Step A.2.2: FUNCTION TO CALCULATE TIME TO COLLISION(TTC)\n","*   Step A.2.3: FUNCTION TO CALCULATE RELATIVE POSITION, RELATIVE VELOCITY AND TIME TO COLLISION\n","*   Step A.2.4: FUNCTION TO IMPLEMENT COLLISION AVOIDANCE FEEDBACK"],"metadata":{"id":"oINoG120nF9v"}},{"cell_type":"code","source":["def calculate_lane_changes(df):\n","    df_copy = df.copy()\n","    df_copy['Lane_change_collision_fb'] = 0\n","\n","    # Group by episode\n","    for episode_id, episode_df in df_copy.groupby('episode'):  # Group by 'episode'\n","        idx = 0\n","        while idx < len(episode_df):  # Iterate within each episode\n","            current_lane_index = episode_df.iloc[idx]['lane_index']\n","\n","            if idx == 0:  # First timestep of the episode\n","                episode_df.at[episode_df.index[idx], 'Lane_change_collision_fb'] = 0\n","                idx += 1\n","                continue\n","\n","            previous_lane_index = episode_df.iloc[idx - 1]['lane_index']\n","\n","            if current_lane_index != previous_lane_index:\n","                episode_df.at[episode_df.index[idx], 'Lane_change_collision_fb'] = 1\n","                idx += 1\n","                continue\n","\n","            else:\n","                episode_df.at[episode_df.index[idx], 'Lane_change_collision_fb'] = 0\n","                idx += 1\n","\n","        df_copy.loc[episode_df.index, 'Lane_change_collision_fb'] = episode_df['Lane_change_collision_fb'].values # Update original df\n","        # df_copy.loc[episode_df.index, 'count_lane_change'] = episode_df['count_lane_change'].values\n","\n","    return df_copy"],"metadata":{"id":"3gE7sFDx7JGx","executionInfo":{"status":"ok","timestamp":1750253492886,"user_tz":-330,"elapsed":3,"user":{"displayName":"Saif Nazir","userId":"15029834638479146606"}}},"execution_count":14,"outputs":[]},{"cell_type":"code","source":["# Call the function and save the updated dataframe as \"lane_feedback_df\"\n","lane_change_collision_fb_df = calculate_lane_changes(trajectory_df)"],"metadata":{"id":"xKboQ065Xe1T","executionInfo":{"status":"ok","timestamp":1750253492890,"user_tz":-330,"elapsed":2,"user":{"displayName":"Saif Nazir","userId":"15029834638479146606"}}},"execution_count":15,"outputs":[]},{"cell_type":"code","source":["data_table.enable_dataframe_formatter()\n","data_table.DataTable(lane_change_collision_fb_df)"],"metadata":{"id":"mxC64v2KXmh5","colab":{"base_uri":"https://localhost:8080/","height":3592,"output_embedded_package_id":"13AhIgjb2cXFwAsp0isIjJEB6RmPCJoam"},"executionInfo":{"status":"ok","timestamp":1750253494909,"user_tz":-330,"elapsed":2017,"user":{"displayName":"Saif Nazir","userId":"15029834638479146606"}},"outputId":"1ff32227-9ea9-413a-de3d-b2523253fbdd"},"execution_count":16,"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}]},{"cell_type":"code","source":[" # Step A.2.2: FUNCTION TO CALCULATE TIME TO COLLISION(TTC)\n","def calculate_ttc(ego_vehicle, other_vehicles):\n","    if not other_vehicles:\n","        return np.inf, -1  # No other vehicles\n","\n","    min_ttc = np.inf\n","    nearest_vehicle_index = -1\n","\n","    ego_x = ego_vehicle[\"x\"]\n","    ego_y = ego_vehicle[\"y\"]\n","    ego_vx = ego_vehicle[\"vx\"]\n","    ego_vy = ego_vehicle[\"vy\"]\n","\n","    for i, other in enumerate(other_vehicles):\n","        other_x = other[\"x\"]\n","        other_y = other[\"y\"]\n","        other_vx = other[\"vx\"]\n","        other_vy = other[\"vy\"]\n","\n","        dx = other_x - ego_x\n","        dy = other_y - ego_y\n","\n","        # Use magnitude and heading if vx/vy not directly available\n","        # v_ego = np.sqrt(ego_vx**2 + ego_vy**2)\n","        # heading_ego = ...  # Get heading angle\n","        # v_other = np.sqrt(other_vx**2 + other_vy**2)\n","        # heading_other = ... # Get heading angle\n","\n","        dvx = other_vx - ego_vx\n","        dvy = other_vy - ego_vy\n","\n","        # Calculate TTC (constant velocity assumption)\n","        dot_product = dx * dvx + dy * dvy\n","        if dot_product < 0:  # Vehicles are getting closer\n","            distance = np.sqrt(dx**2 + dy**2)\n","            relative_speed = np.sqrt(dvx**2 + dvy**2)  # Magnitude of relative speed\n","            if relative_speed > 0:\n","              ttc = distance / relative_speed\n","            else:\n","              ttc = np.inf # Relative speed is zero, no collision\n","        else:\n","            ttc = np.inf  # Vehicles are moving apart\n","\n","\n","        if ttc < min_ttc and ttc > 0: # Only consider positive TTCs (collisions)\n","            min_ttc = ttc\n","            nearest_vehicle_index = i\n","\n","    return min_ttc, nearest_vehicle_index"],"metadata":{"id":"NdQ9A6ZbMIm_","executionInfo":{"status":"ok","timestamp":1750253494961,"user_tz":-330,"elapsed":18,"user":{"displayName":"Saif Nazir","userId":"15029834638479146606"}}},"execution_count":17,"outputs":[]},{"cell_type":"code","source":["#  Step A.2.3: FUNCTION TO CALCULATE RELATIVE POSITION, RELATIVE VELOCITY AND ACCELARATION\n","\n","def calculate_collision_parameters_1(trajectory_df):\n","    # Create a copy of the original dataframe\n","    df_copy = trajectory_df.copy()\n","\n","    df_copy['Nearest vehicle id'] = None\n","    df_copy['TTC'] = 0.0\n","    # Create a new column for storing collision parameters\n","    df_copy['Collision_Parameters'] = None\n","\n","    # Group by episode\n","    for episode_id, episode_df in df_copy.groupby('episode'):\n","        # Iterate through each timestep in the episode\n","        for idx, row in episode_df.iterrows():\n","            # Get the agent's state and new state\n","            agent_state = row['state']\n","            agent_new_state = row['next_state']\n","\n","            agent_position = np.array([agent_state[1], agent_state[2]])  # x, y\n","            agent_velocity = np.array([agent_state[3], agent_state[4]])  # vx, vy\n","            agent_new_position = np.array([agent_new_state[1], agent_new_state[2]])  # new x, new y\n","            agent_new_velocity = np.array([agent_new_state[3], agent_new_state[4]])  # new vx, new vy\n","\n","            # Find the nearest vehicle\n","            nearest_vehicle_distance = float('inf')\n","            nearest_vehicle_idx = None\n","            other_vehicles = [] # Initialize list to store other vehicles' data\n","            for vehicle_idx, vehicle_row in episode_df.iterrows():\n","                if vehicle_idx != idx:  # Skip the agent itself\n","                    vehicle_state = vehicle_row['state']\n","                    vehicle_position = np.array([vehicle_state[1], vehicle_state[2]])\n","                    vehicle_velocity = np.array([vehicle_state[3], vehicle_state[4]]) # Added to store velocity\n","                    distance = np.linalg.norm(agent_position - vehicle_position)\n","                    if distance < nearest_vehicle_distance:\n","                        nearest_vehicle_distance = distance\n","                        nearest_vehicle_idx = vehicle_idx\n","                    other_vehicles.append({\"x\": vehicle_position[0], \"y\": vehicle_position[1], \"vx\":vehicle_velocity[0], \"vy\":vehicle_velocity[1]}) # Added other vehicles\n","\n","            # print(f\"Episode {episode_id}, Time step {row['time_step']}: Nearest vehicle is {nearest_vehicle_idx}\")\n","\n","            if nearest_vehicle_idx is None:\n","                collision_data = {\n","                    'Vehicle_number': None,\n","                    'Relative_position': None,\n","                    'Relative_velocity': None,\n","                    'Relative_speed': None,\n","                    'TTC': None,\n","                    'Agent_acceleration': None\n","                }\n","                df_copy.at[row.name, 'Collision_Parameters'] = collision_data\n","                continue\n","\n","            # --- TTC Calculation Logic (Modified) ---\n","            ego_vehicle = {\"x\": agent_position[0], \"y\": agent_position[1], \"vx\": agent_velocity[0], \"vy\": agent_velocity[1]}\n","            ttc, _ = calculate_ttc(ego_vehicle, other_vehicles) # Call the function\n","\n","            # --- End of TTC Calculation Logic ---\n","\n","            nearest_vehicle_state = episode_df.loc[nearest_vehicle_idx, 'state']\n","            nearest_vehicle_position = np.array([nearest_vehicle_state[1], nearest_vehicle_state[2]])\n","            nearest_vehicle_velocity = np.array([nearest_vehicle_state[3], nearest_vehicle_state[4]])\n","\n","            relative_position = nearest_vehicle_position - agent_position\n","            relative_velocity = nearest_vehicle_velocity - agent_velocity\n","            relative_speed = np.linalg.norm(relative_velocity)\n","\n","\n","            acceleration = agent_new_velocity - agent_velocity\n","\n","            collision_data = {\n","                'Vehicle_number': nearest_vehicle_idx,\n","                'Relative_position': relative_position.tolist(),\n","                'Relative_velocity': relative_velocity.tolist(),\n","                'Relative_speed': relative_speed,\n","                'TTC': ttc,\n","                'Agent_acceleration': acceleration.tolist()\n","            }\n","            df_copy.at[row.name, 'Collision_Parameters'] = collision_data\n","            df_copy.at[row.name, 'Nearest vehicle id'] = nearest_vehicle_idx\n","            df_copy.at[row.name, 'TTC'] = ttc\n","\n","    return df_copy"],"metadata":{"id":"HPpCX1PzMLZv","executionInfo":{"status":"ok","timestamp":1750253494968,"user_tz":-330,"elapsed":3,"user":{"displayName":"Saif Nazir","userId":"15029834638479146606"}}},"execution_count":18,"outputs":[]},{"cell_type":"code","source":["collision_parameters_df_1 = calculate_collision_parameters_1(lane_change_collision_fb_df)"],"metadata":{"id":"TqYFw2pib_zY","executionInfo":{"status":"ok","timestamp":1750253506679,"user_tz":-330,"elapsed":11708,"user":{"displayName":"Saif Nazir","userId":"15029834638479146606"}}},"execution_count":19,"outputs":[]},{"cell_type":"code","source":["data_table.enable_dataframe_formatter()\n","data_table.DataTable(collision_parameters_df_1)"],"metadata":{"id":"h-FlnywacKHX","colab":{"base_uri":"https://localhost:8080/","height":9843,"output_embedded_package_id":"1sN7qD6Kjllv8rip54LMTFlr2nG73fs2S"},"executionInfo":{"status":"ok","timestamp":1750253509700,"user_tz":-330,"elapsed":3032,"user":{"displayName":"Saif Nazir","userId":"15029834638479146606"}},"outputId":"3c5d9033-e701-4ba5-c6a1-780b4bb3a9a4"},"execution_count":20,"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}]},{"cell_type":"code","source":["## Time to collision list for each episode\n","## Group the data by 'episode'\n","# episode_data = collision_parameters_df_1.groupby('episode')\n","## Loop through each episode\n","# for episode, data in episode_data:\n","#    # Extract lane indices\n","#     ttc_list = data['TTC'].tolist()\n","\n","#    # Count the total number of time steps in the episode\n","#     total_timesteps = data['time_step'].max() + 1  # Assuming time_step starts from 0\n","\n","#     print(f\"Episode {episode}:Total timesteps {total_timesteps}: {ttc_list}\")"],"metadata":{"id":"-oWAV3EZcqu-","executionInfo":{"status":"ok","timestamp":1750253509758,"user_tz":-330,"elapsed":8,"user":{"displayName":"Saif Nazir","userId":"15029834638479146606"}}},"execution_count":21,"outputs":[]},{"cell_type":"code","source":["## Nearest vehicles in each time step\n","## Group the data by 'episode'\n","# episode_data = collision_parameters_df_1.groupby('episode')\n","## Loop through each episode\n","# for episode, data in episode_data:\n","#    # Extract lane indices\n","#     nearest_vehicle_list = data['Nearest vehicle id'].tolist()\n","\n","#    # Count the total number of time steps in the episode\n","#     total_timesteps = data['time_step'].max() + 1  # Assuming time_step starts from 0\n","\n","#     print(f\"Episode {episode}:Total timesteps {total_timesteps}: {nearest_vehicle_list}\")"],"metadata":{"id":"mZsgFYSpigoO","executionInfo":{"status":"ok","timestamp":1750253509799,"user_tz":-330,"elapsed":38,"user":{"displayName":"Saif Nazir","userId":"15029834638479146606"}}},"execution_count":22,"outputs":[]},{"cell_type":"code","execution_count":23,"metadata":{"id":"8Ee2reKxpTB6","executionInfo":{"status":"ok","timestamp":1750253509805,"user_tz":-330,"elapsed":3,"user":{"displayName":"Saif Nazir","userId":"15029834638479146606"}}},"outputs":[],"source":["# Step A.2.4: Function to implement collision avoidance feedback\n","def implement_collision_feedback(df):\n","    # Create a copy of the dataframe to avoid modifying the original dataframe\n","    df_copy = df.copy()\n","\n","    # Create new columns for Collision Feedback and Collision Reward\n","    df_copy['Collision_Feedback'] = None\n","    df_copy['Collision_score'] = 0.0\n","\n","    # Iterate through each timestep in the dataframe\n","    for idx, row in df_copy.iterrows():\n","        collision_data = row['Collision_Parameters']\n","        ttc = collision_data['TTC']\n","        agent_acceleration = collision_data['Agent_acceleration']\n","        lane_change = row['Lane_change_collision_fb']\n","\n","        # Initialize feedback and reward\n","        feedback = ''\n","        feedback_1 = ''\n","        score = 0.0\n","\n","        # Logic for Time to Collision (TTC)\n","        if  0.5 <= ttc <=2.0 :\n","            feedback_1 = 'Potential collision risk'\n","            if agent_acceleration[0] < 0:\n","                feedback = 'Avoided collision by slowing down'\n","                score = -2                                                          # Bias Value 5\n","            elif agent_acceleration[0] > 0:\n","                feedback = 'Avoided collision by speeding up'\n","                score = +1                                                          # Bias Value 6\n","            elif lane_change == 1:\n","                feedback = 'Avoided collision by lane change'\n","                score = +1                                                          # Bias Value 7\n","        elif ttc < 0.5:\n","            feedback_1 = 'Immediate collision risk'\n","            # Check if agent_acceleration is not [0, 0] using any\n","            # Modified: Check if any element in agent_acceleration is not 0\n","            if any(x != 0 for x in agent_acceleration):\n","            # if agent_acceleration != [0, 0]:\n","                feedback = 'Emergency avoidance'\n","                score = 0                                                          # Bias Value 8\n","            else:\n","                score = 0.0\n","        else:\n","            feedback = 'Safe Path'\n","            score = -2                                                              # Bias Value 9\n","\n","        # Update the feedback and reward columns\n","        df_copy.at[idx, 'Collision_Feedback'] = feedback_1, feedback\n","        df_copy.at[idx, 'Collision_score'] = score\n","\n","    return df_copy"]},{"cell_type":"code","source":["# Call the function to process collision feedback and reward\n","Collision_feedback_df = implement_collision_feedback(collision_parameters_df_1)"],"metadata":{"id":"uVDzc0QMqYdO","executionInfo":{"status":"ok","timestamp":1750253509809,"user_tz":-330,"elapsed":2,"user":{"displayName":"Saif Nazir","userId":"15029834638479146606"}}},"execution_count":24,"outputs":[]},{"cell_type":"code","source":["data_table.enable_dataframe_formatter()\n","data_table.DataTable(Collision_feedback_df)"],"metadata":{"id":"mvv1exBGqcb6","colab":{"base_uri":"https://localhost:8080/","height":10321,"output_embedded_package_id":"10gNJ2xMTfIufsZmKNdEUtmzePsBVWyFQ"},"executionInfo":{"status":"ok","timestamp":1750253512375,"user_tz":-330,"elapsed":2564,"user":{"displayName":"Saif Nazir","userId":"15029834638479146606"}},"outputId":"181d9878-3e33-4ffc-b029-563292053207"},"execution_count":25,"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}]},{"cell_type":"markdown","source":["SECTION A.3: FEEDBACK BASED ON SPEED OPTIMIZATION\n","*   Step A.3.1: FUNCTION TO CALCULATE AGENT SPEED AND TRAFFIC DENSITY SCORE\n","*   Step A.3.2: FUNCTION TO IMPLEMENT SPEED OPTIMIZATION FEEDBACK"],"metadata":{"id":"-cVuPczPnjiy"}},{"cell_type":"code","execution_count":26,"metadata":{"id":"Oxh0zhuHzx75","executionInfo":{"status":"ok","timestamp":1750253512440,"user_tz":-330,"elapsed":6,"user":{"displayName":"Saif Nazir","userId":"15029834638479146606"}}},"outputs":[],"source":["# Step A.3.1: FUNCTION TO CALCULATE AGENT SPEED AND TRAFFIC DENSITY SCORE\n","# Define the function to calculate agent speed and traffic density score\n","def calculate_speed_and_traffic_density(trajectory_df):\n","    # Create a copy of the input dataframe to avoid modifying the original\n","    df = trajectory_df.copy()\n","\n","    df['Average_distance'] = 0.0\n","    df['Traffic_density_score'] = 0\n","    df['Agent_Speed'] = 0\n","    # Initialize the Speed_Optimization_Parameters column\n","    df['Speed_Optimization_Parameters'] = None\n","\n","\n","    # Function to calculate agent speed based on vx and vy (longitudinal and lateral velocities)\n","    def calculate_speed(vx, vy):\n","        return np.sqrt(vx**2 + vy**2)\n","\n","    # Iterate through the rows of the dataframe to calculate the required values\n","    for index, row in df.iterrows():\n","        # Extract agent state and next state\n","        state = row['state']\n","        next_state = row['next_state']\n","\n","        # Extract agent vehicle's (ego vehicle) longitudinal and lateral velocity\n","        agent_vx = state[3]  # vx of agent\n","        agent_vy = state[4]  # vy of agent\n","\n","        # Calculate agent speed\n","        agent_speed = calculate_speed(agent_vx, agent_vy)\n","\n","        # Extract other vehicles' state\n","        # The original state is a flattened array of shape (25,).\n","        # We need to reshape it to (5, 5) to represent 5 vehicles, each with 5 attributes.\n","        # Then we can select the other vehicles (excluding the ego vehicle at index 0).\n","\n","        state_reshaped = state.reshape(5, 5)  # Reshape to 5 vehicles, 5 features each\n","        other_vehicles_state = state_reshaped[1:]  # Exclude ego vehicle (index 0)\n","\n","\n","        # Extract other vehicles' state\n","        # other_vehicles_state = state[1:].reshape(-1, 5)  # Extract all other vehicles' states\n","\n","        # Calculate the distances between the agent and other vehicles\n","        distances = []\n","        for vehicle in other_vehicles_state:\n","            # Calculate the distance between the agent and other vehicles using x and y positions\n","            vehicle_x, vehicle_y = vehicle[1], vehicle[2]\n","            agent_x, agent_y = state[1], state[2]\n","            distance = np.sqrt((vehicle_x - agent_x)**2 + (vehicle_y - agent_y)**2)\n","            distances.append(distance)\n","            # print(f\"Distance between agent and vehicle {index}: {distance}\")\n","\n","        # Determine traffic density score based on the distance\n","        traffic_density_score = 1  # Default low traffic density (1)\n","        avg_distance = np.mean(distances)\n","        #print(f\"Average distance between agent and other vehicles: {avg_distance}\")\n","\n","        if avg_distance < 0.8:  # High traffic density\n","            traffic_density_score = 3\n","        elif avg_distance < 1.0:  # Medium traffic density\n","            traffic_density_score = 2\n","\n","        df.at[index, 'Average_distance'] = avg_distance\n","        df.at[index, 'Traffic_density_score'] = traffic_density_score\n","        df.at[index, 'Agent_Speed'] = agent_speed\n","        # Add the agent speed and traffic density score to the 'Speed_Optimization_Parameters' column\n","        df.at[index, 'Speed_Optimization_Parameters'] = {'Agent_Speed': agent_speed, 'Traffic_Density_Score': traffic_density_score}\n","\n","\n","    return df\n"]},{"cell_type":"code","source":["# Call the function to calculate speed and traffic density\n","Speed_parameters_df = calculate_speed_and_traffic_density(trajectory_df)"],"metadata":{"id":"S7dIIMD0qkJJ","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1750253512495,"user_tz":-330,"elapsed":20,"user":{"displayName":"Saif Nazir","userId":"15029834638479146606"}},"outputId":"e8a492e8-d0d5-4dc7-8864-f179ad34f304"},"execution_count":27,"outputs":[{"output_type":"stream","name":"stderr","text":["<ipython-input-26-2084209440>:65: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '0.3125' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n","  df.at[index, 'Agent_Speed'] = agent_speed\n"]}]},{"cell_type":"code","source":["data_table.enable_dataframe_formatter()\n","data_table.DataTable(Speed_parameters_df)"],"metadata":{"id":"mLRhQOJNqnU4","colab":{"base_uri":"https://localhost:8080/","height":10256,"output_embedded_package_id":"1v5L3lqoICLvhBK3sKKg6TEe8OqqixssU"},"executionInfo":{"status":"ok","timestamp":1750253515308,"user_tz":-330,"elapsed":2811,"user":{"displayName":"Saif Nazir","userId":"15029834638479146606"}},"outputId":"23aeb9bd-244f-498c-b492-1ece611f5436"},"execution_count":28,"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}]},{"cell_type":"code","source":["## Traffic density score list\n","## Group the data by 'episode'\n","# episode_data = Speed_parameters_df.groupby('episode')\n","# Loop through each episode\n","# for episode, data in episode_data:\n","#    # Extract lane indices\n","#     traffic_density_score_list = data['Traffic_density_score'].tolist()\n","\n","#     # Count the total number of time steps in the episode\n","#     total_timesteps = data['time_step'].max() + 1  # Assuming time_step starts from 0\n","\n","#     print(f\"Episode {episode}:Total timesteps {total_timesteps}: {traffic_density_score_list}\")"],"metadata":{"id":"-yUUPrMLERDu","executionInfo":{"status":"ok","timestamp":1750253515345,"user_tz":-330,"elapsed":3,"user":{"displayName":"Saif Nazir","userId":"15029834638479146606"}}},"execution_count":29,"outputs":[]},{"cell_type":"code","source":["## Agent's speed in each episode\n","## Group the data by 'episode'\n","# episode_data = Speed_parameters_df.groupby('episode')\n","## Loop through each episode\n","# for episode, data in episode_data:\n","#    # Extract lane indices\n","#     agent_speed_list = data['Agent_Speed'].tolist()\n","\n","#    # Count the total number of time steps in the episode\n","#     total_timesteps = data['time_step'].max() + 1  # Assuming time_step starts from 0\n","\n","#     print(f\"Episode {episode}:Total timesteps {total_timesteps}: {agent_speed_list}\")"],"metadata":{"id":"yko_9mnTF50A","executionInfo":{"status":"ok","timestamp":1750253515349,"user_tz":-330,"elapsed":2,"user":{"displayName":"Saif Nazir","userId":"15029834638479146606"}}},"execution_count":30,"outputs":[]},{"cell_type":"code","execution_count":31,"metadata":{"id":"uOHlfCEsp81h","executionInfo":{"status":"ok","timestamp":1750253515354,"user_tz":-330,"elapsed":3,"user":{"displayName":"Saif Nazir","userId":"15029834638479146606"}}},"outputs":[],"source":["# Step A.3.2: FUNCTION TO IMPLEMENT SPEED OPTIMIZATION FEEDBACK\n","def implement_speed_optimization_feedback(Speed_parameters_df):\n","    # Create a copy of the dataframe to avoid modifying the original\n","    df_copy = Speed_parameters_df.copy()\n","\n","    # Define the threshold_speed range\n","    threshold_speed_min = 0.25  # Example minimum threshold speed\n","    threshold_speed_max = 0.30  # Example maximum threshold speed\n","    threshold_speed = (threshold_speed_min, threshold_speed_max)  # Tuple representing min and max speeds\n","\n","    # Initialize columns for feedback and reward\n","    speed_optimization_feedback = []\n","    speed_optimization_score = []\n","\n","    # Iterate through the dataframe to calculate feedback and rewards\n","    for i in range(len(df_copy)):\n","        # Extract the agent speed and traffic density from the Speed_Optimization_Parameters\n","        # agent_speed = df_copy['Speed_Optimization_Parameters']['Agent_Speed']\n","        # traffic_density = df_copy['Speed_Optimization_Parameters']['Traffic_density_score']\n","        agent_speed = df_copy['Speed_Optimization_Parameters'][i]['Agent_Speed']\n","        traffic_density = df_copy['Speed_Optimization_Parameters'][i]['Traffic_Density_Score']\n","\n","        feedback = \"\"\n","        score = 0.0\n","\n","        # Check traffic density and apply corresponding logic\n","        if traffic_density == 1:  # Low traffic density\n","            if agent_speed > threshold_speed[1]:\n","                feedback = \"Low risk, High Speed-Optimization\"\n","                score = +1                                                          # Bias Value 10\n","            elif threshold_speed[0] <= agent_speed <= threshold_speed[1]:\n","                feedback = \"Low risk, moderate Speed-Optimization\"\n","                score = 0                                                           # Bias Value 11\n","            else:  # agent_speed < threshold_speed[0]\n","                feedback = \"Low risk, Low Speed-Optimization\"\n","                score = -2                                                          # Bias Value 12\n","\n","        elif traffic_density == 2:  # Medium traffic density\n","            if agent_speed > threshold_speed[1]:\n","                feedback = \"Moderate risk, High Speed-Optimization\"\n","                score = 0                                                          # Bias Value 13\n","            elif threshold_speed[0] <= agent_speed <= threshold_speed[1]:\n","                feedback = \"Moderate risk, moderate Speed-Optimization\"\n","                score = -1                                                           # Bias Value 14\n","            else:  # agent_speed < threshold_speed[0]\n","                feedback = \"Moderate risk, Low Speed-Optimization\"\n","                score = -2                                                          # Bias Value 15\n","\n","        elif traffic_density == 3:  # High traffic density\n","            if agent_speed > threshold_speed[1]:\n","                feedback = \"High risk, High Speed-Optimization\"\n","                score = +1                                                           # Bias Value 16\n","            elif threshold_speed[0] <= agent_speed <= threshold_speed[1]:\n","                feedback = \"High risk, moderate Speed-Optimization\"\n","                score = 0                                                          # Bais Value 17\n","            else:  # agent_speed < threshold_speed[0]\n","                feedback = \"High risk, Low Speed-Optimization\"\n","                score = -2                                                          # Bias Value 18\n","\n","        # Append the feedback and reward to the respective lists\n","        speed_optimization_feedback.append(feedback)\n","        speed_optimization_score.append(score)\n","\n","    # Add the new columns to the dataframe\n","    df_copy['Speed_Optimization_Feedback'] = speed_optimization_feedback\n","    df_copy['Speed_Optimization_score'] = speed_optimization_score\n","\n","    return df_copy"]},{"cell_type":"code","source":["Speed_optimization_feedback_df = implement_speed_optimization_feedback(Speed_parameters_df)"],"metadata":{"id":"LbwS2giIqvqG","executionInfo":{"status":"ok","timestamp":1750253515358,"user_tz":-330,"elapsed":2,"user":{"displayName":"Saif Nazir","userId":"15029834638479146606"}}},"execution_count":32,"outputs":[]},{"cell_type":"code","source":["data_table.enable_dataframe_formatter()\n","data_table.DataTable(Speed_optimization_feedback_df)"],"metadata":{"id":"HMaW6U2yq0Vg","colab":{"base_uri":"https://localhost:8080/","height":10321,"output_embedded_package_id":"1OF1tUBw9ukjOdBnF_7ptYVkvLEV8A6Cr"},"executionInfo":{"status":"ok","timestamp":1750253518821,"user_tz":-330,"elapsed":3459,"user":{"displayName":"Saif Nazir","userId":"15029834638479146606"}},"outputId":"6f24973e-e83b-475e-ee8a-d9d677e6de5e"},"execution_count":33,"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}]},{"cell_type":"markdown","source":["SECTION- A.4: REWARD MODELLING(HUMAN FEEDBACK)\n","*   Step A.4.1: COMBINING HUMAN FEEDBACK AND CALCULATING ADJUSTED REWARDS\n","*   Step A.4.2: RECALIBRATE REWARDS BASED ON SIMULATED HUMAN FEEDBACK"],"metadata":{"id":"RMguIvy_oi5x"}},{"cell_type":"code","execution_count":34,"metadata":{"id":"kJWJEkepqldb","executionInfo":{"status":"ok","timestamp":1750253518872,"user_tz":-330,"elapsed":2,"user":{"displayName":"Saif Nazir","userId":"15029834638479146606"}}},"outputs":[],"source":["# Step A.4.1: COMBINING HUMAN FEEDBACK AND CALCULATING ADJUSTED REWARDS\n","# Function to combine data from four dataframes and merge with trajectory_df\n","def combine_feedback_and_rewards(trajectory_df, collision_feedback_df, speed_optimization_feedback_df, lane_behaviour_feedback_df):\n","    # Create a copy of the trajectory_df to avoid modifying the original one\n","    df_copy = trajectory_df.copy()\n","\n","    # Convert the 'Collision_Feedback' column to strings\n","    #collision_feedback_df['Collision_Feedback'] = collision_feedback_df['Collision_Feedback'].apply(lambda x:''.join(map(str, x)))\n","    collision_feedback_df['Collision_Feedback'] = collision_feedback_df['Collision_Feedback'].astype(str)\n","\n","\n","    # Combine the 'Feedback' columns from the four dataframes and add to the 'Simulated_human_feedback' column\n","    df_copy['Simulated_human_feedback'] = (\n","        collision_feedback_df['Collision_Feedback'] + \";\" +\n","        speed_optimization_feedback_df['Speed_Optimization_Feedback'] + \";\" +\n","        lane_behaviour_feedback_df['Lane_feedback']\n","    )\n","\n","    # Add the values of the 'Reward' columns from the four dataframes and store the result in 'Adjusted_score' column\n","    df_copy['Adjusted_score'] = (\n","        collision_feedback_df['Collision_score'] +\n","        speed_optimization_feedback_df['Speed_Optimization_score'] +\n","        lane_behaviour_feedback_df['Lane_change_score']\n","    )\n","\n","    # Return the updated dataframe\n","    return df_copy"]},{"cell_type":"code","source":["# Call the function to combine feedback and calculate adjusted rewards\n","simulated_human_feedback_df = combine_feedback_and_rewards(\n","    trajectory_df,\n","    Collision_feedback_df,\n","    Speed_optimization_feedback_df,\n","    lane_behaviour_feedback_df\n",")"],"metadata":{"id":"pDDBxP6Mq6zJ","executionInfo":{"status":"ok","timestamp":1750253518876,"user_tz":-330,"elapsed":2,"user":{"displayName":"Saif Nazir","userId":"15029834638479146606"}}},"execution_count":35,"outputs":[]},{"cell_type":"code","source":["data_table.enable_dataframe_formatter()\n","data_table.DataTable(simulated_human_feedback_df)"],"metadata":{"id":"T7M6IqIfq8pl","colab":{"base_uri":"https://localhost:8080/","height":5030,"output_embedded_package_id":"120XZH5yZFj0zWShJOfQ5rA8DkpKFXSY-"},"executionInfo":{"status":"ok","timestamp":1750253520902,"user_tz":-330,"elapsed":2024,"user":{"displayName":"Saif Nazir","userId":"15029834638479146606"}},"outputId":"f39ca5e7-cabf-4334-b683-8dfc595c3fb8"},"execution_count":36,"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}]},{"cell_type":"code","source":["# Step A.4.2: RECALIBRATE REWARDS BASED ON SIMULATED HUMAN FEEDBACK\n","# Function to recalibrate the rewards\n","def recalibrate_rewards(df):\n","    # Create a copy of the dataframe\n","    df_copy = df.copy()\n","\n","    # Create the 'Recalibrated_rewards' column\n","    df_copy['Recalibrated_rewards'] = df_copy['reward'] + df_copy['Adjusted_score']\n","\n","    # Get the list of recalibrated rewards\n","    recalibrated_rewards_list = df_copy['Recalibrated_rewards'].tolist()\n","\n","    return df_copy, recalibrated_rewards_list"],"metadata":{"id":"E_vUgUJ2rJ7t","executionInfo":{"status":"ok","timestamp":1750253521017,"user_tz":-330,"elapsed":5,"user":{"displayName":"Saif Nazir","userId":"15029834638479146606"}}},"execution_count":37,"outputs":[]},{"cell_type":"code","source":["# Apply the function to recalibrate rewards\n","recalibrated_df, recalibrated_rewards_list = recalibrate_rewards(simulated_human_feedback_df)"],"metadata":{"id":"1tqZXWwmrNFI","executionInfo":{"status":"ok","timestamp":1750253521023,"user_tz":-330,"elapsed":2,"user":{"displayName":"Saif Nazir","userId":"15029834638479146606"}}},"execution_count":38,"outputs":[]},{"cell_type":"code","source":["data_table.enable_dataframe_formatter()\n","data_table.DataTable(recalibrated_df)"],"metadata":{"id":"oYt-iNHMfVqe","colab":{"base_uri":"https://localhost:8080/","height":5675,"output_embedded_package_id":"1cmq7QdYYi1DX_-cs3k2roNpaNprxWpMG"},"executionInfo":{"status":"ok","timestamp":1750253522880,"user_tz":-330,"elapsed":1854,"user":{"displayName":"Saif Nazir","userId":"15029834638479146606"}},"outputId":"a09e71d0-73c2-4a26-b2e4-6adae7144236"},"execution_count":39,"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}]},{"cell_type":"code","source":["recalibrated_df.to_pickle('/content/drive/MyDrive/05_zero_shot_llm_3/02_data/02_trajectories/1_human_feedback/3_Biased_Hf_D_Performance_df.pkl')          # Update directory location 2"],"metadata":{"id":"d7QitVKIfa-B","executionInfo":{"status":"ok","timestamp":1750253522931,"user_tz":-330,"elapsed":5,"user":{"displayName":"Saif Nazir","userId":"15029834638479146606"}}},"execution_count":40,"outputs":[]},{"cell_type":"code","source":["episode_data = recalibrated_df.groupby('episode')\n","# Loop through each episode\n","for episode, data in episode_data:\n","    # Extract lane indices\n","     recalibrated_reward_l = data['Recalibrated_rewards'].tolist()\n","\n","     # Count the total number of time steps in the episode\n","     total_timesteps = data['time_step'].max() + 1  # Assuming time_step starts from 0\n","\n","     print(f\"Episode {episode}:Total timesteps {total_timesteps}: {recalibrated_reward_l}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"iVwlvxBFLQVh","executionInfo":{"status":"ok","timestamp":1750253522959,"user_tz":-330,"elapsed":25,"user":{"displayName":"Saif Nazir","userId":"15029834638479146606"}},"outputId":"b2f6d7d3-2940-4136-dfc4-86cd89e7468f"},"execution_count":41,"outputs":[{"output_type":"stream","name":"stdout","text":["Episode 0:Total timesteps 40: [-1.2000000000000002, -1.0894517646168187, -1.0705603718311516, -0.1778802904515615, 1.8245128840260194, -3.177143511327331, -1.288215715870427, -0.33128610113959933, -2.3326880225258266, -2.333219316175332, -2.222765574211536, -0.31443860390794354, -1.3301044463764384, -1.3327815545414454, -1.333239040829683, -1.3333172198538463, -1.33333057972927, -1.333332862774796, -1.3333332529204158, -1.3333333195917119, -1.333333330985052, -1.3333333329320398, -1.3333333332647572, -1.3333333333216144, -1.3333333333313306, -1.333333333332991, -1.3333333333332749, -1.3333333333333233, -1.3333333333333317, -1.333333333333333, -1.333333333333333, -1.333333333333333, -1.333333333333333, -1.333333333333333, -1.333333333333333, -1.333333333333333, -1.333333333333333, -1.333333333333333, 0.688888888888889, -0.33333333333333337]\n","Episode 1:Total timesteps 40: [-3.266103790938737, -3.2849951837244036, -3.2882235004871756, -1.2666666666666666, -0.2666666666666666, -0.26666358234468557, -3.26666610160967, -3.2666665697210644, -3.2666666500959294, -1.2666666638348834, -1.266666666182748, -1.2666666665839705, -1.2666666666525348, -1.2888888888888888, -2.2888888888888888, -2.2666666666666666, -0.2666666666666666, -0.2666666666666666, -0.2666666666666666, -1.2666666666666666, -1.2666666666666666, -1.2666666666666666, -1.2888888888888888, -2.2888888888888888, -2.311111111111111, -2.311111111111111, -0.311111111111111, -2.311111111111111, -1.311111111111111, -1.311111111111111, -1.3333333333333335, -0.33333333333333337, -1.3333333333333335, -1.3333333333333335, -2.311111111111111, -0.311111111111111, -2.311111111111111, -1.3333333333333335, -0.33333333333333337, -1.3333333333333335]\n","Episode 2:Total timesteps 40: [-2.243881568716515, -1.2627729615021814, -1.266001278264953, -1.1560047242341756, -0.13720760730089732, -0.24454363655528966, -1.2628861011063526, -1.2660206124921762, -1.1560080282261338, -0.24775640729743176, 0.7124745239921375, -1.1778039641625688, 1.8614025534746927, 0.8660063458276014, -0.24399260300178094, -1.2627919226315547, -1.2660045183579092, -1.2665535133096713, -1.2666473300892331, -1.2666633622730852, -1.266666101984681, -1.2666665701691588, -1.1561184147931964, -0.13722703567982208, -0.13399872125348455, 1.8428433490480818, -0.04503451915341439, -0.13666750418733142, -0.2628760417459737, -1.2844435993429237, -1.2881292412057688, -1.2887590740373804, 0.688888888888889, -1.311111111111111, -1.3111106994047477, -4.311111002791537, -4.311111092216759, -2.2888888888888888, -1.2888888888888888, -1.2888888888888888]\n","Episode 3:Total timesteps 40: [-2.310548235383181, -4.329439628168848, -2.33266794493162, -2.333219626284024, -2.333313902136412, -0.311111111111111, -0.311111111111111, -0.311111111111111, -1.2888888888888888, -1.2888888888888888, -2.311111111111111, -2.311111111111111, -0.311111111111111, -0.311111111111111, -1.2888888888888888, -1.2888888888888888, -2.2888888888888888, -1.2888888888888888, -2.2888888888888888, -2.2666666666666666, -0.2666666666666666, -1.2666666666666666, -1.2666666666666666, -1.15611843129926, -0.2477752738811012, 0.7124713021543484, -4.288360471970985, -2.311111111111111, -0.311111111111111, -1.3333333333333335, -0.33333333333333337, -0.33333333333333337, -1.3333333220291874, -1.333333331010035, -1.3333333329323582, -1.3333333332647714, -1.3333333333216166, -1.333333333331331, -1.333333333332991, -1.3333333333332749]\n","Episode 4:Total timesteps 40: [-3.266103790938737, -4.284995183724404, -3.2882235004871756, -3.288775181839579, -3.288869457691968, -1.2666666666666666, -0.2666666666666666, -1.2666666666666666, 0.7111111111111111, 1.7333333333333334, -0.2666666666666666, -1.2666666666666666, -1.2666666666666666, -1.2666666666666666, -1.2666666666664512, -1.2666666666665982, -1.2666666666666546, -1.2666666666666644, -1.2666666666666662, -1.2666666666666662, -1.2666666666666662, -1.2666666666666662, -1.2666666666666662, -1.2666666666666662, -1.2666666666666662, -1.2666666666666662, -0.15611843128348524, -0.13722703849781848, -0.24454695711822827, -1.262886668551491, -1.2660207094618743, -1.2665562801802954, -1.2666478029148842, -1.1561152076902448, -0.24777472300684178, -1.263438255765983, -1.2661149692272007, -1.2665723880651885, -1.2666505555628973, -1.156115678085404]\n","Episode 5:Total timesteps 20: [-2.310548235383181, -2.3294396281688483, -2.33266794493162, -2.333219626284024, -2.333313902136412, -2.3333300127703946, -2.2227845305050136, -1.3144418435779688, 0.6902490937161394, 0.7111111111111111, -0.28882250616188754, -1.1783247308853504, 1.8168485189980887, -0.06790201928052741, -1.0484517884889741, 0.9314145197316366, -1.06678995524679, -1.066686677941878, -1.177218319535899, 0.022222222222222216]\n","Episode 6:Total timesteps 40: [-2.1777777777777776, -3.1777777777777776, -3.1777777777777776, -1.1570430091974955, -0.04501509397795134, -0.13666418365523947, -0.2628754743014504, -1.1738952669896783, -0.1586895964659426, -0.2666393616571584, 0.7352674937746125, -1.2660402387508967, -1.266555873268043, -1.2666476946435599, -1.1561151887875116, -0.24777471977393706, 0.7124713968908707, -1.2883604557984158, -1.2887948504790598, 0.7333333333333334, -1.2666666666666666, -1.26666643181462, -1.266666588647583, -1.266666652951102, -1.2666666643189735, 0.7111111111111111, -1.2888888888888888, 0.7333333333333334, -1.2666666666666666, -1.2666666666666666, -1.2666666666666666, -1.2666666666666666, -1.2666666666666666, -1.156118431283487, -0.24777527388099962, -1.263438349903895, 0.7111111111111111, 0.7333333333333334, -0.2666666666666666, 0.7111111111111111]\n","Episode 7:Total timesteps 23: [-2.288326013160959, -1.3072174059466257, -4.310445722709398, -2.3333333333333335, -1.3333333333333335, -1.333330249011352, -2.3333327682763363, -2.333333236387731, -2.222785081379331, -0.20389370233270032, -1.3112136233009761, -2.329553335135462, -2.332687376114409, -0.311111111111111, -2.311111111111111, -0.33333333333333337, -1.3333333333333335, -2.3333333333333335, -2.3333333195854746, -2.333333330607845, -0.311111111111111, -2.311111111111111, -0.9555555555555556]\n","Episode 8:Total timesteps 40: [-2.288326013160959, -3.3072174059466257, -3.3104457227093977, -3.3109974040618018, -3.31109167991419, -3.3111077905481725, -3.3111105436659725, -1.2888888888888888, -1.2888888888888888, -1.2888888888888888, -2.2666666666666666, -0.15613375749667735, -0.1372271059576331, -0.24454695754812594, -1.2628866685555362, -1.2660207094618494, -1.2665562801802839, -1.266647802914882, -1.1561152076902443, -0.24777472300684167, -1.263438255765983, -1.2661149692272007, 0.7111111111111111, 1.7333333333333334, -0.2666666666666666, -1.2666663876700945, -1.2666665882018098, -1.2666666529466073, -1.2666666643189286, -1.2666666662654342, -1.156118431214919, -0.1372270384861013, -0.24454695711622587, -1.262886668551149, -1.2660207094618157, -1.1560080447971042, -0.24775641012921568, -1.2634351263106542, -1.2661144344401047, -1.2665722966763657]\n","Episode 9:Total timesteps 40: [-0.1333333333333333, -0.1333333333333333, -0.24388156871651467, -1.2627729615021814, -1.266001278264953, -1.266552959617357, -1.2666472354697458, -1.2666633461037282, 0.7111111111111111, -0.28888888888888886, -0.28888888888888886, -0.2888888884437145, -1.28888888842905, -1.2888888888064356, -1.2666666666666666, -2.156133726759183, -0.247775377204832, -1.2634383509656377, -1.2661149853251135, -1.2665723908143862, -1.266650556032685, -1.2666639135488666, -1.2666661961912262, -1.2666665862679491, -1.266666652927472, -1.2666666643187998, -1.2666666662654436, -1.2666666665981023, -1.2666666666549498, -1.2666666666646647, -1.2666666666663247, -1.2666666666666084, -1.2666666666666568, -1.2666666666666648, -1.2666666666666662, -1.2666666666666662, -1.2666666666666662, -1.2666666666666662, -1.2666666666666662, -1.2666666666666662]\n","Episode 10:Total timesteps 40: [-0.20000000000000007, -3.310548235383181, -4.329439628168848, -4.33266794493162, -4.3332196262840235, -4.333313902136412, -4.333330012770395, -4.333332765888195, -4.333333236363636, -4.333333316762353, -2.3333333305015476, -1.2227850974662333, -3.2038937050817893, -1.1799302308413466, -3.288456294424905, -1.2869199237781666, -0.2666666666666666, -0.26658148699232875, -1.266647619785651, -1.266663365579233, -1.266666102082619, -1.2666665701811834, -1.2666666501783852, -1.266666663849013, 0.7111111111111111, -2.2888888888888888, -1.2666666666666666, -0.2666666666666666, -1.2666666666666666, -1.156118432816036, -0.13722703850420181, -0.24454695711826646, -1.262886668551491, -1.2660207094618743, -1.2665562801802954, -1.2666478029148842, -1.2666634430734263, -1.2666661157925088, -1.2666665725287545, -1.2666666505796051]\n","Episode 11:Total timesteps 40: [-2.310548235383181, -4.329439628168848, -4.33266794493162, -4.3332196262840235, -4.333313902136412, -4.333330012770395, -4.333332765888195, -2.311111111111111, -1.311111111111111, -1.311111111111111, -1.311111111111111, -2.311111111052495, -2.3111111110972224, -2.2888888888888888, -1.2888888888888888, -2.2666666666666666, -2.2666666666666666, -1.2666666666666666, -3.2666666666666666, 0.7111111111111111, -0.28888888888888886, -2.2888888888888888, -1.2888888888888888, -2.2888888888888888, -2.2666666666666666, -0.2666666666666666, -1.2666666666666666, -1.2666666666666666, -1.2666666666666666, -1.2666666666666666, -1.2666666666666666, -1.2666666666666662, -1.2666666666666662, -0.15611843128348524, -0.24777527388099962, -1.263438349903895, -1.2661149853142626, -1.2665723908142783, -1.2666505560326842, -1.2666639135488666]\n","Episode 12:Total timesteps 11: [-2.1570430091974955, -3.2661204243912874, -2.2849953679717263, -2.2882235023917814, -2.2887751818588904, -0.2666666666666666, -0.2666666666666666, -1.2666663353456262, -1.1561183358776814, -0.24777525732008476, -1.9333333333333333]\n","Episode 13:Total timesteps 40: [-2.243881568716515, -3.2627729615021814, -1.266001278264953, -1.266552959617357, -1.2666472354697458, -1.2666633461037282, -1.2666660992215282, 1.7111111111111112, -0.311111111111111, -1.311111111111111, -2.2888888888888888, -2.2888888888888888, -1.2888888888888888, -0.28888888888888886, -1.2888888888888888, -2.2666666666666666, -0.2666666666666666, -0.2666666666666666, -1.2666666666666666, -1.2666666666666666, -1.2666666666666666, -1.2666666666666666, -1.2666666666666662, -1.2666666666666662, -1.2666666666666662, -1.2666666666666662, -1.2666666666666662, -1.2666666666666662, -1.2666666666666662, -1.2666666666666662, -1.2666666666666662, -1.2666666666666662, -1.2666666666666662, -1.2666666666666662, -1.2666666666666662, -1.2666666666666662, -1.2666666666666662, -1.2666666666666662, -1.2666666666666662, -1.2666666666666662]\n","Episode 14:Total timesteps 12: [-1.1555555555555554, -1.266103790938737, -1.1744469483412225, -0.2693321077015085, 0.6903628039351609, -4.310563274117104, -2.2888888888888888, -1.2888888888888888, -2.1783379553379136, -0.1594487743109544, 1.8645141717095046, -2.9247994633619077]\n","Episode 15:Total timesteps 40: [-1.2000000000000002, -1.3105482353831812, -2.3294396281688483, -2.33266794493162, -2.333219626284024, -2.333313902136412, -2.3333300127703946, -2.3333327658881946, -2.3333332363636354, -2.333333316762353, -2.3333333305015476, -1.2227850974662333, -1.2038937050817893, -1.2006653883875815, 0.8206211267460269, -1.2883620677043854, -0.2869038768085207, -1.311111111111111, -1.31101604842006, -4.311091887902278, -0.33333333333333337, -1.3333333333333335, -2.3333333333333335, -1.3333333191674472, -2.333333330528087, -2.3333333328500707, -2.3333333332507102, -2.3333333333192137, -2.3333333333309203, -2.333333333332921, -0.311111111111111, -3.311111111111111, -2.311111111111111, -2.311111111111111, -2.311111111111111, -0.33333333333333337, -1.3333333333333335, -2.3333333333333335, -2.3333333333333335, -2.3333333333333335]\n","Episode 16:Total timesteps 40: [-2.243881568716515, -3.2627729615021814, -3.266001278264953, -3.266552959617357, -3.266647235469746, -3.266663346103728, -3.266666099221528, -3.2666665696969686, -3.266666650095686, -1.2666666638348811, -1.266666666182748, -1.2666666665839705, -1.2666666666525348, -1.2666666666642517, -1.266666666666254, -1.266666666666596, -1.2666666666666546, -1.2666666666666644, -1.2666666666666662, -1.2666666666666662, -1.2666666666666662, -1.2666666666666662, -1.2666666666666662, -1.2888888888888888, -2.2888888888888888, -1.2888888888888888, -1.2888888888888888, -2.2888888888888888, -2.2888888888888888, -2.311111111111111, -0.311111111111111, -0.311111111111111, -0.311111111111111, -1.311111111111111, -1.311111111111111, -1.311111111111111, -1.311111111111111, -1.311111111111111, -1.311111111111111, -1.311111111111111]\n","Episode 17:Total timesteps 6: [-2.266103790938737, -4.284995183724404, -2.2666666666666666, -1.2888888888888888, -1.2888880282201347, -2.9333333333333336]\n","Episode 18:Total timesteps 40: [-0.1333333333333333, -0.24388156871651467, -1.2627729615021814, -1.266001278264953, -1.266552959617357, -1.2666472354697458, -1.2666633461037282, -1.2666660992215282, -1.2666665696969686, -3.266666650095686, -1.2666666638348811, -1.266666666182748, -1.2666666665839705, -1.2666666666525348, -1.2666666666642517, -1.266666666666254, -1.266666666666596, -1.2888888888888888, -2.2888888888888888, -1.2888888888888888, -1.2888888888888888, -2.2666666666666666, -0.2666666666666666, -3.2666666666666666, -1.2666666666666666, -1.2666666666666666, -1.2666666666666666, -1.2666666666666666, -1.2666666666666662, -1.2666666666666662, -1.2666666666666662, -1.2666666666666662, -1.2666666666666662, -1.2666666666666662, -1.2666666666666662, -1.2888888888888888, -2.2888888888888888, -1.2888888888888888, -1.2888888888888888, -2.2888888888888888]\n","Episode 19:Total timesteps 40: [0.9327704576054036, 0.9726526706793114, -0.13344462394292567, -0.041227354494347224, -0.025469970225943883, 1.9537666581708635, -1.155096498199732, -1.2844485904932577, -2.306554788046424, -2.3103324889757184, -0.28888888888888886, -2.178333221191079, 0.8168674632333639, -0.06790176133257797, -1.1589999983380799, 0.8017191409412923, -1.1994632919840447, -1.3104546152337155, -2.329423615348362, -2.3326652083779416, -2.333219158637641, -2.3333138222211316, -2.3333299991138134, -2.333332763554446, -2.333333235964825, -2.3333333166942007, -0.311111111111111, -1.3333333333333335, -2.3333333333333335, -2.3333333333333335, -2.3333333333333335, -2.3333333333333335, -0.311111111111111, -2.311111111111111, -2.2005630306694752, -1.1816714835921966, -1.1784431661821593, -1.1778914848270983, -1.2883454443578803, -2.3072207265095646]\n","Episode 20:Total timesteps 3: [-2.1777777777777776, -2.0672295423945966, -3.9095426098241726]\n","Episode 21:Total timesteps 6: [-2.1777777777777776, -3.1777777777777776, -3.1777777777777776, -3.0672295423945966, -3.158886384992111, -2.0]\n","Episode 22:Total timesteps 26: [-0.1333333333333333, -2.243881568716515, -1.1522247261190004, -0.24710988547928636, -1.2633246428545855, -1.2660955541173418, -1.26656907025134, -1.2666499885875457, -1.2666638165791686, -1.2666661796202456, -1.2666665834361637, -1.2666666524435528, -1.2666666642361037, -1.2666666662513122, -1.2666666665956874, -1.2666666666545372, -1.2666666666645936, -1.2666666666663122, -1.2666666666666062, -1.156118431283475, -0.026678803114635552, 1.9719878197959346, -2.1335582914172457, -0.13104509459803848, -2.1327022839803598, 1.0444444444444445]\n","Episode 23:Total timesteps 40: [-2.288326013160959, -4.307217405946626, -1.1998974873262163, -3.2921060112761347, -1.2875092661128615, -0.2666666666666666, -1.2665997176036092, -1.2666507457060776, -1.266663899875239, -1.2666661933886734, -1.2666665857843253, -1.266666652844779, -1.2666666643046685, -1.266666666263029, -1.2666666665976898, -1.2666666666548791, -1.2666666666646522, 0.7111111111111111, -3.2888888888888888, -1.2888888888888888, 0.7333333333333334, 0.7111111111111111, -3.2888888888888888, -1.1783407792278147, -0.1594492612477567, 1.8645143273930476, -0.2440118490358857, -1.262792576142998, -1.266004600723909, -1.1560052916919155, 1.8390851589132486, -0.26678216032147695, 0.7352824035167004, -1.2888888888888888, -1.288797106609333, -1.2888702144799602, -1.288885666757373, -1.2888883379520548, 1.688888888888889, -1.3333333333333335]\n","Episode 24:Total timesteps 11: [-2.288326013160959, -2.3072174059466257, 0.7111111111111111, -0.2666666666666666, -1.2666666666666666, 0.7111111111111111, -1.1783550467777273, 2.8613078996732626, 1.84253697636131, 1.8652977583077712, 1.0508293364718437]\n","Episode 25:Total timesteps 40: [-2.310548235383181, -2.3294396281688483, 0.688888888888889, 0.7111111111111111, -1.2888888888888888, -1.311111111111111, -1.311111111111111, -1.311111111111111, -1.3111110968746402, -2.31111110830288, -2.31111111062743, -2.3111111110284175, -2.3111111110969795, -2.3111111111086964, -2.3111111111106983, -2.3111111111110407, -2.3333333333333335, -2.3333333333333335, -2.3333333333333335, -2.3333333333333335, -2.3333333333333335, -2.3333333333333335, -2.3333333333333335, -2.333333333333333, -2.333333333333333, -2.333333333333333, -2.333333333333333, -2.333333333333333, -2.333333333333333, -2.333333333333333, -2.333333333333333, -2.333333333333333, -2.311111111111111, -3.311111111111111, -1.311111111111111, -1.311111111111111, -2.2888888888888888, -1.2888888888888888, -1.2888888888888888, -1.2888888888888888]\n","Episode 26:Total timesteps 40: [0.9772149020498481, -0.11444194054766632, -0.13010501657056173, -0.022233416597747913, -0.003799429312096536, -0.11119751315091231, -0.24009881748353912, -1.2621265338219483, -1.2658908113798648, -1.26653408212638, -1.2666440095286382, -1.2666627948283473, -1.2666660050150513, 0.7111111111111111, -1.2888888888888888, -1.2888888888888888, -1.2888888888888888, -1.2888888888165435, -2.2888888888726537, -2.2888888888860754, -2.288888888888408, -2.2888888888888066, -2.288888888888875, -0.2666666666666666, -3.2666666666666666, -1.2666666666666666, -1.1561184328471779, 1.839066018473814, -0.26678546108151, -1.285109070332704, -1.2882429335386067, -2.2887785024213176, -2.288870025137296, -2.28888566529565, -2.288888338014731, -2.2888887947509766, -0.2666666666666666, -1.2666666666666666, -1.2666666666666666, 0.7111111111111111]\n","Episode 27:Total timesteps 40: [-3.1348207869752733, -0.13334476734494272, -0.2438816552680385, -1.2627729624175852, -1.2660012782743704, -1.2665529596174525, -1.2666472354697467, 0.7111111111111111, -0.28888888888888886, -2.2888888888888888, -2.288888874704557, -0.2666666666666666, 0.7111111111111111, -0.28888888888888886, -2.2888888888888888, -2.178340654771889, -1.269997496110975, -2.28566057212613, -2.2883372075364736, -0.2666666666666666, -1.2666666666666666, -1.2666641497648312, -1.266666198579105, -1.1561183509005506, -0.026678789375483625, -0.11510732660151335, -0.24076695860182973, -1.2622407112781344, -1.2659103229637862, -1.266537416426511, -1.2666445793213015, -1.2666628921992098, -1.156117786271405, -0.13722692827284266, -0.24454693828207663, -1.2628866653326143, -1.2660207089118058, -1.2665562800862955, -1.2666478028988206, -1.266663443070681]\n","Episode 28:Total timesteps 40: [-3.1348207869752733, -0.15679404833440114, -2.2661181406232296, -1.3091201825781171, -2.2888888888888888, -0.311111111111111, -1.3333333333333335, -1.3333333333333335, -2.333333046716775, -2.2227850028400606, -1.203893688601264, -1.2006653855699598, -1.310661941948572, -2.329459059283073, -2.3326712654804265, -2.222671958343566, -1.3144226063200306, -2.219553477195352, 0.8173954463973881, -1.2889133627508813, -2.307315166116632, -2.310462399832672, -0.33333333333333337, -1.3333333333333335, -2.3333303321819296, -2.3333327824965826, -2.3333332388178785, -2.222785081794615, -1.2038937024036676, -1.2006653879299223, -1.3106619423518673, -2.3294590593519917, -2.2221230301090222, -1.314328800943093, -0.30973158532135825, -0.33333333333333337, -1.3332570745387802, -2.333317317957177, -2.333330565666227, -2.3333328600598033]\n","Episode 29:Total timesteps 40: [-3.310548235383181, -2.3294396281688483, 0.688888888888889, -0.28888888888888886, -1.2888888888888888, -2.2666666666666666, -0.2666666666666666, -1.2666666666666666, -1.2666666525350552, -1.266666663859493, -1.2666666661829962, -1.2666666665839732, -1.2666666666525348, -1.2666666666642517, -1.266666666666254, -1.266666666666596, -1.2666666666666546, -1.2666666666666644, 0.7111111111111111, -2.2888888888888888, -2.311111111111111, -0.28888888888888886, -1.2888888888888888, -1.2888888888888888, -2.2666666666666666, -2.2666666666666666, -1.2666666666666666, -1.1561184328500014, -0.24777527389108212, -1.1528901145207815, -0.1366753571454148, -0.24445268126583963, -1.2628705579175086, -1.2660179563440743, -1.266555809704855, -1.2666477225161668, -1.2666634293342312, -1.1561178780614605, -0.1372269439586833, -0.023450470196239692]\n","Episode 30:Total timesteps 40: [-0.1333333333333333, -0.24388156871651467, -1.2627729615021814, 0.7111111111111111, 0.7333333333333334, -0.26666580599791223, -1.266663537641314, -1.266666101158231, -1.2666665697165098, -1.2666666500958832, -1.266666663834883, -1.266666666182748, -1.2666666665839705, 0.7111111111111111, -3.2888888888888888, -1.1783408084496672, -0.269997497105117, -1.2856605721363383, 0.7333333333333334, -0.26659539083755135, -1.2666507928324582, -1.2666639159428925, -1.1561179608238685, -0.24777519348238408, -1.2634383361647012, -1.2661149829663958, -1.2665723904130552, -1.26665055596412, -1.2666639135371498, -1.2666661961892238, -1.2666665862676072, 0.7111111111111111, 0.7333333333333334, -0.2666666666666666, -1.2666666666666666, -1.2666666666666666, -1.2666666666666666, 0.7111111111111111, -2.2888888888888888, -2.178340808447245]\n","Episode 31:Total timesteps 35: [-2.243881568716515, -1.2627729615021814, -1.266001278264953, -1.266552959617357, -1.2666472354697458, 0.7111111111111111, 0.7333333333333334, -0.2666666666666666, -1.2666666666666666, -1.266666665771007, -1.266666666202283, -1.2666666665841677, 0.7111111111111111, -3.2888888888888888, -2.2888888888888888, -2.2888888888888888, -2.2888888888888888, -2.2888888888888888, -2.2888888888888888, -2.2888888888888883, -2.2888888888888883, -2.2666666666666666, -2.1561337267927407, -0.2477753772054493, -1.2634383509657106, 0.7111111111111111, -1.2888176102153395, -2.288873015025725, -2.2888861381648224, -0.311111111111111, -1.2005780939702877, -0.07112327656222395, 1.9275429330606295, -0.0674518473844844, -4.0]\n","Episode 32:Total timesteps 40: [-2.310548235383181, -2.3294396281688483, -0.311111111111111, -2.2004645155911895, -1.292200390946527, -2.30787947485257, -2.310558862324487, -2.311016738289135, -2.311094983906149, -2.3111083551615255, -2.311110640151752, -1.3111110306296974, -1.3111110973577844, -1.3111111087608296, 0.6666666666666666, -2.3333333333333335, -2.3333333333333335, -0.311111111111111, -1.311111111111111, -1.311111111111111, 1.7111111111111112, -1.2666666666666666, -2.156136928571737, -0.1372271195228304, -0.2445469576365461, -1.2628866685568343, -1.266020709461929, -1.2665562801802963, -1.2666478029148842, -1.2666634430734263, -1.2666661157925088, -1.2666665725287545, 0.7111111111111111, -1.1783559462671502, -1.2699975989578967, -2.2856605731076516, -2.288337207533629, -2.288794613034266, -0.311111111111111, -0.311111111111111]\n","Episode 33:Total timesteps 40: [-3.1792652314197176, -1.2883426466135095, -2.307217590193949, -2.3104457246140035, -0.33333333333333337, -2.3333333333333335, 0.688888888888889, 0.7111111111111111, 1.688888888888889, -1.3333333333333335, -1.3333333333333335, -1.3333333333333335, -1.3333333333333335, -2.3333333333333335, -2.3333333333312063, -2.3333333333329236, -2.311111111111111, -3.311111111111111, -1.311111111111111, -1.311111111111111, -1.311111111111111, -1.311111111111111, -1.311111111111111, -1.311111111111111, -1.311111111111111, -1.311111111111111, -1.311111111111111, 0.6666666666666666, -3.3333333333333335, 0.688888888888889, -1.311111111111111, -1.311111111111111, -1.311111111111111, -1.311111111111111, -1.311111111111111, -1.311111111111111, -1.311111111111111, 1.7111111111111112, -2.2666666666666666, -1.2888888888888888]\n","Episode 34:Total timesteps 40: [-3.310548235383181, -3.3294396281688483, -3.33266794493162, -2.311111111111111, -1.311111111111111, -1.31110802678913, -4.311110546054114, -4.311111014165508, -2.2888888888888888, -0.28888888888888886, -0.28888888888888886, -0.28888888888888886, -1.2888888888888888, -1.311111111111111, -1.311111111111111, -1.311111111111111, -1.311111111111111, -2.3333333333333335, 0.688888888888889, -0.311111111111111, -0.311111111111111, -0.311111111111111, -1.311111111111111, -1.311111111111111, -1.311111111111111, -1.311111111111111, -1.311111111111111, -1.311111111111111, -1.311111111111111, -0.28888888888888886, -2.2666666666666666, -0.2666666666666666, -0.2666666666666666, -0.2666666666666666, -1.2666666666666666, -1.2666666666666666, -1.2666666666666666, -1.2666666666666662, -1.2666666666666662, -0.15611843128348524]\n","Episode 35:Total timesteps 40: [-3.266103790938737, -2.2849951837244036, -0.2666666666666666, -1.1560200711467448, -0.24775594650208266, -1.2634350304081252, -1.2661144178800425, -1.2665722938446908, -1.266650539461705, -1.2666639107170812, -1.266666195707307, -1.266666586185253, -1.2666666529133401, -1.2666666643163849, -1.266666666265031, -1.2666666665980317, -1.2666666666549378, -1.2666666666646624, 0.7111111111111111, -2.2888888888888888, -0.2666666666666666, -0.2666666666666666, -1.2666666666666666, -1.2666666666666666, -1.2666666666666666, -1.2666666666666666, -1.2666666666666666, -1.2666666666666662, 0.7111111111111111, -0.2666666666666666, -0.2666666666666666, -1.2666666666666666, 0.7111111111111111, -2.2888888888888888, -2.2888888888888888, -2.2888888888888888, -0.2666666666666666, -1.1561337237051816, -0.24777537718516773, 0.7124741227310075]\n","Episode 36:Total timesteps 11: [-2.310548235383181, -2.218891392785667, -1.3137765521459528, -2.3299913095212523, -0.311111111111111, -2.200480618956502, -1.071106612404947, 0.9275466690492459, -1.067451360284962, 0.9541961256325227, -1.9777777777777779]\n","Episode 37:Total timesteps 40: [-3.266103790938737, -0.2646409648650705, -1.2660246074762829, -1.266553200664155, -1.2666472379085292, -1.2666633461283383, -1.2666660992217764, -1.2666665696969712, -1.266666650095686, -1.2666666638348811, -1.266666666182748, -1.2666666665839705, -1.2666666666525348, -1.2666666666642517, -1.266666666666254, -1.266666666666596, -1.2666666666666546, -1.2666666666666644, -1.2666666666666662, -1.2666666666666662, -1.2666666666666662, 0.7111111111111111, -2.2888888888888888, -0.2666666666666666, -1.2666666666666666, -1.2666666666666666, -1.2666666666666666, -1.156118431298946, -0.2477752738810991, -1.263438349903896, -1.2661149853142626, -1.2665723908142783, -1.2666505560326842, -1.2666639135488666, -1.2666661961912262, -1.2666665862679491, -1.266666652927472, -1.2666666643187998, -1.2666666662654436, -1.2666666665981023]\n","Episode 38:Total timesteps 40: [-2.1570430091974955, 1.8654281738878211, -0.13334322533871923, -0.24388164422073944, -1.2627729623016206, -1.2660012782731784, -1.2665529596174405, -1.2666472354697462, -1.2666633461037282, -1.2666660992215282, -1.2666665696969686, -1.266666650095686, -1.2666666638348811, -1.266666666182748, 0.7111111111111111, -3.2888888888888888, -1.2666666666666666, -1.2666666666666666, -1.2666666666666666, -1.2666666666666666, -1.1561184312989439, -0.13722703849788254, -0.2445469571182287, -1.15233843316831, -0.2471293166762073, -1.2633279634175238, 0.7111111111111111, 0.7333333333333334, -1.2666666666666666, -1.2666640109410525, -1.2666661820407845, -1.1561183481484787, -0.24777525967210023, -1.1528901120925665, -0.13667535673047249, -0.13390444581174987, -0.1334309297365429, -0.24389824679356498, -1.2627758115893255, -1.2660017653113136]\n","Episode 39:Total timesteps 36: [-3.1348207869752733, -0.022792871755729194, -0.0038937180440926644, -0.11121362380049471, -0.12955333521819423, -0.24323561151172235, -1.2626625750158107, -1.2659824145131706, -1.2665497360241167, -1.2666466845955875, -1.2666632519658156, -1.2666660831344667, -1.2666665669478792, -1.2666666496258991, -1.2666666637546, -1.2666666661690287, -1.2666666665816262, 0.7111111111111111, -3.2888888888888888, -1.311111111111111, -3.311111111111111, -2.311111111111111, -1.2888888888888888, -1.2888888888888888, -1.2666666666666666, -1.2666666666666666, -1.2666666666666666, -3.2666666666666666, -1.2666666666666666, -1.1561184312836477, 2.8390658231385504, 2.819800453623861, -1.1779044980730489, -1.1777972737402402, 0.842954984724725, -0.9555555555555556]\n","Episode 40:Total timesteps 40: [-2.266103790938737, 0.7353590351349295, -1.2660246074762829, -1.266553200664155, -1.2666472379085292, -1.2666633461283383, -1.2666660992217764, -1.2666665696969712, -1.266666650095686, -1.2666666638348811, -0.15611843079956655, -0.026678803031941256, -0.11510732893524833, -0.24076695900063771, -1.2622407113462857, -1.2659103229754325, -1.266537416428501, -1.2666445793216417, -1.266662892199268, -1.2666660216545962, -1.2666665564416926, -3.2666666478305157, -1.2666666634477903, -1.2666666661165986, -1.2666666665726662, -1.266666666650603, -1.2888888888888888, -0.2666666666666666, -1.2666666666666666, -1.2666666666666666, 0.7111111111111111, -2.2888888888888888, -0.2666666666666666, -1.2666666666666666, -1.2666666666666666, -1.2666666666666666, -1.2666666666666666, -1.2666666666666666, -1.2666666666666666, -1.2666666666666662]\n","Episode 41:Total timesteps 40: [-3.1570430091974955, -2.2661204243912874, -1.2849953679717263, -1.2882235023917814, -1.2887751818588904, -1.2888694576921629, -1.2888855683259521, -1.2888883214437503, -1.2888887919191911, -1.2888888723179086, 0.7333333333333334, -2.1561337263090756, -0.24777537712275555, -1.2634383509515787, -1.266114985322711, -1.2665723908139754, -1.266650556032615, -1.2666639135488547, -1.1561179608080425, -0.24777519348228194, 0.7124713131062839, -1.2666666666666666, -0.26659097199939474, -1.2666507477061688, -1.2666639154761108, -1.1561179608188588, -0.2477751934820227, -1.2634383361646426, -1.266114982966386, -1.2665723904130535, -1.2666505559641195, -1.2666639135371498, -1.2666661961892238, -1.2666665862676072, -1.2666666529274133, -1.26666666431879, -1.2666666662654422, -1.2666666665981023, -1.2666666666549498, -1.2666666666646647]\n","Episode 42:Total timesteps 14: [-3.1792652314197176, -2.2883426466135095, -1.307217590193949, 0.7111111111111111, -1.288798235337572, -2.311111111111111, -1.2005745465365023, -0.07112272202933623, -1.0490034410798992, -1.1557717587076808, -1.1740172080277378, 0.799154824573726, 0.8000983411240012, -2.9525720051028306]\n","Episode 43:Total timesteps 40: [-0.20000000000000007, -1.2000000000000002, -1.3105482353831812, -2.3294396281688483, -2.33266794493162, -2.333219626284024, -2.333313902136412, -2.2227817773872136, -1.314441373102528, -2.330104919600864, -2.332781635409949, -2.3332390546491593, -0.311111111111111, -2.311111111111111, -2.3111108767370827, -2.3111110330968003, -2.3111110973955857, -2.311111108763417, -2.3111111107098785, -1.3111111110425449, -1.311111111099394, -0.20056287572592746, -0.1816714829419207, -1.288991401562614, -0.33142136160258096, -4.332710694300939, -2.3332231877506286, -2.3333144720188246, -2.333330109764688, -2.3333327824594234, -2.3333332391954236, -2.3333333172462716, -2.3333333305842436, -2.333333332863546, -2.3333333332530524, -2.3333333333196142, -2.333333333330989, -0.311111111111111, -3.311111111111111, -1.311111111111111]\n","Episode 44:Total timesteps 40: [-2.310548235383181, -1.3090854093095148, -3.310469051920727, -2.2888888888888888, -0.28888888888888886, -1.2888858093657367, 0.688888888888889, -1.311111111111111, -0.311111111111111, -0.3111111106611011, -1.2888888888888888, 0.688888888888889, -0.311111111111111, -0.311111111111111, -1.2888888888888888, -2.178355921311857, 0.8612679452117101, -2.2445634065441764, -1.2628868498946821, -1.2660207113347428, -1.15600804480956, -0.13720817474608793, -0.13399549814180656, -0.24399472489166607, -1.2627922985611901, -1.26600458274083, -1.266553524313406, -1.2666473319696565, -1.2666633625944277, -1.2666661020395944, 0.7111111111111111, -0.28888888888888886, -2.2888888888888888, -0.2666666666666666, -0.2666666666666666, -1.2666666666666666, -1.2666666666666666, -1.2666666666666666, -1.2666666666666666, -1.2666666666666573]\n","Episode 45:Total timesteps 40: [-2.243881568716515, -1.2627729615021814, -1.266001278264953, -1.266552959617357, -1.2666472354697458, -1.2666633461037282, -1.2666660992215282, -1.2666665696969686, -3.266666650095686, -1.2666666638348811, -1.266666666182748, -1.2666666665839705, -1.2666666666525348, -1.2666666666642517, -1.266666666666254, -1.266666666666596, -1.2666666666666546, -1.2666666666666644, -1.2666666666666662, -1.2666666666666662, -1.2666666666666662, -1.2666666666666662, -1.2666666666666662, -1.2666666666666662, -1.2666666666666662, -1.2666666666666662, -1.2666666666666662, -1.2666666666666662, -1.2666666666666662, -1.2888888888888888, -2.2888888888888888, -2.2666666666666666, -0.2666666666666666, -1.2666666666666666, -1.2666666666666666, -1.2666666666666666, -1.2666666666666666, -1.2666666666666666, -1.2666666666666662, -1.2666666666666662]\n","Episode 46:Total timesteps 40: [-2.243881568716515, -0.1522247261190003, -2.136561650096105, -2.1338850146857373, -2.1334276091857216, -2.243897679350497, -3.2627757146199814, -3.266001748740394, -3.2665530400160745, -3.2666472492089405, -3.266663348451595, -3.266666099622751, -3.266666569765533, -3.266666650107403, -1.2666666638368835, -1.2666666661830899, -1.2666666665840292, -1.266666666652545, -1.2666666666642534, -1.2666666666662545, -1.2666666666665964, -1.2666666666666546, -0.15611843128348324, -2.2477752738809995, -3.263438349903895, -3.2661149853142626, -1.2888888888888888, -0.28888888888888886, -2.311111111111111, -0.311111111111111, -0.311111111111111, -0.3111110998064799, -1.311111108787808, -1.2888888888888888, 0.688888888888889, -0.311111111111111, -1.2888888888888888, -1.2888888888888888, -2.2888888888888888, -1.2666666666666666]\n","Episode 47:Total timesteps 12: [-3.310548235383181, -4.329439628168848, -4.33266794493162, -1.2226713909008424, -3.0933260385843826, -3.071222439669927, -2.067445194672551, -3.1773479433263807, -0.17539618280125613, -0.15665783007600487, 0.8445443211181939, -2.9555555555555557]\n","Episode 48:Total timesteps 40: [-3.1348207869752733, -0.24389820216906521, -1.2627731457495042, -1.2660012801695588, -1.2665529596366683, -1.2666472354699407, -1.26666334610373, -1.2666660992215282, -1.2666665696969686, 0.7111111111111111, -1.2888888888888888, 0.688888888888889, -2.311111111111111, -0.311111111111111, -3.2888888888888888, -1.2888888888888888, -2.2888888888888888, -2.2888888888888888, -2.1783406535214476, 0.8612880235545429, -0.2445632406396815, -1.2628868481294035, -1.2660207113165796, -1.2665562801990973, -1.2666478029150738, -1.266663443073428, -1.2666661157925088, -1.2666665725287545, -1.2666666505796051, -1.2666666639175772, -1.2666666661968797, -1.2666666665863855, -1.1561184312697663, -0.13722703849547413, -0.13399872173464622, -0.13344704038257438, -0.24390099991342395, 0.7131334916679828, -1.2882473968214234, -1.2887755198518969]\n","Episode 49:Total timesteps 5: [-3.0450073201723744, -2.0261159273867073, -2.133435846007117, -2.15177555744038, -0.9777777777777777]\n","Episode 50:Total timesteps 40: [-2.288326013160959, -0.33130763153173726, -4.33269127414295, -4.333219867330822, -2.311111111111111, -1.311111111111111, -0.28888888888888886, -1.2888888888888888, -2.2888888888888888, -2.2888888884915777, -2.1783406530378793, -1.2699974960206295, -1.2856605721119867, -1.2883372075340698, -1.2887946130360879, 0.7333333333333334, -1.2666666666666666, -1.2666664323067676, -3.2666665886547706, -3.266666652951554, -1.2666666643190427, -1.2666666662654462, -1.2666666665981023, -1.2666666666549498, -1.2666666666646647, -1.2888888888888888, -2.2888888888888888, -2.2888888888888888, -2.2888888888888888, -2.2888888888888888, -2.2888888888888888, -0.2666666666666666, -3.2666666666666666, -1.2666666666666666, -0.2666666666666666, -1.2666666666666666, -1.2666666666666666, -1.2666666666666666, -1.2666666666666662, -1.2888888888888888]\n","Episode 51:Total timesteps 40: [0.9772149020498481, -0.11444194054766632, -0.24065325195374287, 0.7136886154176678, 0.7333333333333334, -1.266555435956806, -1.2666446741924804, -1.266662877568335, -1.2666660188423862, -1.266666555957971, -1.2666666477478215, -1.266666663433658, -1.2666666661141837, -1.2666666665722537, -0.15611843126735137, -0.2477752738782426, -1.2634383499034239, -1.2661149853141822, -1.2665723908142645, -1.2666505560326815, -1.2666639135488662, -1.2666661961912258, -1.2666665862679491, -3.266666652927472, -1.2666666643187998, -1.2666666662654436, -1.2666666665981023, -1.2666666666549498, -1.2666666666646647, -1.2666666666663247, -0.15611843128342684, -0.24777527388098974, -1.2634383499038933, 0.7111111111111111, 0.7333333333333334, -1.2666666666666666, -1.2666641050774765, -1.2666661981278295, -1.266666586287489, -1.2666666529276687]\n","Episode 52:Total timesteps 40: [-3.266103790938737, -1.2646409648650705, -3.266024607476283, -1.266553200664155, -1.2666472379085292, -1.2666633461283383, -1.2666660992217764, -1.2666665696969712, -1.266666650095686, -1.2666666638348811, -1.266666666182748, -1.2666666665839705, -1.2666666666525348, -1.2666666666642517, -1.266666666666254, -0.15611843128341485, -0.24777527388098786, -1.2634383499038933, -1.2661149853142621, -1.2665723908142783, -1.2666505560326842, -1.2666639135488666, -1.2666661961912262, -1.156118350884768, -0.1372270247586237, -0.1339987193871801, -0.24399527536460142, -1.2627923926305384, -1.266004598816175, -1.2665535270604935, -1.2666473324391014, -1.2666633626746502, -1.2666661020533039, -1.266666570180886, -3.266666650178382, -1.2666666638490125, -1.2666666661851629, -1.2666666665843835, -1.2666666666526054, -1.2666666666642636]\n","Episode 53:Total timesteps 40: [-3.1348207869752733, 1.843205951665599, -0.15556544756094148, -0.2661038664429616, -1.2849951845238428, -1.2882235004954006, -1.2887751818396627, -1.2888694576919688, -1.2888855683259504, -1.2888883214437503, -1.2888887919191911, 0.7333333333333334, -1.2666666666666666, -1.2666666666666666, -1.2666666666666666, -1.2666666666666666, -1.2666666666644946, -1.2666666666662563, -1.266666666666596, -1.2666666666666546, 0.7111111111111111, -3.2888888888888888, -1.2888888888888888, -0.2666666666666666, -1.2666666666666666, -1.2666666666666666, -1.2666666666666666, -1.2666666666666666, 0.7111111111111111, -1.2888888888888888, -2.2888888888888888, -0.2666666666666666, -1.2666666666666666, -1.2666666666666666, -1.2666666666666666, -1.2666666666666666, -1.156118431283644, -0.13722703849781903, -0.1339987217350469, -0.022898804999461397]\n","Episode 54:Total timesteps 6: [-3.0894517646168187, -2.0705603718311516, -2.06733205506838, -2.066780373715976, -0.04569815318961423, -3.8649797808181017]\n","Episode 55:Total timesteps 40: [-3.266103790938737, -1.2849951837244036, -1.2882235004871756, -1.2887751818395792, 0.7333333333333334, -1.2666666666666666, -1.2666663353413394, -3.2666665720838353, -3.2666666501197685, -1.266666663835124, -1.2666666661827501, -1.2666666665839705, -1.2666666666525348, -1.2666666666642517, -1.2888888888888888, -0.2666666666666666, -0.2666666666666666, -0.2666666666666666, -0.2666666666666666, -1.2888888888888888, -2.2888888888888888, -3.2888888888888888, -1.2888888888888888, -1.2888888888888888, 0.7333333333333334, -1.2666666666666666, -1.2666666666666666, -0.2666666666666666, -1.2666666666666666, -1.2666666666666666, -1.2666666666666666, -1.2666666666666662, -1.2666666666666662, -1.2888888888888888, -0.2666666666666666, -0.2666666666666666, -0.2666666666666666, -0.2666666666666666, -1.2666666666666666, -1.2666666666666666]\n","Episode 56:Total timesteps 40: [-1.2000000000000002, -1.2000000000000002, -1.3105482353831812, -0.3090854093095149, -2.310469051920727, -2.3109976451086, -2.2005434461290814, -1.292216397772795, -2.307882226903306, -2.31055933278901, -2.311016818687742, -2.311094997645343, -0.33333333333333337, -1.3333333333333335, -2.3333333333333335, -0.311111111111111, -1.311111111111111, -1.311111111111111, -1.311111111111111, -1.311111111111111, -1.311111111109351, -1.3111111111107712, -1.3111111111110527, -1.3111111111111011, 0.7111111111111111, -0.311111111111111, -0.33333333333333337, -2.3333333333333335, -2.2227852818623486, -1.2038937059355552, -1.311213623789759, -2.3295533352182076, -2.332687376128541, -0.311111111111111, -1.311111111111111, -1.200559807174836, 1.839064400629356, -1.2667853847848072, -2.285109054435409, -0.2666666666666666]\n","Episode 57:Total timesteps 40: [-3.1792652314197176, 0.8426842960918286, -0.15556864593923436, -0.15555562080974472, -0.1555555558464431, -0.2661037909406474, -1.2849951837244236, -1.2882235004871756, 0.688888888888889, -2.2005587488404585, -1.1816682297790195, -1.0678943635296396, -1.0484517596887053, -1.0451292474720986, -0.15510970460808837, -1.2844523061546145, -2.306555434994853, -2.3103325996620754, -2.310978072663949, -0.33333333333333337, -1.3333333333333335, -2.333332905540593, -2.2227849860584774, -1.31444192116951, -2.3301050132574455, -2.33278165141474, -2.3332390573841897, -2.3333172226828163, -2.333330580212708, -2.33333286285741, -2.3333332529345334, -2.333333319594124, -2.333333330985464, -0.311111111111111, -3.311111111111111, -2.311111111111111, -0.28888888888888886, -1.2888888888888888, -1.2888888888888888, -1.2888888888888888]\n","Episode 58:Total timesteps 40: [-2.310548235383181, -1.3090854093095148, -4.310469051920728, -4.3109976451086, -4.3110916823529735, -2.2888888888888888, -0.17835538495161174, -0.1594492311078901, -0.2667691632010456, 0.7352451250364452, -1.2660440291966912, 0.7111111111111111, -0.28888888888888886, 0.7333333333333334, -1.2666666666666666, -1.2666666666666666, -1.2666666529192723, -1.2666666639411814, -1.2666666661971173, -1.2666666665863882, -1.1561184312697663, -0.13722703849547413, -0.24454695711782737, -1.2628866685514226, -1.2660207094618623, -1.2665562801802936, -1.2666478029148838, -1.2666634430734263, -1.2666661157925088, -1.2666665725287545, -3.266666650579605, -1.2666666639175772, -1.2666666661968797, -1.2666666665863855, -1.2666666666529478, -1.2666666666643223, -1.266666666666266, -1.2666666666665982, -1.266666666666655, -1.2666666666666648]\n","Episode 59:Total timesteps 40: [-0.20000000000000007, -1.2000000000000002, -1.3105482353831812, -2.3294396281688483, -2.33266794493162, -0.22267139090084243, 1.8168630158579258, -1.289004366126985, -2.2870132563678003, -3.2882665671137756, -3.2887787309682706, -3.2888700247853717, -1.2666666666666666, -0.2666666666666666, -1.2666666666666666, 0.7111111111111111, -1.2888888888888888, -1.2888888888888888, -2.2666666666666666, -2.2666666666666666, -1.2666666666666666, -1.2666666666666666, 0.7111111111111111, -1.2888888888888888, -2.2888888888888888, -2.311111111111111, -0.311111111111111, -1.3333333333333335, -1.3333333333333335, -2.3333333333333335, -0.311111111111111, 1.7111111111111112, -1.2666666666666666, -0.2666666666666666, -1.15611862192686, -0.24777527511313158, -1.2634383499164779, -1.2661149853143914, -1.2665723908142796, -1.2666505560326842]\n","Episode 60:Total timesteps 40: [-2.288326013160959, -2.3072174059466257, -2.1998974873262163, -1.2921060112761347, -2.197315127768237, 0.7951759781692255, -1.3111351142636716, -2.329537307860765, -2.3326846083016033, -0.311111111111111, -2.311111111111111, 0.7111111111111111, -1.2666666666666666, -0.2666666666666666, -0.2666666666666666, -0.2666666666666666, -1.2666666662240194, -1.2888888888888888, -0.28888888888888886, -0.28888888888888886, -1.2888888888888888, -2.2888888888888888, -2.2666666666666666, -0.2666666666666666, -1.2888888888888888, -0.28888888888888886, -1.2888888888888888, -2.311111111111111, -0.311111111111111, 0.6666666666666666, -1.3333333333333335, -1.3333333333333335, -3.3333333333333335, 0.688888888888889, -1.311111111111111, -3.311111111111111, -1.311111111111111, -1.311111111111111, -1.311111111111111, -1.311111111111111]\n","Episode 61:Total timesteps 17: [-0.1333333333333333, -2.243881568716515, -3.2627729615021814, -3.266001278264953, -3.266552959617357, -3.266647235469746, -3.266663346103728, -3.266666099221528, -3.2666665696969686, -3.266666650095686, -1.2666666638348811, -1.266666666182748, -0.1561184312007894, -2.1372270384836867, -2.244546957115813, -3.2628866685510785, -3.9333333333333336]\n","Episode 62:Total timesteps 35: [-2.243881568716515, -3.2627729615021814, -3.266001278264953, -3.266552959617357, -0.28888888888888886, -1.311111111111111, 0.7111111111111111, -2.311111111111111, -1.311111111111111, -2.3333333333333335, -1.3333333333333335, -2.3333333333333335, -3.3333333333333335, -2.3333333333333335, -2.333333333333168, -2.333333333333265, -2.3333333333333215, -2.22278509795015, -1.203893705164485, -1.2006653884017133, -1.3106619424324908, -2.2189108239825877, -1.3137798727088916, -2.2194436415832093, -1.3138709249680391, -2.3300074367262154, -2.332764976733594, -2.333236207877366, -2.3333167357356257, -2.333330496999162, -2.333332848637194, -2.3333332505044657, -2.333333319178854, 0.688888888888889, -2.9555555555555557]\n","Episode 63:Total timesteps 5: [-2.243881568716515, -3.2627729615021814, -3.266001278264953, -0.15600472423417566, -2.9333333333333336]\n","Episode 64:Total timesteps 7: [-2.1333333333333333, -2.1333333333333333, -2.1333333333333333, -2.1333333333333333, -0.15704300919749536, 0.844433010432835, -0.9333333333333333]\n","Episode 65:Total timesteps 40: [-0.1333333333333333, -2.243881568716515, -3.2627729615021814, -0.28888888888888886, -1.311111111111111, -0.311111111111111, -0.3111080761970363, -3.31111054655299, -4.3111110141705415, -4.311111094540425, -2.3111111082793285, -2.311111110627192, -2.3111111110284153, -2.3111111110969795, -2.3333333333333335, -2.3333333333333335, -1.3333333333333335, -1.3333333333333335, -2.3333333333333335, -2.3333333333333335, -2.3333333333333335, -2.333333333333333, -2.333333333333333, -2.333333333333333, -2.333333333333333, -2.333333333333333, -2.333333333333333, -2.333333333333333, -2.333333333333333, -2.333333333333333, -2.333333333333333, -2.333333333333333, -2.333333333333333, -2.333333333333333, -2.333333333333333, -2.333333333333333, -2.333333333333333, -2.333333333333333, -2.333333333333333, -2.333333333333333]\n","Episode 66:Total timesteps 3: [-2.1333333333333333, -2.1333333333333333, -0.9555555555555556]\n","Episode 67:Total timesteps 40: [-2.2, -1.1792652314197176, -0.17778921178938722, -1.2883260997124828, -2.3072174068620295, -2.310445722718815, -0.28888888888888886, -0.28888888888888886, -0.28888580456990887, -1.2666666666666666, -0.2666666666666666, -1.2666666666666666, -1.2666666662262847, -1.1561184308153725, -0.13722703841518846, -0.24454695710409702, -1.262886668549076, -1.2660207094614617, -1.2665562801802253, -1.2666478029148718, -1.266663443073424, -1.2666661157925083, 0.7111111111111111, 0.7333333333333334, -0.2666666666666666, -1.2666666666666666, -1.1561184324717728, -0.13722703848939355, -0.244546957115917, -1.2628866685510909, -1.2660207094618054, -1.2665562801802839, 0.7111111111111111, -1.2888888888888888, -0.28888857413381264, -3.2888887971378353, -1.2666666666666666, -0.2666666666666666, -3.2666666666666666, -1.2666666666666666]\n","Episode 68:Total timesteps 40: [-2.243881568716515, -1.2627729615021814, -1.266001278264953, -1.1560047242341756, -0.13720760730089732, -0.1339954011721084, -0.13344647293750445, -0.24390090294373767, -1.2627762654941392, -1.266001842878306, -1.2665530561031364, -1.2666472519580299, 0.7111111111111111, 0.7333333333333334, -1.2666666666666666, -1.2666666666666666, -1.1561184297226728, -0.13722703801960423, -0.24454695703563578, -1.1523384331541902, -0.0260328459074316, 2.9720981162012627, 2.953381927080197, -1.1551323995149878, -1.2844545898163013, -2.306555812292141, -2.310332663996931, -0.28888888888888886, -0.28888888888888886, -1.2888852403790652, -1.2888882274153213, 0.688888888888889, -0.28888888888888886, -0.28888888888888886, 0.688888888888889, -2.311111111111111, -3.311111111111111, -0.28888888888888886, -2.2888888888888888, 0.7333333333333334]\n","Episode 69:Total timesteps 2: [-2.1792652314197176, -2.839357720087481]\n","Episode 70:Total timesteps 3: [-2.266103790938737, -2.2646409648650705, -3.9333333333333336]\n","Episode 71:Total timesteps 19: [-3.266103790938737, -1.3090854093095148, -1.1999130803290456, 1.7947145952097951, -0.20065724237259897, -1.2001104426352418, -1.2000188640017617, -1.310551458978063, -2.329440179043023, -2.3326680390695325, -2.3332196423710854, -2.3333139048855016, -2.333330013240182, -2.2227845305852947, -1.203893608208506, -1.2006653718330775, -0.3106619396011059, -1.3294590588819188, -1.8887896966953592]\n","Episode 72:Total timesteps 12: [-2.266103790938737, -3.2849951837244036, -3.2882235004871756, -1.2666666666666666, -0.2666666666666666, -1.2666635823446857, -1.2666661016096699, -1.2666665697210644, -1.2666666500959294, -1.2666666638348834, -1.1561184307995664, 1.0444444444444445]\n","Episode 73:Total timesteps 40: [-2.1570430091974955, -0.15556698956716497, -0.26610387749026065, -1.2849951846398073, -1.288223500496593, 0.7333333333333334, -0.2666666666666666, -1.2666635823476868, -1.2666661016097, -1.2666665697210644, -1.2666666500959294, -1.2666666638348834, -1.266666666182748, -1.2666666665839705, -1.2666666666525348, -1.2666666666642517, -0.15611843128307268, -0.24777527388092935, -1.263438349903883, -1.2661149853142608, -1.2665723908142779, -1.2666505560326842, -1.2666639135488666, -1.2666661961912262, -1.2666665862679491, -3.266666652927472, -1.2666666643187998, -1.2666666662654436, -1.2666666665981023, -1.2666666666549498, -1.2666666666646647, -1.2666666666663247, -1.2666666666666084, -1.2666666666666568, -1.2666666666666648, -1.2666666666666662, -1.2666666666666662, -1.2666666666666662, -1.2666666666666662, -1.2666666666666662]\n","Episode 74:Total timesteps 40: [-2.310548235383181, -4.329439628168848, -4.33266794493162, -1.2226713909008424, -3.3144225093507456, -4.330101696007623, -1.311111111111111, -1.2888888888888888, -1.2888888888888888, -1.2888864185444282, -2.2666666666666666, -0.2666666666666666, -1.2666666666666666, -1.2666666666666666, -1.2666666662891641, -1.2666666665982755, -1.2666666666549404, -1.2666666666646624, -1.2666666666663242, -1.266666666666608, -1.2666666666666568, -1.2666666666666648, -1.2666666666666662, -1.2666666666666662, -1.2666666666666662, -1.2666666666666662, -1.2666666666666662, -1.2666666666666662, -0.15611843128348524, -0.13722703849781848, -0.24454695711822827, -1.262886668551491, -1.2660207094618743, -1.2665562801802954, -1.2666478029148842, -1.1561152076902448, -0.24777472300684178, -1.263438255765983, -1.2661149692272007, -1.2665723880651885]\n","Episode 75:Total timesteps 40: [-3.1792652314197176, -1.1777892117893871, -1.1777778352366215, 0.7985137846576715, -3.3105648583539464, -2.3294398123040385, -2.3326679468350706, -2.333219626303323, -2.333313902136607, -0.311111111111111, -2.311111111111111, -2.2005629337052044, -1.2922197027564475, -2.307882791526787, -2.310559429274893, -2.3110168351760274, -0.28888888888888886, -0.28888888888888886, -0.28888865452861057, -3.288888810876923, -3.2888888751737637, -1.288888886541263, -1.2888888884876684, -1.2888888888203245, -1.2666666666666666, -0.28888888888888886, -0.28888888888888886, -0.28888888888888886, -1.2666666666666666, -2.2666666666666666, -0.2666666666666666, -1.2888888888888888, -0.2666666666666666, -2.2666666666666666, -0.2666666666666666, -0.2666666666666666, -1.2666666666666666, -1.2888888888888888, -0.28888888888888886, -0.28888888888888886]\n","Episode 76:Total timesteps 40: [-3.266103790938737, -2.2849951837244036, -0.2666666666666666, -1.2665759712930984, -1.1560991556075009, -0.24777195432407328, -1.2634377824690315, -1.2661148883446698, -1.2665723742432986, -1.2666505532008987, -1.266663913064948, -1.2666661961085302, -1.2666665862538173, -1.266666652925057, -1.2666666643183873, -1.2666666662653734, -1.2666666665980904, -1.2666666666549475, -1.2666666666646638, 0.7111111111111111, -2.2888888888888888, -2.2888888888888888, -2.2888888888888888, -2.1783406535214818, -1.2699974961033234, -2.2856605721261185, -2.2883372075364847, -2.2887946130365004, -2.178324542871725, 0.8612907944493076, -0.24456277025246764, -1.2628867677322888, -1.2660206975774022, -1.266556277851231, -1.2666478025138512, -1.2666634430048638, -1.266666115780792, -1.266666572526752, -1.2666666505792628, -1.2666666639175186]\n","Episode 77:Total timesteps 32: [-0.1333333333333333, -0.24388156871651467, -1.2627729615021814, 0.7111111111111111, -1.2887981935153205, -1.2888696946405669, -1.1783373345123827, 1.8612888081050492, -0.24456314193808615, -1.2628868315401536, -1.2660207084846062, -1.2665562797151768, -1.2666478028323778, -1.2666634430592962, -1.2666661157900938, -1.2666665725283415, -1.2666666505795345, -1.2666666639175652, -1.2666666661968775, -1.266666666586385, 0.7111111111111111, -1.2666666666666666, -1.2666666666666666, -1.2666666666666666, -1.156118432552042, -0.026678803117970662, -0.11510732894938502, 1.8460700103557608, 0.9555169926448963, -0.1365732291470868, -0.26285993111824546, 0.022222222222222216]\n","Episode 78:Total timesteps 3: [-3.1792652314197176, -1.2012384927788458, -3.7561251808526834]\n","Episode 79:Total timesteps 40: [-1.2000000000000002, -1.2000000000000002, -3.310548235383181, -4.329439628168848, -4.33266794493162, -4.3332196262840235, -4.333313902136412, -4.333330012770395, -4.333332765888195, -4.333333236363636, -4.333333316762353, -2.3333333305015476, -2.3333333328494144, -2.3333333332506374, -2.3333333333192017, -2.3333333333309185, -2.3333333333329205, -2.333333333333263, -2.3333333333333215, -2.3333333333333313, -2.311111111111111, -2.311111111111111, -0.311111111111111, -0.311111111111111, -1.311111111111111, -1.311111111111111, -1.311111111111111, -1.311111111111111, -1.311111111111111, -1.311111111111111, -1.2888888888888888, -2.2888888888888888, -1.2888888888888888, -2.311111111111111, -0.311111111111111, -0.311111111111111, -0.311111111111111, -1.3333333333333335, 0.688888888888889, -0.311111111111111]\n","Episode 80:Total timesteps 40: [-0.0450073201723743, -0.13666416276988846, -2.2628754741759654, -3.2844435023719996, -0.17758098925160548, 2.8614177661748585, -2.244541067971064, -1.2628830572461687, -1.2660200634743806, -1.2665561694902219, -1.266647783996227, -1.2666634398404195, 1.7111111111111112, 1.688888888888889, -1.311111111111111, -1.3333333333333335, -1.3333333333333335, -2.3333333333333335, -3.3333333333333335, -2.3333333333333335, -2.3333333333331807, -2.3333333333332673, -2.2227850979501405, -1.3144419405476646, -2.3301050165705615, -2.3327816519809295, -2.3332390574809447, -2.333317222699351, -2.3333305802155335, -2.3333328628578927, -2.3333332529346156, -2.3333333195941384, -2.3333333309854667, -2.3333333329321104, -2.333333333264769, -2.222785097938435, -1.3144419405456644, -2.3301050165702195, -2.332781651980871, -0.311111111111111]\n","Episode 81:Total timesteps 40: [-2.266103790938737, -1.2849951837244036, -1.311111111111111, -1.3110204157375431, -4.3110919168627895, -2.2888888888888888, -1.2888888888888888, 0.7333333333333334, -0.2666666666666666, -1.2666666666666666, -1.2666666666666666, -1.2666666666085336, -1.2666666666527826, -1.2666666666642543, -1.266666666666254, -1.266666666666596, -1.2666666666666546, -1.2666666666666644, -1.2666666666666662, -1.2666666666666662, -1.2666666666666662, -1.2666666666666662, -1.2666666666666662, -1.2666666666666662, -1.2666666666666662, -1.2666666666666662, -1.2666666666666662, -0.15611843128348524, -0.13722703849781848, -0.24454695711822827, -1.262886668551491, -1.2660207094618743, -1.2665562801802954, 0.7111111111111111, 0.7333333333333334, -0.2666666666666666, -1.2666666666666666, -1.2666666525157448, -1.2666666639371127, -1.266666666197077]\n","Episode 82:Total timesteps 19: [-2.243881568716515, -3.2627729615021814, -0.15545304288177186, -2.24766156683169, -3.263418918706974, -3.266111664751324, -3.2665718233691394, -3.266650459062986, -3.266663896977886, -0.28888888888888886, -0.311111111111111, -1.311111111111111, -1.311111111111111, -2.2888888888888888, -0.28888888888888886, -0.28888888888888886, -0.28888888888888886, -1.2888888888888888, -1.9777777777777779]\n","Episode 83:Total timesteps 13: [-3.1348207869752733, 0.8666552326550573, -0.022785135287955782, -0.0038937052076825074, -0.11121362378492206, -0.2401015706013392, -1.262127004297389, -1.2658908917785823, -1.2665340958655746, -1.266644011876505, -1.26666279522957, -1.2666660050836156, 0.04444444444444443]\n","Episode 84:Total timesteps 40: [-2.1570430091974955, 0.8209837294433765, -1.1777876697831635, -1.1777778279439381, -0.1777777780026243, 1.7985124703048272, 0.8209837338908795, -1.0672362919471339, 0.9726451198722725, -1.1334446459730319, -1.2623238656759028, 0.6915631251485269, 1.6666666666666665, -2.3332286952756975, -4.333310965650389, -4.3333294647984255, -2.311111111111111, -1.311111111111111, -1.311111111111111, -1.3111111101956205, -1.3111111105709856, -1.311111111014939, -1.3111111110946374, -1.2005628757251143, -0.29221971832496296, 0.668026854923017, -1.3328049164465114, -3.3332392976889267, -1.311111111111111, -1.311111111111111, 0.7111111111111111, -2.2888888888888888, -2.2888888888888888, -2.2888888888888888, -2.1783406531205753, 0.8612880234052717, -2.2445632406297564, -1.2628868481274202, -1.2660207113162376, -1.266556280199039]\n","Episode 85:Total timesteps 40: [-1.1555555555555554, 0.8651792130247268, -0.24389820216906521, 0.7131738126960566, -1.288246413696637, -1.2887754186341889, -1.2888694600877795, -1.288885568350127, -1.2888883214439941, -1.2888887919191934, -1.2888888723179086, -1.2666666666666666, -1.2888888888888888, -0.28888888888888886, 0.688888888888889, -2.311111111111111, -1.311111111111111, -2.2888888888888888, -1.2666666666666666, -1.2666666666666666, -1.2666666666666666, -1.2666666666666666, -1.2666666666666666, -1.2666666666666666, -1.2666666666666666, -1.2666666666666662, -1.2666666666666662, -1.2666666666666662, -1.2666666666666662, 0.7111111111111111, -3.2888888888888888, -2.2888888888888888, -0.2666666666666666, -1.2666666666666666, -1.2666666666666666, -1.2666666666666666, -1.2666666666666666, -1.2666666666666666, -1.2666666666666666, -1.2666666666666662]\n","Episode 86:Total timesteps 6: [-2.243881568716515, -1.2627729615021814, 0.7111111111111111, -1.2887981935153205, -2.178321377829723, -1.9555555555555555]\n","Episode 87:Total timesteps 40: [-2.1570430091974955, -3.2661204243912874, -2.2849953679717263, -2.2882235023917814, -0.2666666666666666, -0.2666666666666666, -0.2666635823873794, -1.2666661016101006, -3.2666665697210684, -3.2666666500959294, -1.2666666638348834, -1.266666666182748, -1.2666666665839705, -1.2666666666525348, -1.2666666666642517, -1.2888888888888888, -0.2666666666666666, -0.2666666666666666, -0.2666666666666666, -0.2666666666666666, -1.2666666666666666, -1.2888888888888888, -1.2888888888888888, -1.2888888888888888, -0.2666666666666666, -0.2666666666666666, -0.2666666666666666, 0.7111111111111111, -2.2888888888888888, -2.2666666666666666, -0.2666666666666666, -0.2666666666666666, -0.2666666666666666, -1.2666666666666666, -1.2666666666666666, -1.2666666666666666, -1.2666666666666662, -1.2666666666666662, -1.2666666666666662, -1.2666666666666662]\n","Episode 88:Total timesteps 40: [-2.310548235383181, -2.3294396281688483, -2.33266794493162, -0.311111111111111, 0.6666666666666666, -1.3333333333333335, -2.33333295738231, -2.3333332382998577, -2.3333333167818893, -2.3333333305017447, -2.3333333328494166, -2.3333333332506374, -2.3333333333192017, -2.3333333333309185, -2.3333333333329205, -2.333333333333263, -2.3333333333333215, -2.3333333333333313, -2.333333333333333, -0.311111111111111, -3.311111111111111, -0.311111111111111, -0.311111111111111, -0.28888888888888886, -1.2666666666666666, 1.7111111111111112, -1.2888888888888888, -1.2888888888888888, -1.2888888888888888, -2.2888888888888888, -2.2888888888888888, -2.2888888888888888, -2.2666666666666666, -0.28888888888888886, -2.2666666666666666, -0.2666666666666666, -0.2666666666666666, -0.2666666666666666, -1.2666666666666666, -1.2666666666666666]\n","Episode 89:Total timesteps 17: [-2.1570430091974955, -0.15556698956716497, -0.13483936555758091, -0.13334487463124, -0.2438816560211725, -1.2627729624254682, -1.2660012782744516, -1.2665529596174534, -1.2666472354697467, -1.2666633461037282, 0.7111111111111111, 1.7333333333333334, -1.2666666666666666, -1.1561185541460115, -0.13722703854149954, -0.1339987216545172, -0.9333333333333333]\n","Episode 90:Total timesteps 40: [-0.1333333333333333, -2.243881568716515, -3.2627729615021814, -0.15545304288177186, -0.16082055494898417, -2.2667660418461577, -1.2851057499243685, -1.2882423660951123, -1.178230170061973, -0.15943038039732915, 0.8200729925163762, -1.177902322014273, 0.842956070511538, -2.2661235685257246, -1.2849959309412409, 0.688888888888889, -2.3110203906300515, -2.311091919257277, -2.3111077934210593, -2.3111105437723958, -2.3111110141557196, -0.33333333333333337, -2.3333333333333335, -2.3333333333333335, -2.2227850994311638, -1.3144419405436012, -2.33010501656825, -2.332781651980518, -2.3332390574808746, -2.3333172226993386, -2.3333305802155313, -2.3333328628578927, -2.3333332529346156, -2.3333333195941384, -2.222785095602285, -1.0933454693800813, -1.1817739955474824, -1.1968853902748209, -0.31001598522569607, -1.329348672879056]\n","Episode 91:Total timesteps 40: [-2.243881568716515, -1.2627729615021814, -1.266001278264953, -1.266552959617357, 0.7111111111111111, -1.1783526299565485, -0.2699970319969598, 0.7346964424231905, 0.7111111111111111, -0.2888131945961262, 0.7333333333333334, -1.2666666666666666, -1.2666664280558706, -1.2666665886095787, -1.2666666529507098, -1.2666666643189681, -1.2666666662654342, -1.2666666665981001, -1.2666666666549493, -1.2666666666646647, -1.2666666666663247, -1.2888888888888888, -3.2888888888888888, -2.2888888888888888, -2.2888888888888888, -2.2888888888888888, -2.1783406535058667, -1.159449260720041, -1.2667691793404505, -1.2851088907737132, -1.2882429316840964, -1.2887785024025176, 0.7333333333333334, 0.7111111111111111, -1.2666666666666666, -0.2666666666666666, 0.7111111111111111, 1.7333333333333334, -0.2666666666666666, -1.2666666666666666]\n","Episode 92:Total timesteps 40: [-1.1555555555555554, -1.266103790938737, 0.6909145906904851, -4.310469051920728, -4.3109976451086, -4.3110916823529735, -4.311107790572783, -4.311110543666221, -4.3111110141414155, -2.3111110945401308, -2.3111111082793254, -2.311111110627192, -2.3111111110284153, 0.7111111111111111, -2.2666666666666666, -0.2666666666666666, -1.2666666666666666, -1.2666666666666666, -1.2666666666666666, -1.2666666666666666, -1.2666666666666666, -1.2666666666666662, -1.2666666666666662, -1.2666666666666662, -1.2666666666666662, -1.2666666666666662, 0.7111111111111111, -2.178355949014994, -1.2699975994276715, -2.2856605731879327, -2.288337207547348, -2.2887946130366106, -2.2888727782549076, -2.288886135771089, -0.2666666666666666, -0.15613364643027283, -0.1372270921014005, -0.24454695520184222, -1.2628866681547177, -1.2660207093933558]\n","Episode 93:Total timesteps 21: [0.9327704576054036, 1.9726526706793113, -1.1334446239429257, -1.1517756064398026, -0.26545783408401613, -1.2848847972417148, -1.288204636735431, -1.2887719582463393, -1.2888689068178096, -1.2888854741880378, -1.2888883053566889, 0.688888888888889, -2.311111111111111, -2.311111111111111, -2.200562876793985, -1.2922197182504682, -0.2875286728369941, -1.2883604716896269, -1.2887948532408955, -1.2888727806847382, 0.06666666666666665]\n","Episode 94:Total timesteps 3: [-2.022785097950152, -2.114441940547666, -2.7913391290368645]\n","Episode 95:Total timesteps 40: [-2.288326013160959, -1.3072174059466257, -1.3104457227093977, -1.3109974040618018, -1.31109167991419, -1.3111077905481725, 0.7111111111111111, -1.2888888888888888, -2.2666666666666666, -0.2666666666666666, -0.2666666666666666, -2.2666666666666666, -1.2888888888888888, -0.28888888888888886, -2.2888888888888888, -1.2888888888888888, -2.2888888888888888, -2.2666666666666666, -0.2666666666666666, -0.2666666666666666, -0.2666666666666666, -1.2666666666666666, -1.2666666666666666, -1.2666666666666666, -1.2666666666666662, -1.2666666666666662, -1.2666666666666662, -1.2888888888888888, -0.2666666666666666, -0.2666666666666666, -0.2666666666666666, -0.2666666666666666, -1.2666666666666666, -1.2666666666666666, -1.2888888888888888, -2.2888888888888888, -1.2888888888888888, -1.2888888888888888, -1.2888888888888888, -1.2666666666666666]\n","Episode 96:Total timesteps 19: [-0.1333333333333333, -0.24388156871651467, -1.2627729615021814, -3.266001278264953, -1.2888888888888888, -1.2888888888888888, -1.2888858045669078, -4.288888323831892, -4.288888791943286, -2.311111111111111, -2.2888888888888888, -1.2888888888888888, -1.2888888888888888, -1.2888888888888888, -2.2888888888888888, -2.2888888888886734, -2.2666666666666666, -0.2666666666666666, -1.9333333333333333]\n","Episode 97:Total timesteps 40: [-0.1777777777777777, -1.288326013160959, -0.33130763153173726, -1.2221353025512678, -1.2037800674062158, 0.8200905059609197, -1.2884529645978948, -0.331289587906067, -1.2221382499433502, -1.3143288887354352, -2.3300856805857464, -2.332778347516045, -2.333238492785007, -2.333317126199441, -0.311111111111111, -2.311111111111111, -2.311111111111111, -2.3111110996762614, -2.3111111087732614, -0.28888888888888886, -0.28888888888888886, -0.28888888888888886, -1.2666666666666666, -0.2666666666666666, -0.2666666666666666, -0.2666666666666666, -1.2666666666666666, -1.2666666666666666, -1.2666666666666666, -1.2666666666666662, -1.2666666666666662, -1.2666666666666662, -1.2666666666666662, -1.2666666666666662, -1.2666666666666662, -1.2888888888888888, -0.2666666666666666, -0.2666666666666666, -0.2666666666666666, -0.2666666666666666]\n","Episode 98:Total timesteps 40: [-2.310548235383181, -1.3294396281688483, -2.33266794493162, -2.333219626284024, -2.333313902136412, -2.3333300127703946, -2.3333327658881946, -2.3333332363636354, -2.333333316762353, -2.3333333305015476, -2.3333333328494144, -2.3333333332506374, -2.3333333333192017, -2.3333333333309185, -2.3333333333329205, -2.333333333333263, -2.3333333333333215, -2.22278509795015, -3.314441940547666, -4.3301050165705615, -2.3327816519809295, -2.3332390574809447, -2.333317222699351, -2.3333305802155335, -0.311111111111111, -1.200578090874929, -1.2922198079110485, -2.307882793062292, -0.28888888888888886, -2.288817616454955, -2.288873015078224, -2.2888861381634684, -2.288888418437265, -2.288888808490357, -2.178340639766504, -1.1594492583721725, -1.156220943556046, -1.0451210271531193, -1.0261353585719117, -0.022890931184872065]\n","Episode 99:Total timesteps 40: [-2.243881568716515, -1.2627729615021814, -1.266001278264953, -3.266552959617357, -3.266647235469746, -3.266663346103728, -3.266666099221528, -3.2666665696969686, -3.266666650095686, -1.2666666638348811, -1.266666666182748, -1.2666666665839705, -1.2666666666525348, -1.2666666666642517, -1.266666666666254, -1.266666666666596, -1.2666666666666546, -1.2666666666666644, -1.2666666666666662, -1.2666666666666662, -1.2666666666666662, -1.2666666666666662, -0.15611843128348524, -0.24777527388099962, -1.263438349903895, -1.2661149853142626, -3.2665723908142783, -1.2888888888888888, -0.28888888888888886, -0.2888886545289916, -3.288888810876993, -3.288888875173776, -1.2888888865412649, -1.2888888884876684, -1.2888888888203245, -1.288888888877172, -1.2666666666666666, -2.2666666666666666, -1.2666666666666666, -1.2666666666666666]\n"]}]},{"cell_type":"code","source":["# To access the reward for a specific step:\n","#for i, feedback in enumerate(recalibrated_rewards_list):\n","#    human_recalibrated_reward_for_step = recalibrated_rewards_list[i]\n","#    print(f\"Recalibrated reward for step {i}: {human_recalibrated_reward_for_step}\")"],"metadata":{"id":"9ghTAsxHrRBv","executionInfo":{"status":"ok","timestamp":1750253522962,"user_tz":-330,"elapsed":1,"user":{"displayName":"Saif Nazir","userId":"15029834638479146606"}}},"execution_count":42,"outputs":[]},{"cell_type":"markdown","source":["SECTION A.5: MODEL TRAINING(HUMAN FEEDBACK - EFFICIENCY-ORIENTED)\n","*   Step A.5.1: CUSTOM REWARD FUNCTION\n","*   Step A.5.2: LOAD THE SAVED INITIALLY TRAINED PPO MODEL FROM GOOGLE DRIVE\n","*   Step A.5.3: TRAIN/UPDATE PPO MODEL WITH RECALIBRATED REWARD\n","*   Step A.5.4: SAVE THE TRAINED MODEL FOR TESTING"],"metadata":{"id":"XBMjLEJEo-Ah"}},{"cell_type":"code","execution_count":43,"metadata":{"id":"7q52Lb46CuhD","executionInfo":{"status":"ok","timestamp":1750253522966,"user_tz":-330,"elapsed":2,"user":{"displayName":"Saif Nazir","userId":"15029834638479146606"}}},"outputs":[],"source":["# Step A.5.1: CUSTOM REWARD FUNCTION\n","def custom_reward(self, env, state, action, next_state, reward, done):\n","    # Access and recalculate the reward using human_feedback_data or recalibrate_rewards_human function\n","    global step_counter\n","    try:\n","        step_counter\n","    except NameError:\n","        step_counter = 0\n","\n","    reward = recalibrated_rewards_list[step_counter]\n","    step_counter += 1\n","    return reward\n","\n","# Create a new environment class that wraps your original environment and overrides the default reward function with your custom function\n","class CustomRewardWrapper(gym.Wrapper):\n","    def __init__(self, env):\n","        super(CustomRewardWrapper, self).__init__(env)\n","\n","    def step(self, action):\n","        next_state, reward, terminated, truncated, info = self.env.step(action)\n","        done = terminated or truncated\n","        reward = custom_reward(self, self.env, self.last_obs, action, next_state, reward, done)\n","        # custom_reward should be defined and accessible to your class\n","        self.last_obs = next_state\n","        return next_state, reward, terminated, truncated, info\n","\n","    def reset(self, **kwargs):\n","        global step_counter\n","        step_counter = 0\n","        self.last_obs = self.env.reset(**kwargs)[0]  # Assuming Gymnasium env returns (obs, info)\n","        return self.last_obs, {}  # Assuming Gymnasium env requires (obs, info)\n","# Create and wrap the environment with your custom reward wrapper\n","env_human = CustomRewardWrapper(gym.make('highway-v0'))"]},{"cell_type":"markdown","source":["PPO training and Training logs"],"metadata":{"id":"cqSABpgMsP7-"}},{"cell_type":"code","source":["drive_log_dir = \"/content/drive/MyDrive/05_zero_shot_llm_3/02_data/00_training_logs/5_a_log_dir/5_a_ppo_highway_biased_hf_direct_performance\"               # Update directory location 3"],"metadata":{"id":"AWqWv7gvsPi6","executionInfo":{"status":"ok","timestamp":1750253522969,"user_tz":-330,"elapsed":2,"user":{"displayName":"Saif Nazir","userId":"15029834638479146606"}}},"execution_count":44,"outputs":[]},{"cell_type":"code","source":["# Train PPO with Custom Rewards\n","def train_ppo_with_custom_rewards(log_dir=drive_log_dir, total_timesteps=10000):\n","    os.makedirs(log_dir, exist_ok=True)\n","    env = CustomRewardWrapper(gym.make(\"highway-v0\"))\n","    env = Monitor(env, log_dir)\n","    model = PPO(\"MlpPolicy\", env, verbose=1, tensorboard_log=log_dir)\n","    model.learn(total_timesteps=total_timesteps)\n","    model.save('/content/drive/MyDrive/05_zero_shot_llm_3/02_data/01_trained_models/5_a_ppo_highway_biased_hf_direct_performance')        # Update directory location 4\n","    return model, log_dir"],"metadata":{"id":"YijhozSMsPeR","executionInfo":{"status":"ok","timestamp":1750253522973,"user_tz":-330,"elapsed":2,"user":{"displayName":"Saif Nazir","userId":"15029834638479146606"}}},"execution_count":45,"outputs":[]},{"cell_type":"code","source":["# log_path = os.path.join(drive_log_dir, \"monitor.csv\")\n","# df = pd.read_csv(log_path, skiprows=1)\n","## Ensure episodes are logged correctly\n","# df.reset_index(inplace=True)\n","# df.rename(columns={\"index\": \"episode\", \"r\": \"reward\", \"l\": \"length\", \"t\": \"time_step\"}, inplace=True)"],"metadata":{"id":"_qz6jhwRQJ25","executionInfo":{"status":"ok","timestamp":1750253522976,"user_tz":-330,"elapsed":1,"user":{"displayName":"Saif Nazir","userId":"15029834638479146606"}}},"execution_count":46,"outputs":[]},{"cell_type":"code","source":["# data_table.enable_dataframe_formatter()\n","# data_table.DataTable(df)"],"metadata":{"id":"dB_mo72XQMb4","executionInfo":{"status":"ok","timestamp":1750253522980,"user_tz":-330,"elapsed":2,"user":{"displayName":"Saif Nazir","userId":"15029834638479146606"}}},"execution_count":47,"outputs":[]},{"cell_type":"code","source":["# Execute Training and Convergence Tracking\n","model, log_dir = train_ppo_with_custom_rewards(total_timesteps=10000)"],"metadata":{"id":"NYq_INeWQXKn","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1750258765559,"user_tz":-330,"elapsed":5242577,"user":{"displayName":"Saif Nazir","userId":"15029834638479146606"}},"outputId":"fdcab6cf-1338-42f4-c73c-a0a856e2eae2"},"execution_count":48,"outputs":[{"output_type":"stream","name":"stdout","text":["Using cpu device\n","Wrapping the env in a DummyVecEnv.\n","Logging to /content/drive/MyDrive/05_zero_shot_llm_3/02_data/00_training_logs/5_a_log_dir/5_a_ppo_highway_biased_hf_direct_performance/PPO_1\n","---------------------------------\n","| rollout/           |          |\n","|    ep_len_mean     | 13.7     |\n","|    ep_rew_mean     | -15.6    |\n","| time/              |          |\n","|    fps             | 1        |\n","|    iterations      | 1        |\n","|    time_elapsed    | 1054     |\n","|    total_timesteps | 2048     |\n","---------------------------------\n","-----------------------------------------\n","| rollout/                |             |\n","|    ep_len_mean          | 11.2        |\n","|    ep_rew_mean          | -12.5       |\n","| time/                   |             |\n","|    fps                  | 1           |\n","|    iterations           | 2           |\n","|    time_elapsed         | 2104        |\n","|    total_timesteps      | 4096        |\n","| train/                  |             |\n","|    approx_kl            | 0.010161332 |\n","|    clip_fraction        | 0.186       |\n","|    clip_range           | 0.2         |\n","|    entropy_loss         | -1.6        |\n","|    explained_variance   | -0.00144    |\n","|    learning_rate        | 0.0003      |\n","|    loss                 | 10.2        |\n","|    n_updates            | 10          |\n","|    policy_gradient_loss | -0.023      |\n","|    value_loss           | 43          |\n","-----------------------------------------\n","-----------------------------------------\n","| rollout/                |             |\n","|    ep_len_mean          | 8.83        |\n","|    ep_rew_mean          | -9.14       |\n","| time/                   |             |\n","|    fps                  | 1           |\n","|    iterations           | 3           |\n","|    time_elapsed         | 3152        |\n","|    total_timesteps      | 6144        |\n","| train/                  |             |\n","|    approx_kl            | 0.015227694 |\n","|    clip_fraction        | 0.212       |\n","|    clip_range           | 0.2         |\n","|    entropy_loss         | -1.57       |\n","|    explained_variance   | 0.00244     |\n","|    learning_rate        | 0.0003      |\n","|    loss                 | 19.7        |\n","|    n_updates            | 20          |\n","|    policy_gradient_loss | -0.0223     |\n","|    value_loss           | 47.4        |\n","-----------------------------------------\n","-----------------------------------------\n","| rollout/                |             |\n","|    ep_len_mean          | 8.38        |\n","|    ep_rew_mean          | -8.65       |\n","| time/                   |             |\n","|    fps                  | 1           |\n","|    iterations           | 4           |\n","|    time_elapsed         | 4192        |\n","|    total_timesteps      | 8192        |\n","| train/                  |             |\n","|    approx_kl            | 0.014573525 |\n","|    clip_fraction        | 0.169       |\n","|    clip_range           | 0.2         |\n","|    entropy_loss         | -1.51       |\n","|    explained_variance   | 0.0274      |\n","|    learning_rate        | 0.0003      |\n","|    loss                 | 22.1        |\n","|    n_updates            | 30          |\n","|    policy_gradient_loss | -0.0226     |\n","|    value_loss           | 41.4        |\n","-----------------------------------------\n","-----------------------------------------\n","| rollout/                |             |\n","|    ep_len_mean          | 7.35        |\n","|    ep_rew_mean          | -7.32       |\n","| time/                   |             |\n","|    fps                  | 1           |\n","|    iterations           | 5           |\n","|    time_elapsed         | 5234        |\n","|    total_timesteps      | 10240       |\n","| train/                  |             |\n","|    approx_kl            | 0.009352802 |\n","|    clip_fraction        | 0.145       |\n","|    clip_range           | 0.2         |\n","|    entropy_loss         | -1.45       |\n","|    explained_variance   | 0.0507      |\n","|    learning_rate        | 0.0003      |\n","|    loss                 | 11.2        |\n","|    n_updates            | 40          |\n","|    policy_gradient_loss | -0.0162     |\n","|    value_loss           | 31          |\n","-----------------------------------------\n"]}]}]}