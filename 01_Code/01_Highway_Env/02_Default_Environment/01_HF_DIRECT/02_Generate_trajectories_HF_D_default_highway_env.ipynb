{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":134457,"status":"ok","timestamp":1750211777247,"user":{"displayName":"Saif Nazir","userId":"15029834638479146606"},"user_tz":-330},"id":"OuwmGGRJrPVF","outputId":"b49850ac-6d7d-4335-8915-ef9f56b69aa1"},"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/184.5 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m184.3/184.5 kB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m184.5/184.5 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m105.0/105.0 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m55.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m56.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m33.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m12.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m54.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h"]}],"source":["# Install the required libraries in your Google Colab environment\n","!pip install gymnasium stable-baselines3 highway-env -q"]},{"cell_type":"code","execution_count":2,"metadata":{"executionInfo":{"elapsed":1785,"status":"ok","timestamp":1750211779045,"user":{"displayName":"Saif Nazir","userId":"15029834638479146606"},"user_tz":-330},"id":"VZhaXFBUrfBS"},"outputs":[],"source":["# Import the necessary libraries\n","import gymnasium as gym\n","import highway_env\n","import numpy as np\n","import pandas as pd\n","import pickle\n","import os\n","import matplotlib.pyplot as plt"]},{"cell_type":"code","execution_count":3,"metadata":{"executionInfo":{"elapsed":64,"status":"ok","timestamp":1750211779118,"user":{"displayName":"Saif Nazir","userId":"15029834638479146606"},"user_tz":-330},"id":"BP5KACM8rlKX"},"outputs":[],"source":["# THE ENVIRONMENT\n","# Step 1.1: Choose the Environment\n","# Initialize the environment.\n","env = gym.make('highway-v0',config={\"vehicles_count\":50})"]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":54470,"status":"ok","timestamp":1750211833591,"user":{"displayName":"Saif Nazir","userId":"15029834638479146606"},"user_tz":-330},"id":"oilpd3dOz8r_","outputId":"1ea084b5-a6e8-41ef-f1fc-702715393597"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from stable_baselines3 import PPO\n","from google.colab import drive\n","from google.colab import data_table\n","\n","# Mount Google Drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":5,"metadata":{"executionInfo":{"elapsed":8915,"status":"ok","timestamp":1750211842494,"user":{"displayName":"Saif Nazir","userId":"15029834638479146606"},"user_tz":-330},"id":"fnHpE3hDaNom"},"outputs":[],"source":["# Load the all the saved PPO model\n","model = PPO.load('/content/drive/MyDrive/05_zero_shot_llm_3/02_data/01_trained_models/1_ppo_highway_hf_direct_ideal')                # Update directory location 1"]},{"cell_type":"markdown","metadata":{"id":"8eJ7IUv5j7iS"},"source":["Trajectory Collection with Additional information (Collision Flag and Lane Index)"]},{"cell_type":"code","execution_count":6,"metadata":{"executionInfo":{"elapsed":9,"status":"ok","timestamp":1750211842510,"user":{"displayName":"Saif Nazir","userId":"15029834638479146606"},"user_tz":-330},"id":"WCoPWduUICcu"},"outputs":[],"source":["# TRAJECTORY COLLECTION WITH ADDTIONNAL INFORMATION\n","# Initialize a list to store trajectory data\n","trajectories = []\n","\n","# FUNCTION TO COLLECT TRAJECTORY DATA (state-action-reward transitions).\n","\n","def collect_trajectory_data(env, model, num_episodes,seed):\n","    \"\"\"\n","    Collect trajectory data for a number of episodes.\n","    Each trajectory contains state-action-reward sequences.\n","    \"\"\"\n","    trajectory_data = []\n","\n","    for episode in range(num_episodes):\n","        state, _ = env.reset(seed=seed)  # Reset the environment at the start of each episode              #  change environment name here\n","        done = False\n","        episode_data = []\n","\n","        while not done:\n","            # Get action from the trained PPO model\n","            action, _states = model.predict(state, deterministic = True)                                       # change model name here\n","\n","            # Take the action and get next state and reward\n","            next_state, reward, terminated, truncated, info = env.step(action)                    #  change environment name here\n","            done = terminated or truncated\n","            # Extract lane index and collision flag\n","            lane_index = int(env.unwrapped.vehicle.lane_index[2])\n","            collision_flag = int(info.get('crashed', 0))\n","\n","            # Store the trajectory: (state, action, reward, next_state)\n","            episode_data.append({\n","                \"state\": state,\n","                \"action\": action,\n","                \"reward\": reward,\n","                \"next_state\": next_state,\n","                \"lane_indices\": lane_index,\n","                \"collision_flags\": collision_flag\n","            })\n","\n","            # Update the state for the next iteration\n","            state = next_state\n","\n","        # Add the episode data to the overall trajectory list\n","        trajectory_data.append(episode_data)\n","\n","    return trajectory_data"]},{"cell_type":"code","execution_count":7,"metadata":{"executionInfo":{"elapsed":18,"status":"ok","timestamp":1750211842533,"user":{"displayName":"Saif Nazir","userId":"15029834638479146606"},"user_tz":-330},"id":"SsiZnt73xMQd"},"outputs":[],"source":["# FUNCTION TO PREPROCESS TRAJECTORY DATA\n","def preprocess_trajectory_data(trajectory_data):\n","    \"\"\"\n","    Preprocesses the trajectory data into a structured format for further analysis.\n","    Returns a DataFrame with columns: episode, time_step, state, action, reward, next_state, speed, and reward_details.\n","    \"\"\"\n","    processed_data = []\n","\n","    for episode_num, episode_data in enumerate(trajectory_data):\n","        for time_step, step in enumerate(episode_data):\n","            # Flatten the state and next_state for easy interpretation (if they are multi-dimensional)\n","            state = np.array(step['state']).flatten()  # Flatten the state vector (if multi-dimensional)\n","            next_state = np.array(step['next_state']).flatten()  # Flatten the next_state vector\n","\n","            collision_flag = step['collision_flags']\n","            lane_index = step['lane_indices']\n","\n","            # Append the processed data for this step\n","            processed_data.append({\n","                \"episode\": episode_num,\n","                \"time_step\": time_step,\n","                \"state\": state,\n","                \"action\": step['action'],\n","                \"reward\": step['reward'],\n","                \"next_state\": next_state,\n","                \"collision_flag\": collision_flag,\n","                \"lane_index\": lane_index\n","            })\n","\n","    # Convert the list of processed data into a DataFrame\n","    df = pd.DataFrame(processed_data)\n","    return df"]},{"cell_type":"markdown","metadata":{"id":"qLgAKXgUWiEj"},"source":["0. GENERATING TRAJECTORIES FOR TESTING (HUMAN FEEDBACK DIRECT)"]},{"cell_type":"markdown","metadata":{"id":"-n-_2c_tXDTG"},"source":["First Human feedback direct data frame"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"NtUE_W7-WhQj"},"outputs":[],"source":["# Collect data for 100 episodes\n","trajectory_data_1 = collect_trajectory_data(env, model, num_episodes=100,seed=2)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"YPBCBmGJWvt7"},"outputs":[],"source":["# Preprocess the trajectory data\n","trajectory_df_seed_1 = preprocess_trajectory_data(trajectory_data_1)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"output_embedded_package_id":"1DRUJG6wkVi-EkYK7GfCWREnM1mhny0wb"},"id":"uVd9HKPZWvnP","outputId":"5c2cbda7-febd-4c45-a210-b1ed26661521"},"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}],"source":["data_table.enable_dataframe_formatter()\n","data_table.DataTable(trajectory_df_seed_1)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"KlTviQ7LWvUr"},"outputs":[],"source":["# Save the dataframe as a pickle file\n","trajectory_df_seed_1.to_pickle('/content/drive/MyDrive/05_zero_shot_llm_3/02_data/03_test_trajectories/1_hf_d_ideal/1_hf_d_ideal_df.pkl')           # Update directory location 2\n"]},{"cell_type":"markdown","metadata":{"id":"E6yiiseHg8Bh"},"source":["Second Human feedback direct data frame\n"]},{"cell_type":"code","execution_count":8,"metadata":{"id":"N6pxD621hOql","executionInfo":{"status":"ok","timestamp":1750213858137,"user_tz":-330,"elapsed":2015600,"user":{"displayName":"Saif Nazir","userId":"15029834638479146606"}}},"outputs":[],"source":["# Collect data for 100 episodes\n","trajectory_data_2 = collect_trajectory_data(env, model, num_episodes=100,seed=10)"]},{"cell_type":"code","execution_count":9,"metadata":{"id":"tqlWzOemhOcZ","executionInfo":{"status":"ok","timestamp":1750213858160,"user_tz":-330,"elapsed":27,"user":{"displayName":"Saif Nazir","userId":"15029834638479146606"}}},"outputs":[],"source":["# Preprocess the trajectory data\n","trajectory_df_seed_2 = preprocess_trajectory_data(trajectory_data_2)"]},{"cell_type":"code","execution_count":10,"metadata":{"id":"ga44R6BVhORd","colab":{"base_uri":"https://localhost:8080/","height":3029,"output_embedded_package_id":"1a9yGrIeGYGxPeszQIzj3B95CamcGPIY7"},"executionInfo":{"status":"ok","timestamp":1750213863495,"user_tz":-330,"elapsed":5333,"user":{"displayName":"Saif Nazir","userId":"15029834638479146606"}},"outputId":"b641866b-1a26-4f10-8b14-5b4ecf0fe5c0"},"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}],"source":["data_table.enable_dataframe_formatter()\n","data_table.DataTable(trajectory_df_seed_2)"]},{"cell_type":"code","execution_count":11,"metadata":{"id":"-0ouJiqohOHO","executionInfo":{"status":"ok","timestamp":1750213863587,"user_tz":-330,"elapsed":29,"user":{"displayName":"Saif Nazir","userId":"15029834638479146606"}}},"outputs":[],"source":["# Save the dataframe as a pickle file\n","trajectory_df_seed_2.to_pickle('/content/drive/MyDrive/05_zero_shot_llm_3/02_data/03_test_trajectories/1_hf_d_ideal/2_hf_d_ideal_df.pkl')          # Update directory location 3"]},{"cell_type":"markdown","metadata":{"id":"LNI1Q2aIhAXP"},"source":["Third Human feedback direct data frame"]},{"cell_type":"code","execution_count":12,"metadata":{"id":"eJe17vLxhP37","executionInfo":{"status":"ok","timestamp":1750215794694,"user_tz":-330,"elapsed":1821648,"user":{"displayName":"Saif Nazir","userId":"15029834638479146606"}}},"outputs":[],"source":["# Collect data for 100 episodes\n","trajectory_data_3 = collect_trajectory_data(env, model, num_episodes=100,seed=6)"]},{"cell_type":"code","execution_count":13,"metadata":{"id":"L-1wNg9BhPmZ","executionInfo":{"status":"ok","timestamp":1750215794737,"user_tz":-330,"elapsed":22,"user":{"displayName":"Saif Nazir","userId":"15029834638479146606"}}},"outputs":[],"source":["# Preprocess the trajectory data\n","trajectory_df_seed_3 = preprocess_trajectory_data(trajectory_data_3)"]},{"cell_type":"code","execution_count":14,"metadata":{"id":"QvcIR1LAhPgi","colab":{"base_uri":"https://localhost:8080/","height":3029,"output_embedded_package_id":"11VhXAxqmAOWucZiQcHYTvgzaZ48mps7G"},"executionInfo":{"status":"ok","timestamp":1750215801249,"user_tz":-330,"elapsed":6499,"user":{"displayName":"Saif Nazir","userId":"15029834638479146606"}},"outputId":"ff748323-b4f5-4076-fa85-357741a40f25"},"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}],"source":["data_table.enable_dataframe_formatter()\n","data_table.DataTable(trajectory_df_seed_3)"]},{"cell_type":"code","execution_count":15,"metadata":{"id":"3hYXf2kchPba","executionInfo":{"status":"ok","timestamp":1750215801305,"user_tz":-330,"elapsed":2,"user":{"displayName":"Saif Nazir","userId":"15029834638479146606"}}},"outputs":[],"source":["# Save the dataframe as a pickle file\n","trajectory_df_seed_3.to_pickle('/content/drive/MyDrive/05_zero_shot_llm_3/02_data/03_test_trajectories/1_hf_d_ideal/3_hf_d_ideal_df.pkl')             # Update directory location 4"]},{"cell_type":"markdown","metadata":{"id":"O8UPT7E2hEw4"},"source":["Fourth Human feedback direct data frame"]},{"cell_type":"code","execution_count":16,"metadata":{"id":"XM_zO3mehROZ","executionInfo":{"status":"ok","timestamp":1750217739467,"user_tz":-330,"elapsed":1938151,"user":{"displayName":"Saif Nazir","userId":"15029834638479146606"}}},"outputs":[],"source":["# Collect data for 100 episodes\n","trajectory_data_4 = collect_trajectory_data(env, model, num_episodes=100,seed=20)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"pTUEoqhahQ9-"},"outputs":[],"source":["# Preprocess the trajectory data\n","trajectory_df_seed_4 = preprocess_trajectory_data(trajectory_data_4)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"sE0nYkpChQ6p"},"outputs":[],"source":["data_table.enable_dataframe_formatter()\n","data_table.DataTable(trajectory_df_seed_4)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"1qCe_JCNhQ22"},"outputs":[],"source":["# Save the dataframe as a pickle file\n","trajectory_df_seed_4.to_pickle('/content/drive/MyDrive/05_zero_shot_llm_3/02_data/03_test_trajectories/1_hf_d_ideal/4_hf_d_ideal_df.pkl')             # Update directory location 5"]},{"cell_type":"markdown","metadata":{"id":"GK2JR89NhIeJ"},"source":["Fifth Human feedback direct data frame"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"GeZXIUCDg7fA"},"outputs":[],"source":["# Collect data for 100 episodes\n","trajectory_data_5 = collect_trajectory_data(env, model, num_episodes=100,seed=34)"]},{"cell_type":"code","execution_count":21,"metadata":{"id":"RRVMOCvDhSWQ","executionInfo":{"status":"ok","timestamp":1750219677300,"user_tz":-330,"elapsed":22,"user":{"displayName":"Saif Nazir","userId":"15029834638479146606"}}},"outputs":[],"source":["# Preprocess the trajectory data\n","trajectory_df_seed_5 = preprocess_trajectory_data(trajectory_data_5)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"A4dorT-ahSJ5"},"outputs":[],"source":["data_table.enable_dataframe_formatter()\n","data_table.DataTable(trajectory_df_seed_5)"]},{"cell_type":"code","execution_count":23,"metadata":{"id":"zXgtf5LXhSCc","executionInfo":{"status":"ok","timestamp":1750219680272,"user_tz":-330,"elapsed":3,"user":{"displayName":"Saif Nazir","userId":"15029834638479146606"}}},"outputs":[],"source":["# Save the dataframe as a pickle file\n","trajectory_df_seed_5.to_pickle('/content/drive/MyDrive/05_zero_shot_llm_3/02_data/03_test_trajectories/1_hf_d_ideal/5_hf_d_ideal_df.pkl')           # Update directory location 6"]}],"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyPvPHqfkOIUvjkuoC3tHDxB"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}