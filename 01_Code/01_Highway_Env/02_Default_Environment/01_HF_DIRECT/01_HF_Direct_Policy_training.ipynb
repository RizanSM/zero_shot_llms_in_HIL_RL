{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyOfT+iL/NFOGHNqMuDvi2h1"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["[![Open in Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/RizanSM/zero_shot_llms_in_HIL_RL/blob/main/01_Code/01_Highway_Env/02_Default_Environment/01_HF_DIRECT/01_HF_Direct_Policy_training.ipynb)\n","\n","> Add blockquote\n","\n"],"metadata":{"id":"omFnXNvssffi"}},{"cell_type":"code","source":["\n","# Install the required libraries in your Google Colab environment\n","!pip install stable-baselines3 gymnasium highway-env -q"],"metadata":{"id":"APrU5xhT0nTF","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1750200706289,"user_tz":-330,"elapsed":139822,"user":{"displayName":"Saif Nazir","userId":"15029834638479146606"}},"outputId":"dc5e6bd2-9e5d-4792-df33-dc29a8b54f81"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/184.5 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m184.3/184.5 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m184.5/184.5 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m105.0/105.0 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m62.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m57.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m32.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m829.4 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m10.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m42.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h"]}]},{"cell_type":"code","source":["# Import the necessary libraries\n","import gymnasium as gym\n","import highway_env\n","import numpy as np\n","import pandas as pd\n","import pickle\n","import os\n","import matplotlib.pyplot as plt"],"metadata":{"id":"SQJ0fTEA0m_G"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from stable_baselines3 import PPO\n","from stable_baselines3.common.vec_env import DummyVecEnv\n","from stable_baselines3.common.evaluation import evaluate_policy\n","from stable_baselines3.common.monitor import Monitor\n","from google.colab import data_table\n","from google.colab import drive\n","\n","# Mount Google Drive\n","drive.mount('/content/drive')"],"metadata":{"id":"go9u8BAE1Olz","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1750200749670,"user_tz":-330,"elapsed":41113,"user":{"displayName":"Saif Nazir","userId":"15029834638479146606"}},"outputId":"28aa51b3-6081-480e-bd96-39ac0425e6fb"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["# Load the dataframe back from the pickle file\n","trajectory_df = pd.read_pickle('/content/drive/MyDrive/05_zero_shot_llm_3/02_data/02_trajectories/0_initial_training/0_initial_trajectory_df.pkl')        # Update directory location 1"],"metadata":{"id":"84qr9aP-nc0d"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Display the data frame\n","data_table.enable_dataframe_formatter()\n","data_table.DataTable(trajectory_df)"],"metadata":{"id":"MHAY3C2LxMel","colab":{"base_uri":"https://localhost:8080/","height":2847,"output_embedded_package_id":"1MGu_aniZWN7naZQFboE54p08UTIA50cU"},"executionInfo":{"status":"ok","timestamp":1750200755020,"user_tz":-330,"elapsed":3785,"user":{"displayName":"Saif Nazir","userId":"15029834638479146606"}},"outputId":"cd5e5d9a-889d-4e26-df6d-382bdd20acd8"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}]},{"cell_type":"code","source":["# Check the data type of each column\n","print(type(trajectory_df['episode'][0]))\n","print(type(trajectory_df['time_step'][0]))\n","print(type(trajectory_df['state'][0]))\n","print(type(trajectory_df['action'][0]))\n","print(type(trajectory_df['reward'][0]))\n","print(type(trajectory_df['next_state'][0]))\n","print(type(trajectory_df['collision_flag'][0]))\n","print(type(trajectory_df['lane_index'][0]))"],"metadata":{"id":"BPFidEkGlZAC","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1750200755061,"user_tz":-330,"elapsed":8,"user":{"displayName":"Saif Nazir","userId":"15029834638479146606"}},"outputId":"852e1580-fac8-4696-f41a-0748ddfd4341"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["<class 'numpy.int64'>\n","<class 'numpy.int64'>\n","<class 'numpy.ndarray'>\n","<class 'numpy.ndarray'>\n","<class 'numpy.float64'>\n","<class 'numpy.ndarray'>\n","<class 'numpy.int64'>\n","<class 'numpy.int64'>\n"]}]},{"cell_type":"code","source":["trajectory_df.dtypes"],"metadata":{"id":"NYe0lzD3XNwm","colab":{"base_uri":"https://localhost:8080/","height":335},"executionInfo":{"status":"ok","timestamp":1748546810011,"user_tz":-330,"elapsed":24,"user":{"displayName":"Saif Nazir","userId":"15029834638479146606"}},"outputId":"012eab8e-d9bd-4e86-a97f-2e71faf3f677"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["episode             int64\n","time_step           int64\n","state              object\n","action             object\n","reward            float64\n","next_state         object\n","collision_flag      int64\n","lane_index          int64\n","dtype: object"],"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>0</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>episode</th>\n","      <td>int64</td>\n","    </tr>\n","    <tr>\n","      <th>time_step</th>\n","      <td>int64</td>\n","    </tr>\n","    <tr>\n","      <th>state</th>\n","      <td>object</td>\n","    </tr>\n","    <tr>\n","      <th>action</th>\n","      <td>object</td>\n","    </tr>\n","    <tr>\n","      <th>reward</th>\n","      <td>float64</td>\n","    </tr>\n","    <tr>\n","      <th>next_state</th>\n","      <td>object</td>\n","    </tr>\n","    <tr>\n","      <th>collision_flag</th>\n","      <td>int64</td>\n","    </tr>\n","    <tr>\n","      <th>lane_index</th>\n","      <td>int64</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div><br><label><b>dtype:</b> object</label>"]},"metadata":{},"execution_count":7}]},{"cell_type":"markdown","source":["A : HUMAN FEEDBACK IMPLEMENTATION (IDEAL CASE SCENARIO)\n","*   SECTION A.1: FEEDBACK BASED ON LANE CHANGING BEHAVIOUR\n","*   SECTION A.2: FEEDBACK BASED ON COLLISION AVOIDANCE MANUEVERS\n","*   SECTION A.3: FEEDBACK BASED ON SPEED OPTIMIZATION\n","*   SECTION A.4: REWARD MODELLING\n","*   SECTION A.5: MODEL TRAINING\n"],"metadata":{"id":"yK3Yd5Tt2_FU"}},{"cell_type":"markdown","source":["SECTION A.1: FEEDBACK BASED ON LANE CHANGING BEHAVIOUR\n","*   Step A.1.1: FUNCTION TO COUNT LANE CHANGES\n","*   Step A.1.2: FUNCTION TO PROVIDE FEEDBACK BASED ON LANE CHANGE\n"],"metadata":{"id":"V1BC9xeLm_aS"}},{"cell_type":"code","source":["# Step A.1.1: FUNCTION TO COUNT LANE CHANGES\n","def count_lane_changes(df):\n","    df_copy = df.copy()\n","    df_copy['count_lane_change'] = 0\n","\n","    # Group by episode\n","    for episode_id, episode_df in df_copy.groupby('episode'):  # Group by 'episode'\n","        idx = 0\n","        while idx < len(episode_df):  # Iterate within each episode\n","            current_lane_index = episode_df.iloc[idx]['lane_index']\n","\n","            if idx == 0:  # First timestep of the episode\n","                episode_df.at[episode_df.index[idx], 'count_lane_change'] = 0\n","                idx += 1\n","                continue\n","\n","            previous_lane_index = episode_df.iloc[idx - 1]['lane_index']\n","\n","            if current_lane_index == previous_lane_index:\n","                episode_df.at[episode_df.index[idx], 'count_lane_change'] = 0\n","                idx += 1\n","                continue\n","\n","            change = current_lane_index - previous_lane_index\n","            count = 1\n","            consecutive_indices = [idx]\n","\n","            lookahead_idx = idx + 1\n","            while lookahead_idx < len(episode_df) and (episode_df.iloc[lookahead_idx]['lane_index'] - episode_df.iloc[lookahead_idx - 1]['lane_index'] == change):\n","                count += 1\n","                consecutive_indices.append(lookahead_idx)\n","                lookahead_idx += 1\n","\n","            for i in consecutive_indices:\n","                episode_df.at[episode_df.index[i], 'count_lane_change'] = count #  Use episode_df.index[i]\n","\n","            idx = lookahead_idx\n","\n","        df_copy.loc[episode_df.index, 'count_lane_change'] = episode_df['count_lane_change'].values # Update original df\n","\n","    return df_copy"],"metadata":{"id":"l6ogHDaMcSXf"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Call the function and save the updated dataframe as \"lane_feedback_df\"\n","lane_feedback_df = count_lane_changes(trajectory_df)"],"metadata":{"id":"ytNuI-8zdYHn"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["data_table.enable_dataframe_formatter()\n","data_table.DataTable(lane_feedback_df)"],"metadata":{"id":"dclcOqjRdbKg","colab":{"base_uri":"https://localhost:8080/","height":3558,"output_embedded_package_id":"1Um_fUM5c4vtP1GF0UE0pMzO-WUxMpPKQ"},"executionInfo":{"status":"ok","timestamp":1750200775426,"user_tz":-330,"elapsed":3013,"user":{"displayName":"Saif Nazir","userId":"15029834638479146606"}},"outputId":"a6e82c85-3948-40b9-baf8-774a08c65851"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}]},{"cell_type":"code","source":["# Step A.1.2: FUNCTION TO PROVIDE FEEDBACK BASED ON LANE CHANGE\n","# Define the lane_change_behaviour function\n","def lane_change_behaviour(df):\n","    # Create a copy of the dataframe to avoid modifying the original one\n","    df_copy = df.copy()\n","\n","    # Create 'Lane_feedback' and 'Lane_change_reward' columns\n","    df_copy['Lane_feedback'] = \"\"\n","    df_copy['Lane_change_score'] = 0\n","    df_copy['Lane_change_score'] = df_copy['Lane_change_score'].astype(float)\n","\n","    # Iterate through the dataframe to apply the lane change behavior logic\n","    for i, row in df_copy.iterrows():\n","        lane_change_number = row['count_lane_change']\n","\n","        if lane_change_number == 0:\n","            df_copy.at[i, 'Lane_feedback'] = \"No lane change is observed\"\n","            df_copy.at[i, 'Lane_change_score'] = +1                                 # Bias value 1\n","        elif lane_change_number == 1:\n","            df_copy.at[i, 'Lane_feedback'] = \"One lane change is observed\"\n","            df_copy.at[i, 'Lane_change_score'] = 0                                 # Bias value 2\n","        elif lane_change_number == 2:\n","            df_copy.at[i, 'Lane_feedback'] = \"Two lane change is observed\"\n","            df_copy.at[i, 'Lane_change_score'] = -1                                 # Bias value 3\n","        elif lane_change_number == 3:\n","            df_copy.at[i, 'Lane_feedback'] = \"Three lane change is observed\"\n","            df_copy.at[i, 'Lane_change_score'] = -1                                 # Bias value 4\n","\n","\n","    # Return the updated dataframe\n","    return df_copy"],"metadata":{"id":"5VbJbsKqecVO"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Apply the lane_change_behaviour function to the lane_feedback_df\n","lane_behaviour_feedback_df = lane_change_behaviour(lane_feedback_df)"],"metadata":{"id":"N_idiuM3exV_"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["data_table.enable_dataframe_formatter()\n","data_table.DataTable(lane_behaviour_feedback_df)"],"metadata":{"id":"q4h9suvHesrz","colab":{"base_uri":"https://localhost:8080/","height":5063,"output_embedded_package_id":"1bWUA6Z5PGUJbwGmD3FHvgyodmcQ_XII5"},"executionInfo":{"status":"ok","timestamp":1750200785862,"user_tz":-330,"elapsed":4357,"user":{"displayName":"Saif Nazir","userId":"15029834638479146606"}},"outputId":"233cb496-3c35-4807-818f-dcb30695e0ed"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}]},{"cell_type":"markdown","source":["SECTION A.2: FEEDBACK BASED ON COLLISION AVOIDANCE MANUEVERS\n","*   Step A.2.1: FUNCTION TO CALCULATE LANE CHANGE\n","*   Step A.2.2: FUNCTION TO CALCULATE TIME TO COLLISION(TTC)\n","*   Step A.2.3: FUNCTION TO CALCULATE RELATIVE POSITION, RELATIVE VELOCITY AND TIME TO COLLISION\n","*   Step A.2.4: FUNCTION TO IMPLEMENT COLLISION AVOIDANCE FEEDBACK"],"metadata":{"id":"oINoG120nF9v"}},{"cell_type":"code","source":["def calculate_lane_changes(df):\n","    df_copy = df.copy()\n","    df_copy['Lane_change_collision_fb'] = 0\n","\n","    # Group by episode\n","    for episode_id, episode_df in df_copy.groupby('episode'):  # Group by 'episode'\n","        idx = 0\n","        while idx < len(episode_df):  # Iterate within each episode\n","            current_lane_index = episode_df.iloc[idx]['lane_index']\n","\n","            if idx == 0:  # First timestep of the episode\n","                episode_df.at[episode_df.index[idx], 'Lane_change_collision_fb'] = 0\n","                idx += 1\n","                continue\n","\n","            previous_lane_index = episode_df.iloc[idx - 1]['lane_index']\n","\n","            if current_lane_index != previous_lane_index:\n","                episode_df.at[episode_df.index[idx], 'Lane_change_collision_fb'] = 1\n","                idx += 1\n","                continue\n","\n","            else:\n","                episode_df.at[episode_df.index[idx], 'Lane_change_collision_fb'] = 0\n","                idx += 1\n","\n","        df_copy.loc[episode_df.index, 'Lane_change_collision_fb'] = episode_df['Lane_change_collision_fb'].values # Update original df\n","        # df_copy.loc[episode_df.index, 'count_lane_change'] = episode_df['count_lane_change'].values\n","\n","    return df_copy"],"metadata":{"id":"3gE7sFDx7JGx"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Call the function and save the updated dataframe as \"lane_feedback_df\"\n","lane_change_collision_fb_df = calculate_lane_changes(trajectory_df)"],"metadata":{"id":"xKboQ065Xe1T"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["data_table.enable_dataframe_formatter()\n","data_table.DataTable(lane_change_collision_fb_df)"],"metadata":{"id":"mxC64v2KXmh5","colab":{"base_uri":"https://localhost:8080/","height":3592,"output_embedded_package_id":"1H5AG9vo7HL41f-Bbt3gheYmjSaGYLGWj"},"executionInfo":{"status":"ok","timestamp":1750200794754,"user_tz":-330,"elapsed":2267,"user":{"displayName":"Saif Nazir","userId":"15029834638479146606"}},"outputId":"f79824f0-2ef1-4821-c56b-36382dbeae8d"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}]},{"cell_type":"code","source":[" # Step A.2.2: FUNCTION TO CALCULATE TIME TO COLLISION(TTC)\n","def calculate_ttc(ego_vehicle, other_vehicles):\n","    if not other_vehicles:\n","        return np.inf, -1  # No other vehicles\n","\n","    min_ttc = np.inf\n","    nearest_vehicle_index = -1\n","\n","    ego_x = ego_vehicle[\"x\"]\n","    ego_y = ego_vehicle[\"y\"]\n","    ego_vx = ego_vehicle[\"vx\"]\n","    ego_vy = ego_vehicle[\"vy\"]\n","\n","    for i, other in enumerate(other_vehicles):\n","        other_x = other[\"x\"]\n","        other_y = other[\"y\"]\n","        other_vx = other[\"vx\"]\n","        other_vy = other[\"vy\"]\n","\n","        dx = other_x - ego_x\n","        dy = other_y - ego_y\n","\n","        # Use magnitude and heading if vx/vy not directly available\n","        # v_ego = np.sqrt(ego_vx**2 + ego_vy**2)\n","        # heading_ego = ...  # Get heading angle\n","        # v_other = np.sqrt(other_vx**2 + other_vy**2)\n","        # heading_other = ... # Get heading angle\n","\n","        dvx = other_vx - ego_vx\n","        dvy = other_vy - ego_vy\n","\n","        # Calculate TTC (constant velocity assumption)\n","        # More robust calculation considering angle between vehicles:\n","        dot_product = dx * dvx + dy * dvy\n","        if dot_product < 0:  # Vehicles are getting closer\n","            distance = np.sqrt(dx**2 + dy**2)\n","            relative_speed = np.sqrt(dvx**2 + dvy**2)  # Magnitude of relative speed\n","            if relative_speed > 0:\n","              ttc = distance / relative_speed\n","            else:\n","              ttc = np.inf # Relative speed is zero, no collision\n","        else:\n","            ttc = np.inf  # Vehicles are moving apart\n","\n","\n","        if ttc < min_ttc and ttc > 0: # Only consider positive TTCs (collisions)\n","            min_ttc = ttc\n","            nearest_vehicle_index = i\n","\n","    return min_ttc, nearest_vehicle_index"],"metadata":{"id":"NdQ9A6ZbMIm_"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#  Step A.2.3: FUNCTION TO CALCULATE RELATIVE POSITION, RELATIVE VELOCITY AND ACCELARATION\n","\n","def calculate_collision_parameters_1(trajectory_df):\n","    # Create a copy of the original dataframe\n","    df_copy = trajectory_df.copy()\n","\n","    df_copy['Nearest vehicle id'] = None\n","    df_copy['TTC'] = 0.0\n","    # Create a new column for storing collision parameters\n","    df_copy['Collision_Parameters'] = None\n","\n","    # Group by episode\n","    for episode_id, episode_df in df_copy.groupby('episode'):\n","        # Iterate through each timestep in the episode\n","        for idx, row in episode_df.iterrows():\n","            # Get the agent's state and new state\n","            agent_state = row['state']\n","            agent_new_state = row['next_state']\n","\n","            agent_position = np.array([agent_state[1], agent_state[2]])  # x, y\n","            agent_velocity = np.array([agent_state[3], agent_state[4]])  # vx, vy\n","            agent_new_position = np.array([agent_new_state[1], agent_new_state[2]])  # new x, new y\n","            agent_new_velocity = np.array([agent_new_state[3], agent_new_state[4]])  # new vx, new vy\n","\n","            # Find the nearest vehicle\n","            nearest_vehicle_distance = float('inf')\n","            nearest_vehicle_idx = None\n","            other_vehicles = [] # Initialize list to store other vehicles' data\n","            for vehicle_idx, vehicle_row in episode_df.iterrows():\n","                if vehicle_idx != idx:  # Skip the agent itself\n","                    vehicle_state = vehicle_row['state']\n","                    vehicle_position = np.array([vehicle_state[1], vehicle_state[2]])\n","                    vehicle_velocity = np.array([vehicle_state[3], vehicle_state[4]]) # Added to store velocity\n","                    distance = np.linalg.norm(agent_position - vehicle_position)\n","                    if distance < nearest_vehicle_distance:\n","                        nearest_vehicle_distance = distance\n","                        nearest_vehicle_idx = vehicle_idx\n","                    other_vehicles.append({\"x\": vehicle_position[0], \"y\": vehicle_position[1], \"vx\":vehicle_velocity[0], \"vy\":vehicle_velocity[1]}) # Added other vehicles\n","\n","            # print(f\"Episode {episode_id}, Time step {row['time_step']}: Nearest vehicle is {nearest_vehicle_idx}\")\n","\n","            if nearest_vehicle_idx is None:\n","                collision_data = {\n","                    'Vehicle_number': None,\n","                    'Relative_position': None,\n","                    'Relative_velocity': None,\n","                    'Relative_speed': None,\n","                    'TTC': None,\n","                    'Agent_acceleration': None\n","                }\n","                df_copy.at[row.name, 'Collision_Parameters'] = collision_data\n","                continue\n","\n","            # --- TTC Calculation Logic (Modified) ---\n","            ego_vehicle = {\"x\": agent_position[0], \"y\": agent_position[1], \"vx\": agent_velocity[0], \"vy\": agent_velocity[1]}\n","            ttc, _ = calculate_ttc(ego_vehicle, other_vehicles) # Call the function\n","\n","            # --- End of TTC Calculation Logic ---\n","\n","            nearest_vehicle_state = episode_df.loc[nearest_vehicle_idx, 'state']\n","            nearest_vehicle_position = np.array([nearest_vehicle_state[1], nearest_vehicle_state[2]])\n","            nearest_vehicle_velocity = np.array([nearest_vehicle_state[3], nearest_vehicle_state[4]])\n","\n","            relative_position = nearest_vehicle_position - agent_position\n","            relative_velocity = nearest_vehicle_velocity - agent_velocity\n","            relative_speed = np.linalg.norm(relative_velocity)\n","\n","\n","            acceleration = agent_new_velocity - agent_velocity\n","\n","            collision_data = {\n","                'Vehicle_number': nearest_vehicle_idx,\n","                'Relative_position': relative_position.tolist(),\n","                'Relative_velocity': relative_velocity.tolist(),\n","                'Relative_speed': relative_speed,\n","                'TTC': ttc,\n","                'Agent_acceleration': acceleration.tolist()\n","            }\n","            df_copy.at[row.name, 'Collision_Parameters'] = collision_data\n","            df_copy.at[row.name, 'Nearest vehicle id'] = nearest_vehicle_idx\n","            df_copy.at[row.name, 'TTC'] = ttc\n","\n","    return df_copy"],"metadata":{"id":"HPpCX1PzMLZv"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["collision_parameters_df_1 = calculate_collision_parameters_1(lane_change_collision_fb_df)"],"metadata":{"id":"TqYFw2pib_zY"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["data_table.enable_dataframe_formatter()\n","data_table.DataTable(collision_parameters_df_1)"],"metadata":{"id":"h-FlnywacKHX","colab":{"base_uri":"https://localhost:8080/","height":9843,"output_embedded_package_id":"1RYNbhaIumuUSHjx0Zy8GKyLXmmahcPcT"},"executionInfo":{"status":"ok","timestamp":1750200821590,"user_tz":-330,"elapsed":2936,"user":{"displayName":"Saif Nazir","userId":"15029834638479146606"}},"outputId":"e332e582-53a8-420d-8225-1370db4e13d5"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}]},{"cell_type":"code","source":["## Time to collision list\n","## Group the data by 'episode'\n","# episode_data = collision_parameters_df_1.groupby('episode')\n","## Loop through each episode\n","# for episode, data in episode_data:\n","#    # Extract lane indices\n","#     ttc_list = data['TTC'].tolist()\n","\n","#    # Count the total number of time steps in the episode\n","#     total_timesteps = data['time_step'].max() + 1  # Assuming time_step starts from 0\n","\n","#     print(f\"Episode {episode}:Total timesteps {total_timesteps}: {ttc_list}\")"],"metadata":{"id":"-oWAV3EZcqu-"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["## List of nearest vehicles\n","## Group the data by 'episode'\n","# episode_data = collision_parameters_df_1.groupby('episode')\n","## Loop through each episode\n","# for episode, data in episode_data:\n","#     # Extract lane indices\n","#     nearest_vehicle_list = data['Nearest vehicle id'].tolist()\n","\n","#     # Count the total number of time steps in the episode\n","#     total_timesteps = data['time_step'].max() + 1  # Assuming time_step starts from 0\n","\n","#     print(f\"Episode {episode}:Total timesteps {total_timesteps}: {nearest_vehicle_list}\")"],"metadata":{"id":"mZsgFYSpigoO"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"8Ee2reKxpTB6"},"outputs":[],"source":["# Step A.2.4: Function to implement collision avoidance feedback\n","def implement_collision_feedback(df):\n","    # Create a copy of the dataframe to avoid modifying the original dataframe\n","    df_copy = df.copy()\n","\n","    # Create new columns for Collision Feedback and Collision Reward\n","    df_copy['Collision_Feedback'] = None\n","    df_copy['Collision_score'] = 0.0\n","\n","    # Iterate through each timestep in the dataframe\n","    for idx, row in df_copy.iterrows():\n","        collision_data = row['Collision_Parameters']\n","        ttc = collision_data['TTC']\n","        agent_acceleration = collision_data['Agent_acceleration']\n","        lane_change = row['Lane_change_collision_fb']\n","\n","        # Initialize feedback and reward\n","        feedback = ''\n","        feedback_1 = ''\n","        score = 0.0\n","\n","        # Logic for Time to Collision (TTC)\n","        if  0.5 <= ttc <=2.0 :\n","            feedback_1 = 'Potential collision risk'\n","            if agent_acceleration[0] < 0:\n","                feedback = 'Avoided collision by slowing down'\n","                score = +1                                                          # Bias Value 5\n","            elif agent_acceleration[0] > 0:\n","                feedback = 'Avoided collision by speeding up'\n","                score = 0                                                          # Bias Value 6\n","            elif lane_change == 1:\n","                feedback = 'Avoided collision by lane change'\n","                score = +1                                                          # Bias Value 7\n","        elif ttc < 0.5:\n","            feedback_1 = 'Immediate collision risk'\n","            # Check if agent_acceleration is not [0, 0] using any\n","            # Modified: Check if any element in agent_acceleration is not 0\n","            if any(x != 0 for x in agent_acceleration):\n","            # if agent_acceleration != [0, 0]:\n","                feedback = 'Emergency avoidance'\n","                score = -2                                                          # Bias Value 8\n","            else:\n","                score = 0.0\n","        else:\n","            feedback = 'Safe Path'\n","            score = +2                                                              # Bias Value 9\n","\n","        # Update the feedback and reward columns\n","        df_copy.at[idx, 'Collision_Feedback'] = feedback_1, feedback\n","        df_copy.at[idx, 'Collision_score'] = score\n","\n","    return df_copy"]},{"cell_type":"code","source":["# Call the function to process collision feedback and reward\n","Collision_feedback_df = implement_collision_feedback(collision_parameters_df_1)"],"metadata":{"id":"uVDzc0QMqYdO"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["data_table.enable_dataframe_formatter()\n","data_table.DataTable(Collision_feedback_df)"],"metadata":{"id":"mvv1exBGqcb6","colab":{"base_uri":"https://localhost:8080/","height":10321,"output_embedded_package_id":"12SVYo-UJ05BYxImhDcnXGs2I5aignYtq"},"executionInfo":{"status":"ok","timestamp":1750200826083,"user_tz":-330,"elapsed":3060,"user":{"displayName":"Saif Nazir","userId":"15029834638479146606"}},"outputId":"365a352a-bd61-4e3d-d2fb-5d42c5a2c8a8"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}]},{"cell_type":"markdown","source":["SECTION A.3: FEEDBACK BASED ON SPEED OPTIMIZATION\n","*   Step A.3.1: FUNCTION TO CALCULATE AGENT SPEED AND TRAFFIC DENSITY SCORE\n","*   Step A.3.2: FUNCTION TO IMPLEMENT SPEED OPTIMIZATION FEEDBACK"],"metadata":{"id":"-cVuPczPnjiy"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"Oxh0zhuHzx75"},"outputs":[],"source":["# Step A.3.1: FUNCTION TO CALCULATE AGENT SPEED AND TRAFFIC DENSITY SCORE\n","# Define the function to calculate agent speed and traffic density score\n","def calculate_speed_and_traffic_density(trajectory_df):\n","    # Create a copy of the input dataframe to avoid modifying the original\n","    df = trajectory_df.copy()\n","\n","    df['Average_distance'] = 0.0\n","    df['Traffic_density_score'] = 0\n","    df['Agent_Speed'] = 0\n","    # Initialize the Speed_Optimization_Parameters column\n","    df['Speed_Optimization_Parameters'] = None\n","\n","\n","    # Function to calculate agent speed based on vx and vy (longitudinal and lateral velocities)\n","    def calculate_speed(vx, vy):\n","        return np.sqrt(vx**2 + vy**2)\n","\n","    # Iterate through the rows of the dataframe to calculate the required values\n","    for index, row in df.iterrows():\n","        # Extract agent state and next state\n","        state = row['state']\n","        next_state = row['next_state']\n","\n","        # Extract agent vehicle's (ego vehicle) longitudinal and lateral velocity\n","        agent_vx = state[3]  # vx of agent\n","        agent_vy = state[4]  # vy of agent\n","\n","        # Calculate agent speed\n","        agent_speed = calculate_speed(agent_vx, agent_vy)\n","\n","        # Extract other vehicles' state\n","        # The original state is a flattened array of shape (25,).\n","        # We need to reshape it to (5, 5) to represent 5 vehicles, each with 5 attributes.\n","        # Then we can select the other vehicles (excluding the ego vehicle at index 0).\n","\n","        state_reshaped = state.reshape(5, 5)  # Reshape to 5 vehicles, 5 features each\n","        other_vehicles_state = state_reshaped[1:]  # Exclude ego vehicle (index 0)\n","\n","\n","        # Extract other vehicles' state\n","        # other_vehicles_state = state[1:].reshape(-1, 5)  # Extract all other vehicles' states\n","\n","        # Calculate the distances between the agent and other vehicles\n","        distances = []\n","        for vehicle in other_vehicles_state:\n","            # Calculate the distance between the agent and other vehicles using x and y positions\n","            vehicle_x, vehicle_y = vehicle[1], vehicle[2]\n","            agent_x, agent_y = state[1], state[2]\n","            distance = np.sqrt((vehicle_x - agent_x)**2 + (vehicle_y - agent_y)**2)\n","            distances.append(distance)\n","            # print(f\"Distance between agent and vehicle {index}: {distance}\")\n","\n","        # Determine traffic density score based on the distance\n","        traffic_density_score = 1  # Default low traffic density (1)\n","        avg_distance = np.mean(distances)\n","        #print(f\"Average distance between agent and other vehicles: {avg_distance}\")\n","\n","        if avg_distance < 0.8:  # High traffic density\n","            traffic_density_score = 3\n","        elif avg_distance < 1.0:  # Medium traffic density\n","            traffic_density_score = 2\n","\n","        df.at[index, 'Average_distance'] = avg_distance\n","        df.at[index, 'Traffic_density_score'] = traffic_density_score\n","        df.at[index, 'Agent_Speed'] = agent_speed\n","        # Add the agent speed and traffic density score to the 'Speed_Optimization_Parameters' column\n","        df.at[index, 'Speed_Optimization_Parameters'] = {'Agent_Speed': agent_speed, 'Traffic_Density_Score': traffic_density_score}\n","\n","\n","    return df\n"]},{"cell_type":"code","source":["# Call the function to calculate speed and traffic density\n","Speed_parameters_df = calculate_speed_and_traffic_density(trajectory_df)"],"metadata":{"id":"S7dIIMD0qkJJ","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1750200834823,"user_tz":-330,"elapsed":633,"user":{"displayName":"Saif Nazir","userId":"15029834638479146606"}},"outputId":"f204ac6c-4435-49ae-e746-a051a56ce704"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["<ipython-input-23-2084209440>:65: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '0.3125' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n","  df.at[index, 'Agent_Speed'] = agent_speed\n"]}]},{"cell_type":"code","source":["data_table.enable_dataframe_formatter()\n","data_table.DataTable(Speed_parameters_df)"],"metadata":{"id":"mLRhQOJNqnU4","colab":{"base_uri":"https://localhost:8080/","height":10256,"output_embedded_package_id":"1Z3Pwm-JWYMJJekY9sjKpH-fzKYfNP1xQ"},"executionInfo":{"status":"ok","timestamp":1750200839001,"user_tz":-330,"elapsed":2982,"user":{"displayName":"Saif Nazir","userId":"15029834638479146606"}},"outputId":"ab869466-3982-473b-dde7-4680ec4d3123"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}]},{"cell_type":"code","source":["## Distance between vehicles list\n","## Group the data by 'episode'\n","# episode_data = Speed_parameters_df.groupby('episode')\n","## Loop through each episode\n","# for episode, data in episode_data:\n","#    # Extract lane indices\n","#     average_distance_list = data['Average_distance'].tolist()\n","\n","#    # Count the total number of time steps in the episode\n","#     total_timesteps = data['time_step'].max() + 1  # Assuming time_step starts from 0\n","\n","#     print(f\"Episode {episode}:Total timesteps {total_timesteps}: {average_distance_list}\")"],"metadata":{"id":"-A9XOWDpgRQ2"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["## Traffic density score\n","## Group the data by 'episode'\n","# episode_data = Speed_parameters_df.groupby('episode')\n","## Loop through each episode\n","# for episode, data in episode_data:\n","#    # Extract lane indices\n","#     traffic_density_score_list = data['Traffic_density_score'].tolist()\n","\n","#    # Count the total number of time steps in the episode\n","#     total_timesteps = data['time_step'].max() + 1  # Assuming time_step starts from 0\n","\n","#     print(f\"Episode {episode}:Total timesteps {total_timesteps}: {traffic_density_score_list}\")"],"metadata":{"id":"-yUUPrMLERDu"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["## Agent's speed for each episode\n","## Group the data by 'episode'\n","# episode_data = Speed_parameters_df.groupby('episode')\n","## Loop through each episode\n","# for episode, data in episode_data:\n","#    # Extract lane indices\n","#    agent_speed_list = data['Agent_Speed'].tolist()\n","\n","#    # Count the total number of time steps in the episode\n","#    total_timesteps = data['time_step'].max() + 1  # Assuming time_step starts from 0\n","\n","#    print(f\"Episode {episode}:Total timesteps {total_timesteps}: {agent_speed_list}\")"],"metadata":{"id":"yko_9mnTF50A"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"uOHlfCEsp81h"},"outputs":[],"source":["# Step A.3.2: FUNCTION TO IMPLEMENT SPEED OPTIMIZATION FEEDBACK\n","def implement_speed_optimization_feedback(Speed_parameters_df):\n","    # Create a copy of the dataframe to avoid modifying the original\n","    df_copy = Speed_parameters_df.copy()\n","\n","    # Define the threshold_speed range\n","    threshold_speed_min = 0.25  # Example minimum threshold speed\n","    threshold_speed_max = 0.30  # Example maximum threshold speed\n","    threshold_speed = (threshold_speed_min, threshold_speed_max)  # Tuple representing min and max speeds\n","\n","    # Initialize columns for feedback and reward\n","    speed_optimization_feedback = []\n","    speed_optimization_score = []\n","\n","    # Iterate through the dataframe to calculate feedback and rewards\n","    for i in range(len(df_copy)):\n","        # Extract the agent speed and traffic density from the Speed_Optimization_Parameters\n","        # agent_speed = df_copy['Speed_Optimization_Parameters']['Agent_Speed']\n","        # traffic_density = df_copy['Speed_Optimization_Parameters']['Traffic_density_score']\n","        agent_speed = df_copy['Speed_Optimization_Parameters'][i]['Agent_Speed']\n","        traffic_density = df_copy['Speed_Optimization_Parameters'][i]['Traffic_Density_Score']\n","\n","        feedback = \"\"\n","        score = 0.0\n","\n","        # Check traffic density and apply corresponding logic\n","        if traffic_density == 1:  # Low traffic density\n","            if agent_speed > threshold_speed[1]:\n","                feedback = \"Low risk, High Speed-Optimization\"\n","                score = +2                                                          # Bias Value 10\n","            elif threshold_speed[0] <= agent_speed <= threshold_speed[1]:\n","                feedback = \"Low risk, moderate Speed-Optimization\"\n","                score = +1                                                          # Bias Value 11\n","            else:  # agent_speed < threshold_speed[0]\n","                feedback = \"Low risk, Low Speed-Optimization\"\n","                score = -1                                                          # Bias Value 12\n","\n","        elif traffic_density == 2:  # Medium traffic density\n","            if agent_speed > threshold_speed[1]:\n","                feedback = \"Moderate risk, High Speed-Optimization\"\n","                score = -1                                                          # Bias Value 13\n","            elif threshold_speed[0] <= agent_speed <= threshold_speed[1]:\n","                feedback = \"Moderate risk, moderate Speed-Optimization\"\n","                score = +2                                                          # Bias Value 14\n","            else:  # agent_speed < threshold_speed[0]\n","                feedback = \"Moderate risk, Low Speed-Optimization\"\n","                score = -1                                                          # Bias Value 15\n","\n","        elif traffic_density == 3:  # High traffic density\n","            if agent_speed > threshold_speed[1]:\n","                feedback = \"High risk, High Speed-Optimization\"\n","                score = -2                                                          # Bias Value 16\n","            elif threshold_speed[0] <= agent_speed <= threshold_speed[1]:\n","                feedback = \"High risk, moderate Speed-Optimization\"\n","                score = -1                                                          # Bais Value 17\n","            else:  # agent_speed < threshold_speed[0]\n","                feedback = \"High risk, Low Speed-Optimization\"\n","                ascore = +2                                                          # Bias Value 18\n","\n","        # Append the feedback and reward to the respective lists\n","        speed_optimization_feedback.append(feedback)\n","        speed_optimization_score.append(score)\n","\n","    # Add the new columns to the dataframe\n","    df_copy['Speed_Optimization_Feedback'] = speed_optimization_feedback\n","    df_copy['Speed_Optimization_score'] = speed_optimization_score\n","\n","    return df_copy"]},{"cell_type":"code","source":["Speed_optimization_feedback_df = implement_speed_optimization_feedback(Speed_parameters_df)"],"metadata":{"id":"LbwS2giIqvqG"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["data_table.enable_dataframe_formatter()\n","data_table.DataTable(Speed_optimization_feedback_df)"],"metadata":{"id":"HMaW6U2yq0Vg","colab":{"base_uri":"https://localhost:8080/","height":10321,"output_embedded_package_id":"1qHAZoiln0lyY27a8ger66R5HiRNp1Pjh"},"executionInfo":{"status":"ok","timestamp":1750200851676,"user_tz":-330,"elapsed":2992,"user":{"displayName":"Saif Nazir","userId":"15029834638479146606"}},"outputId":"336c3831-3ad4-4c81-85da-1bd7269980c0"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}]},{"cell_type":"markdown","source":["SECTION- A.4: REWARD MODELLING(HUMAN FEEDBACK)\n","*   Step A.4.1: COMBINING HUMAN FEEDBACK AND CALCULATING ADJUSTED REWARDS\n","*   Step A.4.2: RECALIBRATE REWARDS BASED ON SIMULATED HUMAN FEEDBACK"],"metadata":{"id":"RMguIvy_oi5x"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"kJWJEkepqldb"},"outputs":[],"source":["# Step A.4.1: COMBINING HUMAN FEEDBACK AND CALCULATING ADJUSTED REWARDS\n","# Function to combine data from four dataframes and merge with trajectory_df\n","def combine_feedback_and_rewards(trajectory_df, collision_feedback_df, speed_optimization_feedback_df, lane_behaviour_feedback_df):\n","    # Create a copy of the trajectory_df to avoid modifying the original one\n","    df_copy = trajectory_df.copy()\n","\n","    # Convert the 'Collision_Feedback' column to strings\n","    #collision_feedback_df['Collision_Feedback'] = collision_feedback_df['Collision_Feedback'].apply(lambda x:''.join(map(str, x)))\n","    collision_feedback_df['Collision_Feedback'] = collision_feedback_df['Collision_Feedback'].astype(str)\n","\n","\n","    # Combine the 'Feedback' columns from the four dataframes and add to the 'Simulated_human_feedback' column\n","    df_copy['Simulated_human_feedback'] = (\n","        collision_feedback_df['Collision_Feedback'] + \";\" +\n","        speed_optimization_feedback_df['Speed_Optimization_Feedback'] + \";\" +\n","        lane_behaviour_feedback_df['Lane_feedback']\n","    )\n","\n","    # Add the values of the 'Reward' columns from the four dataframes and store the result in 'Adjusted_score' column\n","    df_copy['Adjusted_score'] = (\n","        collision_feedback_df['Collision_score'] +\n","        speed_optimization_feedback_df['Speed_Optimization_score'] +\n","        lane_behaviour_feedback_df['Lane_change_score']\n","    )\n","\n","    # Return the updated dataframe\n","    return df_copy"]},{"cell_type":"code","source":["# Call the function to combine feedback and calculate adjusted rewards\n","simulated_human_feedback_df = combine_feedback_and_rewards(\n","    trajectory_df,\n","    Collision_feedback_df,\n","    Speed_optimization_feedback_df,\n","    lane_behaviour_feedback_df\n",")"],"metadata":{"id":"pDDBxP6Mq6zJ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["data_table.enable_dataframe_formatter()\n","data_table.DataTable(simulated_human_feedback_df)"],"metadata":{"id":"T7M6IqIfq8pl","colab":{"base_uri":"https://localhost:8080/","height":5030,"output_embedded_package_id":"1jaVQRD6_62_OFmTTmn_EsHcHfTGTFRn-"},"executionInfo":{"status":"ok","timestamp":1750200861732,"user_tz":-330,"elapsed":2366,"user":{"displayName":"Saif Nazir","userId":"15029834638479146606"}},"outputId":"0d6ddaa8-8afb-4c5c-9593-f3d4fb175dc8"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}]},{"cell_type":"code","source":["## List of adjusted scores for each episode\n","## Group the data by 'episode'\n","# episode_data = simulated_human_feedback_df.groupby('episode')\n","## Loop through each episode\n","# for episode, data in episode_data:\n","#    # Extract lane indices\n","#     adjusted_score_list = data['Adjusted_score'].tolist()\n","\n","#     # Count the total number of time steps in the episode\n","#     total_timesteps = data['time_step'].max() + 1  # Assuming time_step starts from 0\n","\n","#     print(f\"Episode {episode}:Total timesteps {total_timesteps}: {adjusted_score_list}\")"],"metadata":{"id":"mqGxdh9QnsHm"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Step A.4.2: RECALIBRATE REWARDS BASED ON SIMULATED HUMAN FEEDBACK\n","# Function to recalibrate the rewards\n","def recalibrate_rewards(df):\n","    # Create a copy of the dataframe\n","    df_copy = df.copy()\n","\n","    # Create the 'Recalibrated_rewards' column\n","    df_copy['Recalibrated_rewards'] = df_copy['reward'] + df_copy['Adjusted_score']\n","\n","    # Get the list of recalibrated rewards\n","    recalibrated_rewards_list = df_copy['Recalibrated_rewards'].tolist()\n","\n","    return df_copy, recalibrated_rewards_list"],"metadata":{"id":"E_vUgUJ2rJ7t"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Apply the function to recalibrate rewards\n","recalibrated_df, recalibrated_rewards_list = recalibrate_rewards(simulated_human_feedback_df)"],"metadata":{"id":"1tqZXWwmrNFI"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["data_table.enable_dataframe_formatter()\n","data_table.DataTable(recalibrated_df)"],"metadata":{"id":"a7_UyXGvIt6n","colab":{"base_uri":"https://localhost:8080/","height":5675,"output_embedded_package_id":"1CEQWI6CvPHioR7vlIaRf2UMeBz_jGG3s"},"executionInfo":{"status":"ok","timestamp":1750200872587,"user_tz":-330,"elapsed":2502,"user":{"displayName":"Saif Nazir","userId":"15029834638479146606"}},"outputId":"d5cb9df0-9e8e-4541-8c5b-efd52ca2f337"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}]},{"cell_type":"code","source":["recalibrated_df.to_pickle('/content/drive/MyDrive/05_zero_shot_llm_3/02_data/02_trajectories/1_human_feedback/1_Hf_D_ideal_df.pkl')            # Update directory location 2"],"metadata":{"id":"Of47ds4OJL2v"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["episode_data = recalibrated_df.groupby('episode')\n","# Loop through each episode\n","for episode, data in episode_data:\n","    # Extract lane indices\n","     recalibrated_reward_l = data['Recalibrated_rewards'].tolist()\n","\n","     # Count the total number of time steps in the episode\n","     total_timesteps = data['time_step'].max() + 1  # Assuming time_step starts from 0\n","\n","     print(f\"Episode {episode}:Total timesteps {total_timesteps}: {recalibrated_reward_l}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"nIaArIukEZrX","executionInfo":{"status":"ok","timestamp":1750200887005,"user_tz":-330,"elapsed":57,"user":{"displayName":"Saif Nazir","userId":"15029834638479146606"}},"outputId":"da4102a9-a46d-4456-d157-949f31b24f7f"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Episode 0:Total timesteps 40: [0.7999999999999999, -1.0894517646168187, -1.0705603718311516, 1.8221197095484385, 0.8245128840260193, 1.8228564886726688, -1.288215715870427, 0.6687138988604007, 1.6673119774741734, 1.6667806838246682, 1.777234425788464, 1.6855613960920564, 0.6698955536235615, 0.6672184454585547, 0.6667609591703169, 0.6666827801461538, 0.6666694202707298, 0.666667137225204, 0.6666667470795843, 0.6666666804082882, 0.6666666690149482, 0.6666666670679603, 0.6666666667352429, 2.6666666666783856, 2.6666666666686694, 2.666666666667009, 2.666666666666725, 2.6666666666666767, 2.6666666666666683, 2.666666666666667, 2.666666666666667, 2.666666666666667, 2.666666666666667, 2.666666666666667, 2.666666666666667, 2.666666666666667, 2.666666666666667, 2.666666666666667, -0.311111111111111, -0.33333333333333337]\n","Episode 1:Total timesteps 40: [1.733896209061263, 3.7150048162755964, 3.7117764995128244, 2.7333333333333334, 2.7333333333333334, 2.7333364176553143, 3.73333389839033, 3.7333334302789356, 3.7333333499040706, 2.7333333361651166, 2.733333333817252, 2.7333333334160295, 2.733333333347465, 2.7111111111111112, 0.7111111111111111, 3.7333333333333334, 2.7333333333333334, 2.7333333333333334, 2.7333333333333334, 2.7333333333333334, 2.7333333333333334, 2.7333333333333334, 2.7111111111111112, 0.7111111111111111, 3.688888888888889, 1.688888888888889, 0.688888888888889, 1.688888888888889, 0.688888888888889, 0.688888888888889, 0.6666666666666666, 0.6666666666666666, 3.6666666666666665, 3.6666666666666665, 3.688888888888889, 0.688888888888889, 1.688888888888889, 0.6666666666666666, 0.6666666666666666, 3.6666666666666665]\n","Episode 2:Total timesteps 40: [4.756118431283485, 0.7372270384978186, 0.7339987217350469, 0.8439952757658243, 1.8627923926991028, 1.7554563634447105, 0.7371138988936474, 0.7339793875078238, 0.8439919717738661, 1.7522435927025684, -0.2875254760078625, 0.8221960358374313, 0.8614025534746929, 3.8660063458276013, 1.756007396998219, 0.7372080773684453, 0.7339954816420909, 0.7334464866903289, 0.733352669910767, 0.7333366377269148, 0.733333898015319, 0.733333429830841, 0.8438815852068035, 1.862772964320178, 1.8660012787465154, 0.8428433490480817, 1.9549654808465857, 1.8633324958126685, 1.7371239582540263, 0.7155564006570763, 0.7118707587942312, 0.7112409259626195, -0.311111111111111, 3.688888888888889, 3.6888893005952523, 4.688888997208463, 4.688888907783241, 3.7111111111111112, 0.7111111111111111, 0.7111111111111111]\n","Episode 3:Total timesteps 40: [0.6894517646168187, 4.670560371831152, 1.6673320550683801, 1.666780373715976, 1.6666860978635878, 0.688888888888889, 0.688888888888889, 0.688888888888889, 0.7111111111111111, 3.7111111111111112, 3.688888888888889, 1.688888888888889, 0.688888888888889, 0.688888888888889, 0.7111111111111111, 3.7111111111111112, 0.7111111111111111, 3.7111111111111112, 3.7111111111111112, 3.7333333333333334, 2.7333333333333334, 0.7333333333333334, 0.7333333333333334, 0.84388156870074, 1.7522247261188988, -0.2875286978456516, 4.711639528029015, 3.688888888888889, 0.688888888888889, 0.6666666666666666, 0.6666666666666666, 0.6666666666666666, -1.3333333220291874, -1.333333331010035, -1.3333333329323582, -1.3333333332647714, -1.3333333333216166, -1.333333333331331, -1.333333333332991, -1.3333333333332749]\n","Episode 4:Total timesteps 40: [1.733896209061263, 4.715004816275596, 3.7117764995128244, 3.711224818160421, 3.711130542308032, 2.7333333333333334, 2.7333333333333334, 0.7333333333333334, -0.28888888888888886, 1.7333333333333334, 2.7333333333333334, 0.7333333333333334, 0.7333333333333334, 0.7333333333333334, 0.7333333333335489, 0.7333333333334018, 0.7333333333333454, 2.7333333333333356, 2.733333333333334, 2.733333333333334, 2.733333333333334, 2.733333333333334, 2.733333333333334, 2.733333333333334, 2.733333333333334, 2.733333333333334, 2.843881568716515, 1.8627729615021815, 1.7554530428817716, 0.7371133314485091, 0.7339792905381258, 0.7334437198197045, 0.7333521970851159, 0.8438847923097552, 1.7522252769931583, 0.7365617442340172, 0.7338850307727992, 0.7334276119348114, 0.7333494444371028, 0.8438843219145958]\n","Episode 5:Total timesteps 20: [0.6894517646168187, 1.6705603718311517, 1.6673320550683801, 1.666780373715976, 1.6666860978635878, 1.6666699872296054, 1.7772154694949864, -1.3144418435779688, -0.3097509062838606, -0.28888888888888886, 2.7111774938381124, 0.8216752691146497, 0.8168485189980889, 0.9320979807194726, -1.0484517884889741, -2.0685854802683634, -1.06678995524679, -1.066686677941878, -1.177218319535899, -2.977777777777778]\n","Episode 6:Total timesteps 40: [1.8222222222222224, 2.8222222222222224, 2.8222222222222224, 1.8429569908025045, 0.9549849060220487, 1.8633358163447604, 1.7371245256985497, 0.8261047330103217, 1.8413104035340573, 1.7333606383428415, -0.26473250622538747, 0.7339597612491032, 0.733444126731957, 0.7333523053564401, 0.8438848112124884, 1.752225280226063, -0.2875286031091293, 0.7116395442015842, 0.7112051495209403, -0.2666666666666666, 0.7333333333333334, 0.7333335681853801, 0.733333411352417, 0.733333347048898, 0.7333333356810265, -0.28888888888888886, 0.7111111111111111, -0.2666666666666666, 0.7333333333333334, 0.7333333333333334, 0.7333333333333334, 0.7333333333333334, 0.7333333333333334, 0.8438815687165132, 1.7522247261190005, 0.736561650096105, -0.28888888888888886, -0.2666666666666666, 2.7333333333333334, -0.28888888888888886]\n","Episode 7:Total timesteps 23: [0.7116739868390409, -1.3072174059466257, 4.689554277290602, 3.6666666666666665, 3.6666666666666665, 0.6666697509886479, 1.6666672317236637, 1.6666667636122692, 1.7772149186206692, 1.7961062976672997, -1.3112136233009761, 1.6704466648645382, 1.667312623885591, 0.688888888888889, 1.688888888888889, 0.6666666666666666, 3.6666666666666665, 1.6666666666666665, 1.6666666804145254, 1.6666666693921548, 0.688888888888889, 1.688888888888889, 0.04444444444444443]\n","Episode 8:Total timesteps 40: [0.7116739868390409, 1.6927825940533743, 1.6895542772906023, 1.6890025959381982, 1.68890832008581, 1.6888922094518275, 1.6888894563340275, 0.7111111111111111, 3.7111111111111112, 3.7111111111111112, 3.7333333333333334, 2.8438662425033225, 1.862772894042367, 1.7554530424518742, 0.7371133314444639, 0.7339792905381507, 0.733443719819716, 0.7333521970851179, 0.8438847923097555, 1.7522252769931583, 0.7365617442340172, 0.7338850307727992, -0.28888888888888886, 1.7333333333333334, 2.7333333333333334, 0.7333336123299055, 0.7333334117981901, 0.7333333470533928, 0.7333333356810715, 0.7333333337345658, 0.8438815687850809, 1.8627729615138988, 1.755453042883774, 0.737113331448851, 0.7339792905381842, 0.8439919552028957, 1.7522435898707842, 0.7365648736893458, 0.7338855655598954, 0.7334277033236343]\n","Episode 9:Total timesteps 40: [3.8666666666666667, 3.8666666666666667, 1.7561184312834852, 0.7372270384978186, 0.7339987217350469, 0.7334470403826429, 0.7333527645302543, 0.7333366538962719, -0.28888888888888886, 2.7111111111111112, 2.7111111111111112, 2.7111111115562854, 2.71111111157095, 2.7111111111935644, 2.7333333333333334, 0.843866273240817, 1.7522246227951679, 0.7365616490343623, 0.7338850146748864, 0.7334276091856139, 0.733349443967315, 0.7333360864511334, 0.7333338038087738, 0.7333334137320509, 0.7333333470725282, 0.7333333356812001, 0.7333333337345563, 0.7333333334018975, 0.7333333333450502, 2.7333333333353353, 2.7333333333336753, 2.7333333333333916, 2.733333333333343, 2.733333333333335, 2.733333333333334, 2.733333333333334, 2.733333333333334, 2.733333333333334, 2.733333333333334, 2.733333333333334]\n","Episode 10:Total timesteps 40: [-0.20000000000000007, 2.689451764616819, 5.670560371831152, 5.66733205506838, 4.6667803737159765, 4.666686097863588, 4.666669987229605, 4.666667234111805, 4.666666763636364, 4.666666683237647, 3.6666666694984524, 3.7772149025337667, 2.7961062949182107, 1.8200697691586534, 1.711543705575095, 2.7130800762218334, 1.7333333333333334, 2.7334185130076714, 0.733352380214349, 0.733336634420767, 0.7333338979173808, 0.7333334298188167, 0.7333333498216148, 0.7333333361509872, -0.28888888888888886, 0.7111111111111111, 2.7333333333333334, 2.7333333333333334, 0.7333333333333334, 0.843881567183964, 1.8627729614957982, 1.7554530428817334, 0.737113331448509, 0.7339792905381258, 0.7334437198197045, 0.7333521970851159, 0.7333365569265738, 0.7333338842074912, 0.7333334274712456, 0.7333333494203949]\n","Episode 11:Total timesteps 40: [0.6894517646168187, 4.670560371831152, 4.66733205506838, 4.6667803737159765, 4.666686097863588, 4.666669987229605, 4.666667234111805, 3.688888888888889, 3.688888888888889, 3.688888888888889, 3.688888888888889, 3.688888888947505, 3.6888888889027776, 3.7111111111111112, 3.7111111111111112, 3.7333333333333334, 0.7333333333333334, 0.7333333333333334, -1.2666666666666666, -0.28888888888888886, 2.7111111111111112, 0.7111111111111111, 3.7111111111111112, 3.7111111111111112, 3.7333333333333334, 2.7333333333333334, 0.7333333333333334, 0.7333333333333334, 0.7333333333333334, 0.7333333333333334, 0.7333333333333334, 0.7333333333333337, 2.733333333333334, 2.843881568716515, 1.7522247261190005, 0.736561650096105, 0.7338850146857374, 0.7334276091857218, 0.7333494439673158, 0.7333360864511334]\n","Episode 12:Total timesteps 11: [1.8429569908025045, 1.7338795756087126, 1.7150046320282737, 1.7117764976082186, 1.7112248181411096, 0.7333333333333334, 2.7333333333333334, 0.7333336646543737, 0.8438816641223186, 1.7522247426799153, 0.06666666666666665]\n","Episode 13:Total timesteps 40: [4.756118431283485, 3.7372270384978186, 0.7339987217350469, 0.7334470403826429, 0.7333527645302543, 0.7333366538962719, 0.7333339007784718, -1.2888888888888888, 1.688888888888889, 3.688888888888889, 3.7111111111111112, 0.7111111111111111, 3.7111111111111112, 2.7111111111111112, 2.7111111111111112, 3.7333333333333334, 2.7333333333333334, 2.7333333333333334, 0.7333333333333334, 0.7333333333333334, 0.7333333333333334, 0.7333333333333334, 0.7333333333333337, 2.733333333333334, 2.733333333333334, 2.733333333333334, 2.733333333333334, 2.733333333333334, 2.733333333333334, 2.733333333333334, 2.733333333333334, 2.733333333333334, 2.733333333333334, 2.733333333333334, 2.733333333333334, 2.733333333333334, 2.733333333333334, 2.733333333333334, 2.733333333333334, 2.733333333333334]\n","Episode 14:Total timesteps 12: [0.8444444444444444, -1.266103790938737, 0.8255530516587775, 1.7306678922984915, -0.3096371960648391, 4.689436725882896, 3.7111111111111112, 3.7111111111111112, 1.8216620446620864, 1.8405512256890457, 0.8645141717095047, 5.075200536638093]\n","Episode 15:Total timesteps 40: [0.7999999999999999, -1.3105482353831812, 1.6705603718311517, 1.6673320550683801, 1.666780373715976, 1.6666860978635878, 1.6666699872296054, 1.6666672341118054, 1.6666667636363646, 1.666666683237647, 3.6666666694984524, 3.7772149025337667, -1.2038937050817893, -1.2006653883875815, -2.179378873253973, -1.2883620677043854, 0.7130961231914793, 3.688888888888889, 3.68898395157994, 4.688908112097722, 0.6666666666666666, 3.6666666666666665, 1.6666666666666665, 0.6666666808325526, 1.6666666694719132, 1.6666666671499293, 1.6666666667492898, 1.6666666666807863, 1.6666666666690797, 1.666666666667079, 0.688888888888889, -1.311111111111111, 1.688888888888889, 1.688888888888889, 1.688888888888889, 0.6666666666666666, 3.6666666666666665, 1.6666666666666665, 1.6666666666666665, 1.6666666666666665]\n","Episode 16:Total timesteps 40: [4.756118431283485, 3.7372270384978186, 3.733998721735047, 3.733447040382643, 3.733352764530254, 3.733336653896272, 3.733333900778472, 3.7333334303030314, 3.733333349904314, 2.733333336165119, 2.733333333817252, 2.7333333334160295, 2.733333333347465, 2.7333333333357483, 2.733333333333746, 2.733333333333404, 2.7333333333333454, 2.7333333333333356, 2.733333333333334, 2.733333333333334, 2.733333333333334, 2.733333333333334, 2.733333333333334, 2.7111111111111112, 0.7111111111111111, 3.7111111111111112, 3.7111111111111112, 3.7111111111111112, 3.7111111111111112, 3.688888888888889, 0.688888888888889, 0.688888888888889, 0.688888888888889, 0.688888888888889, 0.688888888888889, 0.688888888888889, 0.6888888888888892, 0.6888888888888892, 0.6888888888888892, 0.6888888888888892]\n","Episode 17:Total timesteps 6: [0.7338962090612631, 4.715004816275596, 3.7333333333333334, 3.7111111111111112, 3.7111119717798653, 3.0666666666666664]\n","Episode 18:Total timesteps 40: [3.8666666666666667, 1.7561184312834852, 0.7372270384978186, 0.7339987217350469, 0.7334470403826429, 0.7333527645302543, 0.7333366538962719, 0.7333339007784718, 0.7333334303030313, 3.733333349904314, 2.733333336165119, 2.733333333817252, 2.7333333334160295, 2.733333333347465, 2.7333333333357483, 2.733333333333746, 2.733333333333404, 2.7111111111111112, 0.7111111111111111, 3.7111111111111112, 3.7111111111111112, 3.7333333333333334, 2.7333333333333334, -1.2666666666666666, 0.7333333333333334, 0.7333333333333334, 0.7333333333333334, 0.7333333333333334, 0.7333333333333337, 2.733333333333334, 2.733333333333334, 2.733333333333334, 2.733333333333334, 2.733333333333334, 2.733333333333334, 2.7111111111111112, 0.7111111111111111, 3.7111111111111112, 3.7111111111111112, 3.7111111111111112]\n","Episode 19:Total timesteps 40: [-0.06722954239459644, -2.0273473293206887, 1.8665553760570743, 1.9587726455056527, 1.9745300297740562, 0.9537666581708635, -1.155096498199732, -1.2844485904932577, 1.6934452119535761, 1.6896675110242816, 0.7111111111111111, 1.821666778808921, -2.183132536766636, 0.932098238667422, -1.1589999983380799, -2.1982808590587077, -1.1994632919840447, -1.3104546152337155, 1.6705763846516382, 1.6673347916220584, 1.666780841362359, 1.6666861777788684, 1.6666700008861866, 1.6666672364455541, 1.6666667640351749, 1.6666666833057993, 0.688888888888889, -2.3333333333333335, 1.6666666666666665, 1.6666666666666665, 1.6666666666666665, 1.6666666666666665, 0.688888888888889, 1.688888888888889, 1.7994369693305248, -1.1816714835921966, -1.1784431661821593, -1.1778914848270983, -1.2883454443578803, 1.6927792734904354]\n","Episode 20:Total timesteps 3: [1.8222222222222224, 1.9327704576054034, 2.0904573901758274]\n","Episode 21:Total timesteps 6: [1.8222222222222224, 2.8222222222222224, 2.8222222222222224, 2.9327704576054034, 2.841113615007889, 1.0]\n","Episode 22:Total timesteps 26: [3.8666666666666667, 4.756118431283485, 0.8477752738809997, 1.7528901145207136, 0.7366753571454145, 0.7339044458826582, 0.7334309297486602, 0.7333500114124543, 0.7333361834208313, 0.7333338203797544, 0.7333334165638364, 0.7333333475564471, 2.7333333357638963, 2.733333333748688, 2.7333333334043126, 2.733333333345463, 2.7333333333354064, 2.7333333333336878, 2.733333333333394, 0.843881568716525, 1.9733211968853643, 0.9719878197959345, 4.866441708582754, 3.8689549054019614, 4.86729771601964, 0.04444444444444443]\n","Episode 23:Total timesteps 40: [0.7116739868390409, 4.692782594053374, 3.8001025126737837, 1.7078939887238653, 2.7124907338871385, 1.7333333333333334, 0.7334002823963909, 0.7333492542939224, 0.7333361001247608, 0.7333338066113265, 0.7333334142156747, 0.7333333471552211, 0.7333333356953317, 0.7333333337369711, 0.7333333334023103, 0.7333333333451207, 0.7333333333353477, -0.28888888888888886, -1.2888888888888888, 0.7111111111111111, -0.2666666666666666, -0.28888888888888886, -1.2888888888888888, 0.8216592207721855, 1.8405507387522433, 0.8645143273930476, 1.7559881509641144, 0.737207423857002, 0.733995399276091, 0.8439947083080844, 0.8390851589132485, 1.733217839678523, -0.2647175964832996, 2.7111111111111112, 0.7112028933906669, 0.7111297855200399, 0.711114333242627, 0.7111116620479451, -1.311111111111111, 2.6666666666666665]\n","Episode 24:Total timesteps 11: [0.7116739868390409, 1.6927825940533743, -0.28888888888888886, 1.7333333333333334, 0.7333333333333334, -0.28888888888888886, 0.8216449532222728, 2.8613078996732626, 0.84253697636131, 0.8652977583077712, 0.05082933647184366]\n","Episode 25:Total timesteps 40: [0.6894517646168187, 1.6705603718311517, -0.311111111111111, -0.28888888888888886, 3.7111111111111112, 2.688888888888889, 3.688888888888889, 3.688888888888889, 3.6888889031253598, 3.68888889169712, 3.68888888937257, 3.6888888889715825, 3.6888888889030205, 3.6888888888913036, 3.6888888888893017, 3.6888888888889593, 3.6666666666666665, 0.6666666666666666, 1.6666666666666665, 1.6666666666666665, 1.6666666666666665, 1.6666666666666665, 1.6666666666666665, 1.666666666666667, 1.666666666666667, 1.666666666666667, 1.666666666666667, 1.666666666666667, 1.666666666666667, 1.666666666666667, 1.666666666666667, 1.666666666666667, 3.688888888888889, -1.311111111111111, 3.688888888888889, 3.688888888888889, 3.7111111111111112, 3.7111111111111112, 3.7111111111111112, 3.7111111111111112]\n","Episode 26:Total timesteps 40: [3.977214902049848, 1.8855580594523338, 1.8698949834294383, 1.9777665834022522, 1.9962005706879036, 1.8888024868490878, 1.7599011825164608, 0.7378734661780516, 0.7341091886201353, 0.7334659178736201, 0.7333559904713618, 0.7333372051716527, 0.7333339949849486, -0.28888888888888886, 0.7111111111111111, 0.7111111111111111, 0.7111111111111111, 0.7111111111834564, 1.7111111111273463, 1.7111111111139246, 1.7111111111115922, 1.7111111111111934, 1.711111111111125, 0.7333333333333334, -1.2666666666666666, 0.7333333333333334, 0.8438815671528223, 0.839066018473814, 1.73321453891849, 0.714890929667296, 0.7117570664613931, 1.7112214975786824, 1.711129974862704, 1.7111143347043498, 1.711111661985269, 1.7111112052490234, 0.7333333333333334, 0.7333333333333334, 0.7333333333333334, -0.28888888888888886]\n","Episode 27:Total timesteps 40: [1.8651792130247267, 1.8666552326550572, 1.7561183447319615, 0.7372270375824148, 0.7339987217256295, 0.7334470403825475, 0.7333527645302534, -0.28888888888888886, 2.7111111111111112, 1.7111111111111112, 1.7111111252954432, 0.7333333333333334, -0.28888888888888886, 2.7111111111111112, 1.7111111111111112, 1.821659345228111, -1.269997496110975, 1.71433942787387, 1.7116627924635264, 0.7333333333333334, 0.7333333333333334, 0.7333358502351687, 0.7333338014208951, 0.8438816490994493, 1.9733212106245164, 1.8848926733984865, 1.7592330413981703, 0.7377592887218657, 0.7340896770362138, 0.733462583573489, 0.7333554206786986, 0.7333371078007903, 0.8438822137285951, 1.8627730717271573, 1.7554530617179234, 0.7371133346673856, 0.733979291088194, 0.7334437199137046, 0.7333521971011794, 0.7333365569293191]\n","Episode 28:Total timesteps 40: [1.8651792130247267, 4.843205951665599, 4.733881859376771, 2.690879817421883, 3.7111111111111112, 1.688888888888889, 2.6666666666666665, 3.6666666666666665, 1.666666953283225, 1.7772149971599394, -1.203893688601264, -1.2006653855699598, -1.310661941948572, 1.670540940716927, 1.6673287345195735, 1.777328041656434, -1.3144226063200306, 1.780446522804648, -2.1826045536026117, -1.2889133627508813, 1.692684833883368, 1.689537600167328, 0.6666666666666666, 3.6666666666666665, 1.6666696678180704, 1.6666672175034174, 1.6666667611821215, 1.777214918205385, -1.2038937024036676, -1.2006653879299223, -1.3106619423518673, 1.6705409406480083, 1.7778769698909778, -1.314328800943093, 0.6902684146786418, 0.6666666666666666, 3.66674292546122, 1.6666826820428229, 1.6666694343337731, 1.6666671399401967]\n","Episode 29:Total timesteps 40: [1.6894517646168188, 1.6705603718311517, -0.311111111111111, -0.28888888888888886, 3.7111111111111112, 3.7333333333333334, 2.7333333333333334, 0.7333333333333334, 0.7333333474649449, 0.7333333361405069, 0.7333333338170039, 0.7333333334160268, 0.7333333333474651, 0.7333333333357482, 0.733333333333746, 0.7333333333334039, 0.7333333333333454, 0.7333333333333355, -0.28888888888888886, 0.7111111111111111, 3.688888888888889, 0.7111111111111111, 3.7111111111111112, 3.7111111111111112, 3.7333333333333334, 0.7333333333333334, 0.7333333333333334, 0.8438815671499987, 1.7522247261089179, 0.8471098854792184, 1.863324642854585, 1.7555473187341604, 0.7371294420824915, 0.7339820436559258, 0.733444190295145, 0.7333522774838332, 0.7333365706657687, 0.8438821219385394, 1.8627730560413167, 1.9765495298037603]\n","Episode 30:Total timesteps 40: [3.8666666666666667, 1.7561184312834852, 0.7372270384978186, -0.28888888888888886, -0.2666666666666666, 2.733334194002088, 0.7333364623586861, 0.733333898841769, 0.7333334302834901, 0.7333333499041167, 0.733333336165117, 0.7333333338172522, 0.7333333334160294, -0.28888888888888886, -1.2888888888888888, 0.821659191550333, 1.7300025028948829, 0.7143394278636617, -0.2666666666666666, 2.7334046091624487, 0.7333492071675417, 0.7333360840571075, 0.8438820391761316, 1.7522248065176158, 0.7365616638352989, 0.7338850170336041, 0.7334276095869446, 0.7333494440358801, 0.7333360864628501, 0.7333338038107761, 0.7333334137323929, -0.28888888888888886, -0.2666666666666666, 2.7333333333333334, 0.7333333333333334, 0.7333333333333334, 0.7333333333333334, -0.28888888888888886, 1.7111111111111112, 1.821659191552755]\n","Episode 31:Total timesteps 35: [4.756118431283485, 0.7372270384978186, 0.7339987217350469, 0.7334470403826429, 0.7333527645302543, -0.28888888888888886, -0.2666666666666666, 2.7333333333333334, 0.7333333333333334, 0.7333333342289928, 0.733333333797717, 0.7333333334158323, -0.28888888888888886, -1.2888888888888888, 1.7111111111111112, 1.7111111111111112, 1.7111111111111112, 3.7111111111111112, 3.7111111111111112, 3.7111111111111117, 3.7111111111111117, 3.7333333333333334, 0.8438662732072594, 1.7522246227945506, 0.7365616490342896, -0.28888888888888886, 0.7111823897846605, 1.7111269849742752, 1.7111138618351776, 0.688888888888889, -1.2005780939702877, -2.071123276562224, -3.0724570669393705, 0.9325481526155156, 1.0]\n","Episode 32:Total timesteps 40: [0.6894517646168187, 1.6705603718311517, 0.688888888888889, 1.7995354844088105, -1.292200390946527, 1.69212052514743, 1.6894411376755132, 1.6889832617108649, 1.6889050160938508, 1.6888916448384745, 1.6888893598482482, -1.3111110306296974, -1.3111110973577844, -1.3111111087608296, -2.3333333333333335, 0.6666666666666666, 1.6666666666666665, 0.688888888888889, -1.311111111111111, -1.311111111111111, -3.2888888888888888, 2.7333333333333334, 0.8438630714282631, 1.8627728804771695, 1.7554530423634538, 0.7371133314431656, 0.7339792905380711, 0.7334437198197038, 0.7333521970851159, 0.7333365569265738, 0.7333338842074912, 0.7333334274712456, -0.28888888888888886, 3.8216440537328498, -1.2699975989578967, 1.7143394268923484, 1.7116627924663712, 1.7112053869657342, 0.688888888888889, 0.688888888888889]\n","Episode 33:Total timesteps 40: [1.8207347685802824, -1.2883426466135095, 1.692782409806051, 1.6895542753859965, 0.6666666666666666, 1.6666666666666665, -0.311111111111111, -0.28888888888888886, 1.688888888888889, 2.6666666666666665, 3.6666666666666665, 3.6666666666666665, 3.6666666666666665, 3.6666666666666665, 3.6666666666687937, 3.6666666666670764, 3.688888888888889, -0.311111111111111, -1.311111111111111, -1.311111111111111, -1.311111111111111, -1.311111111111111, -1.311111111111111, -1.311111111111111, -1.311111111111111, -1.311111111111111, -1.311111111111111, -2.3333333333333335, -0.33333333333333337, -2.311111111111111, -1.311111111111111, -1.311111111111111, -1.311111111111111, -1.311111111111111, -1.311111111111111, -1.311111111111111, -1.311111111111111, -3.2888888888888888, -0.2666666666666666, 3.7111111111111112]\n","Episode 34:Total timesteps 40: [1.6894517646168188, 3.6705603718311517, 3.66733205506838, 3.688888888888889, 3.688888888888889, 3.68889197321087, 4.688889453945886, 4.688888985834492, 3.7111111111111112, 2.7111111111111112, 2.7111111111111112, 2.7111111111111112, 2.7111111111111112, 2.688888888888889, 3.688888888888889, 3.688888888888889, 3.688888888888889, 3.6666666666666665, 2.688888888888889, 0.688888888888889, 0.688888888888889, 0.688888888888889, 0.688888888888889, 0.688888888888889, 0.688888888888889, 0.6888888888888892, 0.6888888888888892, 0.6888888888888892, 0.6888888888888892, -0.28888888888888886, -0.2666666666666666, 2.7333333333333334, 2.7333333333333334, 2.7333333333333334, 2.7333333333333334, 2.7333333333333334, 2.7333333333333334, 2.733333333333334, 2.733333333333334, 2.843881568716515]\n","Episode 35:Total timesteps 40: [1.733896209061263, 1.7150048162755964, 0.7333333333333334, 0.8439799288532551, 1.7522440534979173, 0.7365649695918747, 0.7338855821199575, 0.7334277061553093, 0.7333494605382952, 0.7333360892829189, 0.7333338042926929, 0.7333334138147469, 0.73333334708666, 0.733333335683615, 0.7333333337349689, 0.7333333334019682, 0.7333333333450622, 2.7333333333353376, -0.28888888888888886, 0.7111111111111111, 0.7333333333333334, 2.7333333333333334, 0.7333333333333334, 0.7333333333333334, 0.7333333333333334, 0.7333333333333334, 0.7333333333333334, 0.7333333333333337, -0.28888888888888886, -0.2666666666666666, 2.7333333333333334, 0.7333333333333334, -0.28888888888888886, 0.7111111111111111, 1.7111111111111112, 1.7111111111111112, 0.7333333333333334, 0.8438662762948183, 1.7522246228148322, -0.2875258772689925]\n","Episode 36:Total timesteps 11: [0.6894517646168187, 1.7811086072143332, -1.3137765521459528, 1.6700086904787477, 0.688888888888889, 1.7995193810434982, -1.071106612404947, -2.0724533309507542, -1.067451360284962, -2.0458038743674773, -1.9777777777777779]\n","Episode 37:Total timesteps 40: [1.733896209061263, 0.7353590351349295, 0.7339753925237171, 0.7334467993358448, 0.7333527620914707, 0.7333366538716616, 0.7333339007782236, 0.7333334303030288, 0.7333333499043139, 0.733333336165119, 0.7333333338172522, 0.7333333334160294, 0.7333333333474651, 0.7333333333357482, 0.733333333333746, 0.7333333333334039, 0.7333333333333454, 2.7333333333333356, 2.733333333333334, 2.733333333333334, 2.733333333333334, -0.28888888888888886, 0.7111111111111111, 0.7333333333333334, 0.7333333333333334, 0.7333333333333334, 0.7333333333333334, 0.8438815687010539, 1.752224726118901, 0.736561650096104, 0.7338850146857374, 0.7334276091857218, 0.7333494439673158, 0.7333360864511334, 0.7333338038087738, 0.7333334137320509, 0.7333333470725282, 0.7333333356812001, 2.7333333337345564, 2.7333333334018977]\n","Episode 38:Total timesteps 40: [4.842956990802505, 0.8654281738878211, 1.8666567746612808, 1.7561183557792606, 0.7372270376983794, 0.7339987217268216, 0.7334470403825595, 0.7333527645302537, 0.7333366538962719, 0.7333339007784718, 0.7333334303030313, 0.7333333499043139, 0.733333336165119, 0.7333333338172522, -0.28888888888888886, -1.2888888888888888, 2.7333333333333334, 0.7333333333333334, 0.7333333333333334, 0.7333333333333334, 0.843881568701056, 1.8627729615021176, 1.7554530428817712, 0.8476615668316901, 1.7528706833237928, 0.736672036582476, -0.28888888888888886, -0.2666666666666666, 0.7333333333333334, 0.7333359890589474, 0.7333338179592155, 0.8438816518515212, 1.7522247403278999, 0.8471098879074336, 1.8633246432695274, 1.86609555418825, 1.866569070263457, 1.7561017532064351, 0.7372241884106744, 0.7339982346886863]\n","Episode 39:Total timesteps 36: [1.8651792130247267, 1.9772071282442707, 1.9961062819559072, 1.8887863761995054, 1.8704466647818059, 1.7567643884882775, 0.7373374249841894, 0.7340175854868293, 0.7334502639758833, 0.7333533154044125, 0.7333367480341844, 0.7333339168655334, 0.7333334330521208, 0.7333333503741009, 2.7333333362454, 2.7333333338309713, 2.733333333418374, -0.28888888888888886, -1.2888888888888888, 2.688888888888889, -1.311111111111111, 1.688888888888889, -2.2888888888888888, 0.7111111111111111, 2.7333333333333334, 0.7333333333333334, 0.7333333333333334, -1.2666666666666666, 0.7333333333333334, 0.8438815687163524, -0.16093417686144973, -0.180199546376139, -1.1779044980730489, -1.1777972737402402, -2.157045015275275, 1.0444444444444445]\n","Episode 40:Total timesteps 40: [4.733896209061263, -0.2646409648650705, 0.7339753925237171, 0.7334467993358448, 0.7333527620914707, 0.7333366538716616, 0.7333339007782236, 0.7333334303030288, 0.7333333499043139, 2.733333336165119, 2.8438815692004336, 1.9733211969680586, 1.8848926710647516, 1.7592330409993622, 0.7377592886537142, 0.7340896770245674, 0.733462583571499, 0.7333554206783585, 0.7333371078007321, 0.7333339783454037, 0.7333334435583073, 3.7333333521694843, 2.7333333365522097, 2.7333333338834014, 2.7333333334273338, 2.733333333349397, 2.7111111111111112, -0.2666666666666666, 0.7333333333333334, 0.7333333333333334, -0.28888888888888886, 0.7111111111111111, 0.7333333333333334, 0.7333333333333334, 0.7333333333333334, 0.7333333333333334, 0.7333333333333334, 0.7333333333333334, 0.7333333333333334, 0.7333333333333337]\n","Episode 41:Total timesteps 40: [2.8429569908025045, 4.733879575608713, 0.7150046320282736, 0.7117764976082187, 0.7112248181411097, 0.7111305423078372, 0.7111144316740478, 0.7111116785562497, 0.711111208080809, 0.7111111276820915, -0.2666666666666666, 0.8438662736909245, 1.7522246228772445, 0.7365616490484213, 0.7338850146772892, 0.7334276091860246, 0.7333494439673852, 0.7333360864511455, 0.8438820391919574, 1.752224806517718, -0.28752868689371613, 2.7333333333333334, 2.7334090280006054, 0.7333492522938311, 0.7333360845238892, 0.8438820391811412, 1.7522248065179773, 0.7365616638353575, 0.7338850170336141, 0.7334276095869464, 0.7333494440358804, 0.7333360864628501, 0.7333338038107761, 0.7333334137323929, 0.7333333470725867, 0.7333333356812101, 2.733333333734558, 2.7333333334018977, 2.7333333333450502, 2.7333333333353353]\n","Episode 42:Total timesteps 14: [2.8207347685802824, 0.7116573533864904, -1.307217590193949, -2.2888888888888888, 3.711201764662428, 3.688888888888889, -1.2005745465365023, -2.0711227220293362, -1.0490034410798992, -1.1557717587076808, -1.1740172080277378, -2.200845175426274, 3.8000983411240012, 4.04742799489717]\n","Episode 43:Total timesteps 40: [-0.20000000000000007, 0.7999999999999999, -1.3105482353831812, 1.6705603718311517, 1.6673320550683801, 1.666780373715976, 1.6666860978635878, 1.7772182226127864, -1.314441373102528, 1.6698950803991361, 1.6672183645900511, 1.6667609453508407, 0.688888888888889, 1.688888888888889, 1.6888891232629173, 1.6888889669031997, 1.6888889026044143, 1.6888888912365831, 1.6888888892901215, -1.3111111110425449, 0.6888888889006061, 0.7994371242740725, -2.181671482941921, -1.288991401562614, 0.668578638397419, 4.667289305699061, 1.6667768122493714, 1.6666855279811754, 1.6666698902353119, 1.6666672175405766, 1.6666667608045764, 1.6666666827537284, 1.6666666694157564, 1.6666666671364538, 1.6666666667469476, 1.6666666666803858, 1.6666666666690109, 0.688888888888889, -0.311111111111111, -1.311111111111111]\n","Episode 44:Total timesteps 40: [1.6894517646168188, 1.6909145906904852, 1.6895309480792728, 3.7111111111111112, 2.7111111111111112, 0.7111141906342634, -0.311111111111111, 3.688888888888889, 0.688888888888889, 0.6888888893388989, 0.7111111111111111, 2.688888888888889, 0.688888888888889, 0.688888888888889, 0.7111111111111111, 0.8216440786881432, -2.13873205478829, 4.755436593455824, 0.7371131501053177, 0.7339792886652571, 0.8439919551904401, 1.862791825253912, 1.8660045018581934, 1.756005275108334, 0.7372077014388099, 0.7339954172591702, 0.7334464756865939, 0.7333526680303434, 0.7333366374055723, 0.7333338979604055, -0.28888888888888886, 2.7111111111111112, 1.7111111111111112, 0.7333333333333334, 2.7333333333333334, 0.7333333333333334, 0.7333333333333334, 0.7333333333333334, 0.7333333333333334, 0.7333333333333428]\n","Episode 45:Total timesteps 40: [4.756118431283485, 0.7372270384978186, 0.7339987217350469, 0.7334470403826429, 0.7333527645302543, 0.7333366538962719, 0.7333339007784718, 0.7333334303030313, 3.733333349904314, 2.733333336165119, 2.733333333817252, 2.7333333334160295, 2.733333333347465, 2.7333333333357483, 2.733333333333746, 2.733333333333404, 2.7333333333333454, 2.7333333333333356, 2.733333333333334, 2.733333333333334, 2.733333333333334, 2.733333333333334, 2.733333333333334, 2.733333333333334, 2.733333333333334, 2.733333333333334, 2.733333333333334, 2.733333333333334, 2.733333333333334, 2.7111111111111112, 0.7111111111111111, 3.7333333333333334, 2.7333333333333334, 0.7333333333333334, 0.7333333333333334, 0.7333333333333334, 0.7333333333333334, 0.7333333333333334, 0.7333333333333337, 2.733333333333334]\n","Episode 46:Total timesteps 40: [4.756118431283485, 2.8477752738809996, 5.863438349903895, 5.866114985314263, 5.866572390814278, 5.756102320649503, 3.7372242853800186, 3.733998251259606, 3.7334469599839255, 3.7333527507910595, 3.733336651548405, 3.733333900377249, 3.733333430234467, 3.733333349892597, 2.7333333361631165, 2.73333333381691, 2.733333333415971, 2.733333333347455, 2.7333333333357466, 2.7333333333337455, 2.7333333333334036, 2.7333333333333454, 2.8438815687165167, 5.7522247261190005, 3.736561650096105, 3.7338850146857374, 2.7111111111111112, 2.7111111111111112, 3.688888888888889, 0.688888888888889, 0.688888888888889, 0.6888889001935201, 0.6888888912121919, 0.7111111111111111, 2.688888888888889, 0.688888888888889, 0.7111111111111111, 3.7111111111111112, 0.7111111111111111, 2.7333333333333334]\n","Episode 47:Total timesteps 12: [1.6894517646168188, 4.670560371831152, 4.66733205506838, 3.7773286090991576, 2.9066739614156174, 2.928777560330073, 5.932554805327449, 2.8226520566736193, 0.8246038171987439, 0.8433421699239951, 3.8445443211181938, 4.044444444444444]\n","Episode 48:Total timesteps 40: [1.8651792130247267, 1.7561017978309348, 0.7372268542504958, 0.7339987198304411, 0.7334470403633319, 0.7333527645300594, 0.73333665389627, 0.7333339007784718, 0.7333334303030313, -0.28888888888888886, 0.7111111111111111, -0.311111111111111, 0.688888888888889, 0.688888888888889, 1.7111111111111112, 3.7111111111111112, 1.7111111111111112, 1.7111111111111112, 1.8216593464785524, -2.138711976445457, 1.7554367593603186, 0.7371131518705966, 0.7339792886834205, 0.7334437198009026, 0.733352197084926, 0.733336556926572, 0.7333338842074912, 0.7333334274712456, 0.7333333494203949, 0.7333333360824229, 0.7333333338031203, 0.7333333334136144, 0.8438815687302338, 1.8627729615045259, 1.8660012782653537, 1.8665529596174255, 1.756099000086576, -0.2868665083320172, 0.7117526031785766, 0.7112244801481031]\n","Episode 49:Total timesteps 5: [2.9549926798276256, 5.973884072613292, 5.866564153992883, 5.84822444255962, 4.022222222222222]\n","Episode 50:Total timesteps 40: [0.7116739868390409, 0.6686923684682627, 4.66730872585705, 4.666780132669178, 3.688888888888889, 3.688888888888889, 0.7111111111111111, 3.7111111111111112, 1.7111111111111112, 1.7111111115084223, 1.8216593469621207, -1.2699974960206295, 0.7143394278880134, 0.7116627924659301, 0.7112053869639122, -0.2666666666666666, 0.7333333333333334, 0.7333335676932323, 3.7333334113452294, 3.733333347048446, 2.7333333356809573, 2.733333333734554, 2.7333333334018977, 2.7333333333450502, 2.7333333333353353, 2.7111111111111112, 0.7111111111111111, 1.7111111111111112, 1.7111111111111112, 1.7111111111111112, 1.7111111111111112, 0.7333333333333334, -1.2666666666666666, 0.7333333333333334, 2.7333333333333334, 2.7333333333333334, 2.7333333333333334, 2.7333333333333334, 2.733333333333334, 2.7111111111111112]\n","Episode 51:Total timesteps 40: [3.977214902049848, 1.8855580594523338, 1.7593467480462572, -0.2863113845823322, -0.2666666666666666, 0.733444564043194, 0.7333553258075197, 0.733337122431665, 0.733333981157614, 0.7333334440420288, 0.7333333522521785, 0.7333333365663418, 2.7333333338858163, 2.7333333334277463, 2.8438815687326486, 1.7522247261217574, 0.7365616500965761, 0.7338850146858179, 0.7334276091857355, 0.7333494439673184, 0.7333360864511338, 0.7333338038087741, 0.7333334137320509, 3.733333347072528, 2.7333333356812, 2.7333333337345564, 2.7333333334018977, 2.7333333333450502, 2.7333333333353353, 2.7333333333336753, 2.843881568716573, 1.7522247261190103, 0.7365616500961066, -0.28888888888888886, -0.2666666666666666, 0.7333333333333334, 0.7333358949225234, 0.7333338018721703, 0.7333334137125108, 0.7333333470723312]\n","Episode 52:Total timesteps 40: [1.733896209061263, 2.7353590351349295, 3.733975392523717, 0.7334467993358448, 0.7333527620914707, 0.7333366538716616, 0.7333339007782236, 0.7333334303030288, 0.7333333499043139, 2.733333336165119, 2.733333333817252, 2.7333333334160295, 2.733333333347465, 2.7333333333357483, 2.733333333333746, 2.843881568716585, 1.752224726119012, 0.7365616500961069, 0.7338850146857377, 0.7334276091857218, 0.7333494439673158, 0.7333360864511334, 0.7333338038087738, 0.843881649115232, 1.8627729752413762, 1.86600128061282, 1.7560047246353987, 0.7372076073694617, 0.7339954011838251, 0.7334464729395066, 0.7333526675608986, 0.7333366373253499, 0.7333338979466962, 0.7333334298191141, 3.733333349821618, 2.7333333361509875, 2.733333333814837, 2.7333333334156165, 2.7333333333473946, 2.7333333333357364]\n","Episode 53:Total timesteps 40: [1.8651792130247267, 0.8432059516655989, 1.8444345524390586, 1.7338961335570384, 0.7150048154761571, 0.7117764995045993, 0.7112248181603373, 0.7111305423080313, 0.7111144316740498, 0.7111116785562497, 0.711111208080809, -0.2666666666666666, 0.7333333333333334, 0.7333333333333334, 0.7333333333333334, 0.7333333333333334, 0.7333333333355053, 0.7333333333337436, 0.7333333333334039, 0.7333333333333454, -0.28888888888888886, -1.2888888888888888, 0.7111111111111111, 0.7333333333333334, 0.7333333333333334, 0.7333333333333334, 0.7333333333333334, 0.7333333333333334, -0.28888888888888886, 0.7111111111111111, 1.7111111111111112, 0.7333333333333334, 0.7333333333333334, 0.7333333333333334, 0.7333333333333334, 0.7333333333333334, 0.843881568716356, 1.862772961502181, 1.866001278264953, 1.9771011950005386]\n","Episode 54:Total timesteps 6: [2.9105482353831813, 5.929439628168848, 5.9326679449316195, 5.933219626284024, 4.954301846810385, 2.1350202191818983]\n","Episode 55:Total timesteps 40: [1.733896209061263, 0.7150048162755963, 0.7117764995128245, 0.7112248181604207, -0.2666666666666666, 0.7333333333333334, 0.7333336646586606, 3.7333334279161647, 3.7333333498802315, 2.733333336164876, 2.73333333381725, 2.7333333334160295, 2.733333333347465, 2.7333333333357483, 2.7111111111111112, -0.2666666666666666, 2.7333333333333334, 2.7333333333333334, 2.7333333333333334, 2.7111111111111112, 0.7111111111111111, -1.2888888888888888, 0.7111111111111111, 0.7111111111111111, -0.2666666666666666, 0.7333333333333334, 0.7333333333333334, 2.7333333333333334, 2.7333333333333334, 2.7333333333333334, 2.7333333333333334, 2.733333333333334, 2.733333333333334, 2.7111111111111112, -0.2666666666666666, 2.7333333333333334, 2.7333333333333334, 2.7333333333333334, 2.7333333333333334, 2.7333333333333334]\n","Episode 56:Total timesteps 40: [0.7999999999999999, 0.7999999999999999, -1.3105482353831812, 0.6909145906904851, 1.6895309480792728, 1.6890023548914002, 1.7994565538709186, -1.292216397772795, 1.6921177730966939, 1.6894406672109898, 1.688983181312258, 1.688905002354657, 0.6666666666666666, 3.6666666666666665, 1.6666666666666665, 0.688888888888889, -1.311111111111111, -1.311111111111111, -1.311111111111111, -1.311111111111111, -1.311111111109351, -1.3111111111107712, -1.3111111111110527, -1.3111111111111011, -2.2888888888888888, -3.311111111111111, -0.33333333333333337, 1.6666666666666665, 1.7772147181376514, -1.2038937059355552, -1.311213623789759, 1.6704466647817924, 1.6673126238714588, 0.688888888888889, -1.311111111111111, -1.200559807174836, -3.160935599370644, -1.2667853847848072, 1.714890945564591, 0.7333333333333334]\n","Episode 57:Total timesteps 40: [1.8207347685802824, -2.1573157039081714, 1.8444313540607657, 1.8444443791902554, 1.8444444441535568, 1.7338962090593526, 0.7150048162755764, 0.7117764995128244, -0.311111111111111, 1.7994412511595415, -1.1816682297790195, -1.0678943635296396, -1.0484517596887053, -1.0451292474720986, -2.1551097046080883, -1.2844523061546145, 1.693444565005147, 1.6896674003379246, 1.689021927336051, 0.6666666666666666, 3.6666666666666665, 1.6666670944594069, 1.7772150139415226, -1.31444192116951, 1.6698949867425545, 1.6672183485852599, 1.6667609426158103, 1.6666827773171837, 1.6666694197872922, 1.66666713714259, 1.6666667470654666, 1.6666666804058758, 1.666666669014536, 0.688888888888889, -1.311111111111111, 1.688888888888889, 0.7111111111111111, 0.7111111111111111, 0.7111111111111111, 0.7111111111111111]\n","Episode 58:Total timesteps 40: [0.6894517646168187, 0.6909145906904851, 4.689530948079272, 4.6890023548914, 4.6889083176470265, 3.7111111111111112, 2.8216446150483883, 1.84055076889211, 1.7332308367989544, -0.26475487496355476, 0.7339559708033089, -0.28888888888888886, 2.7111111111111112, -0.2666666666666666, 0.7333333333333334, 0.7333333333333334, 0.7333333470807276, 0.7333333360588185, 0.7333333338028827, 0.733333333413612, 0.8438815687302338, 1.8627729615045259, 1.7554530428821726, 0.7371133314485775, 0.7339792905381376, 0.7334437198197065, 0.7333521970851162, 0.7333365569265738, 0.7333338842074913, 0.7333334274712456, 3.733333349420395, 2.733333336082423, 2.7333333338031203, 2.7333333334136145, 2.733333333347052, 2.7333333333356777, 2.733333333333734, 2.733333333333402, 2.733333333333345, 2.733333333333335]\n","Episode 59:Total timesteps 40: [-0.20000000000000007, 0.7999999999999999, -1.3105482353831812, 1.6705603718311517, 1.6673320550683801, 2.7773286090991576, 0.8168630158579259, -1.289004366126985, 3.7129867436321997, 3.7117334328862244, 3.7112212690317294, 3.7111299752146283, 2.7333333333333334, 2.7333333333333334, 0.7333333333333334, -0.28888888888888886, 3.7111111111111112, 3.7111111111111112, 3.7333333333333334, 0.7333333333333334, 0.7333333333333334, 0.7333333333333334, -0.28888888888888886, 3.7111111111111112, 0.7111111111111111, 3.688888888888889, 0.688888888888889, 0.6666666666666666, 3.6666666666666665, 1.6666666666666665, -3.311111111111111, -3.2888888888888888, 2.7333333333333334, 2.7333333333333334, 0.8438813780731399, 1.7522247248868683, 0.736561650083522, 0.7338850146856087, 0.7334276091857205, 0.7333494439673158]\n","Episode 60:Total timesteps 40: [0.7116739868390409, 1.6927825940533743, 1.8001025126737837, -1.2921060112761347, 1.802684872231763, -2.2048240218307744, -1.3111351142636716, 1.670462692139235, 1.6673153916983967, 0.688888888888889, 1.688888888888889, -0.28888888888888886, 2.7333333333333334, 2.7333333333333334, 2.7333333333333334, 2.7333333333333334, 2.7333333337759806, 2.7111111111111112, 2.7111111111111112, 2.7111111111111112, 3.7111111111111112, 3.7111111111111112, 3.7333333333333334, 2.7333333333333334, 2.7111111111111112, 2.7111111111111112, 3.7111111111111112, 3.688888888888889, 0.688888888888889, -2.3333333333333335, -1.3333333333333335, -1.3333333333333335, -0.33333333333333337, -2.311111111111111, -1.311111111111111, -0.311111111111111, -1.311111111111111, -1.311111111111111, -1.311111111111111, -1.311111111111111]\n","Episode 61:Total timesteps 17: [3.8666666666666667, 5.756118431283485, 4.737227038497819, 3.733998721735047, 3.733447040382643, 3.733352764530254, 3.733336653896272, 3.733333900778472, 3.7333334303030314, 3.733333349904314, 2.733333336165119, 2.733333333817252, 2.8438815687992105, 5.862772961516313, 5.755453042884187, 4.7371133314489215, 3.0666666666666664]\n","Episode 62:Total timesteps 35: [4.756118431283485, 3.7372270384978186, 3.733998721735047, 3.733447040382643, 1.7111111111111112, 2.688888888888889, 2.7111111111111112, 3.688888888888889, 3.688888888888889, 3.6666666666666665, 3.6666666666666665, 1.6666666666666665, -1.3333333333333335, 1.6666666666666665, 1.6666666666668322, 1.666666666666735, 1.6666666666666785, 1.7772149020498502, -1.203893705164485, -1.2006653884017133, -1.3106619424324908, 1.7810891760174123, -1.3137798727088916, 1.7805563584167907, -1.3138709249680391, 1.6699925632737846, 1.667235023266406, 1.6667637921226341, 1.6666832642643743, 1.666669503000838, 1.6666671513628062, 1.6666667494955343, 1.6666666808211459, -0.311111111111111, -0.9555555555555556]\n","Episode 63:Total timesteps 5: [4.756118431283485, 3.7372270384978186, 3.733998721735047, 2.8439952757658244, 5.066666666666666]\n","Episode 64:Total timesteps 7: [5.866666666666667, 5.866666666666667, 5.866666666666667, 5.866666666666667, 4.842956990802505, 3.844433010432835, 3.0666666666666664]\n","Episode 65:Total timesteps 40: [3.8666666666666667, 5.756118431283485, 3.7372270384978186, 1.7111111111111112, 3.688888888888889, 0.688888888888889, 0.6888919238029637, 1.6888894534470098, 4.6888889858294585, 4.688888905459575, 3.6888888917206715, 3.688888889372808, 3.6888888889715847, 3.6888888889030205, 3.6666666666666665, 0.6666666666666666, 3.6666666666666665, 3.6666666666666665, 3.6666666666666665, 3.6666666666666665, 3.6666666666666665, 3.666666666666667, 3.666666666666667, 3.666666666666667, 3.666666666666667, 3.666666666666667, 3.666666666666667, 3.666666666666667, 3.666666666666667, 3.666666666666667, 3.666666666666667, 3.666666666666667, 3.666666666666667, 3.666666666666667, 3.666666666666667, 3.666666666666667, 3.666666666666667, 3.666666666666667, 3.666666666666667, 3.666666666666667]\n","Episode 66:Total timesteps 3: [5.866666666666667, 5.866666666666667, 4.044444444444444]\n","Episode 67:Total timesteps 40: [1.7999999999999998, 1.8207347685802824, 0.8222107882106128, -1.2883260997124828, 1.6927825931379705, 1.689554277281185, 0.7111111111111111, 2.7111111111111112, 2.711114195430091, 2.7333333333333334, 2.7333333333333334, 0.7333333333333334, 0.7333333337737153, 0.8438815691846274, 1.8627729615848114, 1.755453042895903, 0.7371133314509238, 0.7339792905385384, 0.7334437198197749, 0.7333521970851281, 0.733336556926576, 0.7333338842074917, -0.28888888888888886, -0.2666666666666666, 2.7333333333333334, 0.7333333333333334, 0.8438815675282273, 1.8627729615106063, 1.755453042884083, 0.7371133314489092, 0.7339792905381944, 0.733443719819716, -0.28888888888888886, 0.7111111111111111, 2.7111114258661875, 3.7111112028621647, 2.7333333333333334, 2.7333333333333334, -1.2666666666666666, 0.7333333333333334]\n","Episode 68:Total timesteps 40: [4.756118431283485, 0.7372270384978186, 0.7339987217350469, 0.8439952757658243, 1.8627923926991028, 1.8660045988278915, 1.8665535270624956, 1.7560990970562624, 0.7372237345058607, 0.733998157121694, 0.7334469438968637, 0.73335274804197, -0.28888888888888886, -0.2666666666666666, 0.7333333333333334, 0.7333333333333334, 0.8438815702773272, 1.8627729619803959, 1.7554530429643642, 0.8476615668458098, 1.9739671540925685, -0.027901883798737148, -0.04661807291980302, -1.1551323995149878, -1.2844545898163013, 1.693444187707859, 1.689667336003069, 0.7111111111111111, 2.7111111111111112, 0.711114759620935, 0.7111117725846786, -0.311111111111111, 0.7111111111111111, 2.7111111111111112, -0.311111111111111, 1.688888888888889, -1.311111111111111, 0.7111111111111111, 0.7111111111111111, -0.2666666666666666]\n","Episode 69:Total timesteps 2: [1.8207347685802824, 1.1606422799125191]\n","Episode 70:Total timesteps 3: [1.733896209061263, 4.7353590351349295, 4.066666666666666]\n","Episode 71:Total timesteps 19: [2.733896209061263, 3.690914590690485, 3.8000869196709544, -0.20528540479020496, 0.799342757627401, -1.2001104426352418, -1.2000188640017617, -1.310551458978063, 1.670559820956977, 1.6673319609304675, 1.6667803576289146, 1.6666860951144984, 1.666669986759818, 1.7772154694147053, -1.203893608208506, -1.2006653718330775, 1.6893380603988941, 0.670540941118081, 0.1112103033046407]\n","Episode 72:Total timesteps 12: [4.733896209061263, 3.7150048162755964, 3.7117764995128244, 2.7333333333333334, 2.7333333333333334, 0.7333364176553144, 0.7333338983903303, 0.7333334302789357, 0.7333333499040707, 0.7333333361651165, 0.8438815692004334, 0.04444444444444443]\n","Episode 73:Total timesteps 40: [1.8429569908025045, 0.844433010432835, 1.7338961225097393, 0.7150048153601926, 0.7117764995034072, -0.2666666666666666, 2.7333333333333334, 0.7333364176523133, 0.7333338983902999, 0.7333334302789355, 0.7333333499040707, 0.7333333361651165, 0.7333333338172522, 2.7333333334160295, 2.733333333347465, 2.7333333333357483, 2.8438815687169274, 1.7522247261190707, 0.736561650096117, 0.7338850146857393, 0.7334276091857221, 0.7333494439673159, 0.7333360864511334, 0.7333338038087738, 0.7333334137320509, 3.733333347072528, 2.7333333356812, 2.7333333337345564, 2.7333333334018977, 2.7333333333450502, 2.7333333333353353, 2.7333333333336753, 2.7333333333333916, 2.733333333333343, 2.733333333333335, 2.733333333333334, 2.733333333333334, 2.733333333333334, 2.733333333333334, 2.733333333333334]\n","Episode 74:Total timesteps 40: [0.6894517646168187, 4.670560371831152, 4.66733205506838, 3.7773286090991576, 2.6855774906492544, 4.669898303992377, 2.688888888888889, 3.7111111111111112, 3.7111111111111112, 3.711113581455572, 3.7333333333333334, 2.7333333333333334, 0.7333333333333334, 0.7333333333333334, 0.7333333337108358, 0.7333333334017246, 0.7333333333450597, 0.7333333333353377, 2.733333333333676, 2.733333333333392, 2.733333333333343, 2.733333333333335, 2.733333333333334, 2.733333333333334, 2.733333333333334, 2.733333333333334, 2.733333333333334, 2.733333333333334, 2.843881568716515, 1.8627729615021815, 1.7554530428817716, 0.7371133314485091, 0.7339792905381258, 0.7334437198197045, 0.7333521970851159, 0.8438847923097552, 1.7522252769931583, 0.7365617442340172, 0.7338850307727992, 0.7334276119348114]\n","Episode 75:Total timesteps 40: [1.8207347685802824, -1.1777892117893871, -1.1777778352366215, -2.2014862153423285, 1.6894351416460536, 1.6705601876959615, 1.6673320531649294, 1.6667803736966769, 1.6666860978633928, 0.688888888888889, 1.688888888888889, 1.7994370662947956, -1.2922197027564475, 1.692117208473213, 1.689440570725107, 1.6889831648239726, 0.7111111111111111, 2.7111111111111112, 2.7111113454713895, 3.711111189123077, 3.7111111248262363, 2.711111113458737, 2.7111111115123316, 2.7111111111796755, 2.7333333333333334, -0.28888888888888886, 2.7111111111111112, 2.7111111111111112, 2.7333333333333334, 0.7333333333333334, 2.7333333333333334, 2.7111111111111112, -0.2666666666666666, 0.7333333333333334, 2.7333333333333334, 2.7333333333333334, 2.7333333333333334, 2.7111111111111112, 2.7111111111111112, 2.7111111111111112]\n","Episode 76:Total timesteps 40: [1.733896209061263, 1.7150048162755964, 0.7333333333333334, 0.7334240287069015, 0.8439008443924991, 1.7522280456759267, 0.7365622175309685, 0.7338851116553302, 0.7334276257567013, 0.7333494467991014, 0.733336086935052, 0.7333338038914698, 0.7333334137461825, 0.733333347074943, 0.7333333356816126, 0.7333333337346266, 0.7333333334019096, 2.7333333333450525, 2.7333333333353362, -0.28888888888888886, 0.7111111111111111, 1.7111111111111112, 1.7111111111111112, 1.8216593464785182, -1.2699974961033234, 1.7143394278738815, 1.7116627924635153, 1.7112053869634996, 1.8216754571282752, -2.1387092055506924, 1.7554372297475322, 0.7371132322677111, 0.7339793024225977, 0.7334437221487691, 0.7333521974861488, 0.7333365569951362, 0.7333338842192082, 0.7333334274732479, 0.7333333494207371, 0.7333333360824814]\n","Episode 77:Total timesteps 32: [3.8666666666666667, 1.7561184312834852, 0.7372270384978186, -0.28888888888888886, 0.7112018064846793, 0.711130305359433, 0.8216626654876173, 0.861288808105049, 1.755436858061914, 0.7371131684598463, 0.7339792915153939, 0.7334437202848232, 0.7333521971676221, 0.7333365569407038, 0.7333338842099062, 0.7333334274716584, 0.7333333494204655, 0.7333333360824349, 0.7333333338031225, 0.7333333334136148, -0.28888888888888886, -2.2666666666666666, 0.7333333333333334, 0.7333333333333334, 0.843881567447958, 1.9733211968820292, 1.8848926710506149, 0.8460700103557607, 3.9555169926448963, 1.863426770852913, 1.7371400688817547, -0.9777777777777777]\n","Episode 78:Total timesteps 3: [2.8207347685802824, 1.7987615072211542, 2.2438748191473166]\n","Episode 79:Total timesteps 40: [0.7999999999999999, 0.7999999999999999, 1.6894517646168188, 4.670560371831152, 4.66733205506838, 4.6667803737159765, 4.666686097863588, 4.666669987229605, 4.666667234111805, 4.666666763636364, 4.666666683237647, 3.6666666694984524, 3.6666666671505856, 3.6666666667493626, 3.6666666666807983, 3.6666666666690815, 3.6666666666670795, 3.666666666666737, 3.6666666666666785, 3.6666666666666687, 3.688888888888889, 0.688888888888889, 0.688888888888889, 0.688888888888889, 0.688888888888889, 0.688888888888889, 0.688888888888889, 0.6888888888888892, 0.6888888888888892, 0.6888888888888892, 0.7111111111111111, 1.7111111111111112, 3.7111111111111112, 3.688888888888889, 0.688888888888889, 0.688888888888889, 0.688888888888889, 0.6666666666666666, 2.688888888888889, 0.688888888888889]\n","Episode 80:Total timesteps 40: [0.9549926798276257, 1.8633358372301116, 4.737124525824035, 3.7155564976280004, 2.8224190107483946, 2.8614177661748585, 4.755458932028937, 0.7371169427538312, 0.7339799365256194, 0.7334438305097782, 0.7333522160037731, 0.7333365601595804, -1.2888888888888888, -1.311111111111111, 3.688888888888889, 0.6666666666666666, 3.6666666666666665, 1.6666666666666665, -1.3333333333333335, 1.6666666666666665, 1.6666666666668193, 1.6666666666667327, 1.7772149020498595, -1.3144419405476646, 1.6698949834294385, 1.6672183480190705, 1.6667609425190553, 1.666682777300649, 1.6666694197844665, 1.6666671371421073, 1.6666667470653844, 1.6666666804058616, 3.6666666690145333, 3.6666666670678896, 3.666666666735231, 1.7772149020615648, -1.3144419405456644, 1.6698949834297805, 1.6672183480191292, 0.688888888888889]\n","Episode 81:Total timesteps 40: [4.733896209061263, 0.7150048162755963, 2.688888888888889, 3.688979584262457, 4.6889080831372105, 3.7111111111111112, 3.7111111111111112, -0.2666666666666666, 2.7333333333333334, 0.7333333333333334, 0.7333333333333334, 0.7333333333914666, 0.7333333333472173, 0.7333333333357458, 0.733333333333746, 2.733333333333404, 2.7333333333333454, 2.7333333333333356, 2.733333333333334, 2.733333333333334, 2.733333333333334, 2.733333333333334, 2.733333333333334, 2.733333333333334, 2.733333333333334, 2.733333333333334, 2.733333333333334, 2.843881568716515, 1.8627729615021815, 1.7554530428817716, 0.7371133314485091, 0.7339792905381258, 0.7334437198197045, -0.28888888888888886, 2.7333333333333334, 2.7333333333333334, 0.7333333333333334, 0.7333333474842552, 0.7333333360628874, 0.7333333338029232]\n","Episode 82:Total timesteps 19: [4.756118431283485, 3.7372270384978186, 2.844546957118228, 5.75233843316831, 4.736581081293026, 3.733888335248676, 3.7334281766308606, 3.733349540937014, 3.733336103022114, 1.7111111111111112, 1.688888888888889, 3.688888888888889, 3.688888888888889, 3.7111111111111112, 2.7111111111111112, 2.7111111111111112, 2.7111111111111112, 2.7111111111111112, 2.022222222222222]\n","Episode 83:Total timesteps 13: [2.8651792130247267, 3.866655232655057, 1.9772148647120442, 1.9961062947923174, 1.8887863762150778, 1.7598984293986608, 0.737872995702611, 0.7341091082214178, 0.7334659041344254, 0.7333559881234949, 0.73333720477043, 0.7333339949163843, -0.9555555555555556]\n","Episode 84:Total timesteps 40: [0.8429569908025046, -2.1790162705566236, -1.1777876697831635, -1.1777778279439381, -2.1777777780026244, -3.201487529695173, -2.1790162661091204, -1.0672362919471339, -2.0273548801277275, -1.1334446459730319, -1.2623238656759028, -0.3084368748514731, -3.3333333333333335, 1.6667713047243025, 4.666689034349611, 4.6666705352015745, 3.688888888888889, -1.311111111111111, -1.311111111111111, -1.3111111101956205, -1.3111111105709856, -1.311111111014939, -1.3111111110946374, -1.2005628757251143, -2.292219718324963, -2.331973145076983, -1.3328049164465114, 1.6667607023110733, 0.688888888888889, -1.311111111111111, -2.2888888888888888, 1.7111111111111112, 1.7111111111111112, 1.7111111111111112, 1.8216593468794247, -2.1387119765947284, 4.755436759370244, 0.7371131518725796, 0.7339792886837625, 0.7334437198009609]\n","Episode 85:Total timesteps 40: [0.8444444444444444, -2.1348207869752733, 1.7561017978309348, -0.2868261873039434, 0.7117535863033629, 0.7112245813658112, 0.7111305399122204, 0.7111144316498729, 0.7111116785560058, 0.7111112080808066, 0.7111111276820915, 2.7333333333333334, -2.2888888888888888, 2.7111111111111112, -0.311111111111111, 0.688888888888889, 3.688888888888889, -0.28888888888888886, 2.7333333333333334, 0.7333333333333334, 0.7333333333333334, 0.7333333333333334, 0.7333333333333334, 0.7333333333333334, 0.7333333333333334, 0.7333333333333337, 0.7333333333333337, 0.7333333333333337, 0.7333333333333337, -0.28888888888888886, -1.2888888888888888, 1.7111111111111112, 0.7333333333333334, 0.7333333333333334, 0.7333333333333334, 0.7333333333333334, 0.7333333333333334, 0.7333333333333334, 0.7333333333333334, 0.7333333333333337]\n","Episode 86:Total timesteps 6: [4.756118431283485, 0.7372270384978186, -0.28888888888888886, 3.7112018064846795, 1.821678622170277, -1.9555555555555555]\n","Episode 87:Total timesteps 40: [1.8429569908025045, 1.7338795756087126, 1.7150046320282737, 1.7117764976082186, 0.7333333333333334, 2.7333333333333334, 2.7333364176126205, 0.7333338983898993, 3.7333334302789316, 3.7333333499040706, 2.7333333361651166, 2.733333333817252, 2.7333333334160295, 2.733333333347465, 2.7333333333357483, 2.7111111111111112, -0.2666666666666666, 2.7333333333333334, 2.7333333333333334, 2.7333333333333334, 2.7333333333333334, 2.7111111111111112, 3.7111111111111112, 3.7111111111111112, 0.7333333333333334, 2.7333333333333334, 2.7333333333333334, -0.28888888888888886, 0.7111111111111111, 3.7333333333333334, 2.7333333333333334, 2.7333333333333334, 2.7333333333333334, 2.7333333333333334, 2.7333333333333334, 2.7333333333333334, 2.733333333333334, 2.733333333333334, 2.733333333333334, 2.733333333333334]\n","Episode 88:Total timesteps 40: [0.6894517646168187, 1.6705603718311517, 1.6673320550683801, 0.688888888888889, -2.3333333333333335, 3.6666666666666665, 1.6666670426176902, 1.6666667617001423, 1.6666666832181107, 1.6666666694982553, 1.6666666671505834, 1.6666666667493626, 1.6666666666807983, 1.6666666666690815, 1.6666666666670795, 1.6666666666667371, 1.6666666666666785, 1.6666666666666687, 1.666666666666667, 0.688888888888889, -0.311111111111111, 0.688888888888889, 0.688888888888889, -0.28888888888888886, 2.7333333333333334, 1.7111111111111112, 3.7111111111111112, 3.7111111111111112, 3.7111111111111112, 3.7111111111111112, 3.7111111111111112, 3.7111111111111112, 3.7333333333333334, -0.28888888888888886, 3.7333333333333334, 2.7333333333333334, 2.7333333333333334, 2.7333333333333334, 2.7333333333333334, 2.7333333333333334]\n","Episode 89:Total timesteps 17: [1.8429569908025045, 0.844433010432835, 3.865160634442419, 1.86665512536876, 1.7561183439788275, 0.7372270375745318, 0.7339987217255485, 0.7334470403825466, 0.7333527645302534, 0.7333366538962719, -0.28888888888888886, 1.7333333333333334, 0.7333333333333334, 0.8438814458539886, 1.8627729614585005, 1.866001278345483, 1.0666666666666667]\n","Episode 90:Total timesteps 40: [3.8666666666666667, 5.756118431283485, 4.737227038497819, 2.844546957118228, 4.839179445051016, 4.733233958153842, 0.7148942500756316, 0.7117576339048876, 0.8217698299380268, 1.8405696196026708, -2.1799270074836237, -1.177902322014273, -2.157043929488462, 4.733876431474275, 0.7150040690587591, -0.311111111111111, 1.6889796093699485, 1.6889080807427228, 1.6888922065789407, 1.6888894562276042, 1.6888889858442804, 0.6666666666666666, 1.6666666666666665, 1.6666666666666665, 1.7772149005688362, -1.3144419405436012, 1.66989498343175, 1.6672183480194822, 1.6667609425191254, 1.6666827773006614, 1.6666694197844687, 1.6666671371421073, 1.6666667470653844, 1.6666666804058616, 1.7772149043977148, -1.0933454693800813, -1.1817739955474824, -1.1968853902748209, 1.689984014774304, 0.670651327120944]\n","Episode 91:Total timesteps 40: [4.756118431283485, 0.7372270384978186, 0.7339987217350469, 0.7334470403826429, -0.28888888888888886, 0.8216473700434513, 1.7300029680030402, -0.26530355757680946, -0.28888888888888886, 2.711186805403874, -0.2666666666666666, 0.7333333333333334, 0.7333335719441294, 0.7333334113904212, 0.7333333470492903, 0.733333335681032, 0.7333333337345658, 0.7333333334018998, 2.7333333333450507, 2.7333333333353353, 2.7333333333336753, 2.7111111111111112, -1.2888888888888888, 1.7111111111111112, 1.7111111111111112, 1.7111111111111112, 1.8216593464941333, -1.159449260720041, -1.2667691793404505, 0.7148911092262868, 0.7117570683159037, 0.7112214975974823, -0.2666666666666666, -0.28888888888888886, 2.7333333333333334, 2.7333333333333334, -0.28888888888888886, 1.7333333333333334, 2.7333333333333334, 0.7333333333333334]\n","Episode 92:Total timesteps 40: [0.8444444444444444, -1.266103790938737, -0.3090854093095149, 4.689530948079272, 4.6890023548914, 4.6889083176470265, 4.688892209427217, 4.688889456333779, 4.6888889858585845, 1.6888889054598692, 1.6888888917206746, 1.6888888893728078, 1.6888888889715847, -0.28888888888888886, -0.2666666666666666, 2.7333333333333334, 0.7333333333333334, 0.7333333333333334, 0.7333333333333334, 0.7333333333333334, 0.7333333333333334, 0.7333333333333337, 0.7333333333333337, 0.7333333333333337, 0.7333333333333337, 0.7333333333333337, -0.28888888888888886, 0.8216440509850059, -1.2699975994276715, 1.7143394268120673, 1.711662792452652, 1.7112053869633894, 1.7111272217450924, 1.7111138642289112, 0.7333333333333334, 2.843866353569727, 1.8627729078985995, 1.7554530447981578, 0.7371133318452824, 0.7339792906066442]\n","Episode 93:Total timesteps 21: [-0.06722954239459644, -3.0273473293206887, -1.1334446239429257, -1.1517756064398026, 1.7345421659159839, 0.7151152027582853, 0.7117953632645692, 0.7112280417536607, 0.7111310931821903, 0.7111145258119621, 0.7111116946433113, -0.311111111111111, 1.688888888888889, 1.688888888888889, 1.799437123206015, -1.2922197182504682, 0.7124713271630059, 0.711639528310373, 0.7112051467591044, 0.7111272193152617, -0.9333333333333333]\n","Episode 94:Total timesteps 3: [5.977214902049848, 5.885558059452333, 5.2086608709631355]\n","Episode 95:Total timesteps 40: [0.7116739868390409, -1.3072174059466257, -1.3104457227093977, -1.3109974040618018, -1.31109167991419, -1.3111077905481725, -2.2888888888888888, 3.7111111111111112, 3.7333333333333334, 2.7333333333333334, 2.7333333333333334, 0.7333333333333334, 2.7111111111111112, 2.7111111111111112, 0.7111111111111111, 3.7111111111111112, 3.7111111111111112, 3.7333333333333334, 2.7333333333333334, 2.7333333333333334, 2.7333333333333334, 2.7333333333333334, 2.7333333333333334, 2.7333333333333334, 2.733333333333334, 2.733333333333334, 2.733333333333334, 2.7111111111111112, -0.2666666666666666, 2.7333333333333334, 2.7333333333333334, 2.7333333333333334, 2.7333333333333334, 2.7333333333333334, 2.7111111111111112, 0.7111111111111111, 3.7111111111111112, 3.7111111111111112, 2.7111111111111112, 2.7333333333333334]\n","Episode 96:Total timesteps 19: [3.8666666666666667, 1.7561184312834852, 0.7372270384978186, 3.733998721735047, 2.7111111111111112, 3.7111111111111112, 3.711114195433092, 4.711111676168108, 4.711111208056714, 3.688888888888889, 4.711111111111111, 3.7111111111111112, 3.7111111111111112, 3.7111111111111112, 3.7111111111111112, 3.7111111111113266, 3.7333333333333334, 2.7333333333333334, 0.06666666666666665]\n","Episode 97:Total timesteps 40: [-0.1777777777777777, -1.288326013160959, 0.6686923684682627, 3.777864697448732, -1.2037800674062158, -2.17990949403908, -1.2884529645978948, 0.668710412093933, 3.77786175005665, -1.3143288887354352, 1.6699143194142536, 1.667221652483955, 1.6667615072149928, 1.6666828738005588, 0.688888888888889, 1.688888888888889, 1.688888888888889, 1.6888889003237386, 1.6888888912267386, 0.7111111111111111, 2.7111111111111112, 2.7111111111111112, 2.7333333333333334, 2.7333333333333334, 2.7333333333333334, 2.7333333333333334, 2.7333333333333334, 2.7333333333333334, 2.7333333333333334, 2.733333333333334, 2.733333333333334, 2.733333333333334, 2.733333333333334, 2.733333333333334, 2.733333333333334, 2.7111111111111112, -0.2666666666666666, 2.7333333333333334, 2.7333333333333334, 2.7333333333333334]\n","Episode 98:Total timesteps 40: [0.6894517646168187, -1.3294396281688483, 1.6673320550683801, 1.666780373715976, 1.6666860978635878, 1.6666699872296054, 1.6666672341118054, 1.6666667636363646, 1.666666683237647, 3.6666666694984524, 3.6666666671505856, 3.6666666667493626, 3.6666666666807983, 3.6666666666690815, 3.6666666666670795, 3.666666666666737, 3.6666666666666785, 1.7772149020498502, 2.685558059452334, 4.6698949834294385, 1.6672183480190705, 1.6667609425190553, 1.666682777300649, 1.6666694197844665, 0.688888888888889, 3.799421909125071, -1.2922198079110485, 1.692117206937708, 0.7111111111111111, 1.711182383545045, 1.7111269849217758, 1.7111138618365316, 1.7111115815627351, 1.711111191509643, 1.8216593602334958, -1.1594492583721725, -1.156220943556046, -1.0451210271531193, -1.0261353585719117, 1.9771090688151278]\n","Episode 99:Total timesteps 40: [4.756118431283485, 0.7372270384978186, 0.7339987217350469, 3.733447040382643, 3.733352764530254, 3.733336653896272, 3.733333900778472, 3.7333334303030314, 3.733333349904314, 2.733333336165119, 2.733333333817252, 2.7333333334160295, 2.733333333347465, 2.7333333333357483, 2.733333333333746, 2.733333333333404, 2.7333333333333454, 2.7333333333333356, 2.733333333333334, 2.733333333333334, 2.733333333333334, 2.733333333333334, 2.843881568716515, 1.7522247261190005, 0.736561650096105, 0.7338850146857374, 3.7334276091857217, 2.7111111111111112, 2.7111111111111112, 2.7111113454710085, 3.711111189123007, 3.711111124826224, 2.711111113458735, 2.7111111115123316, 2.7111111111796755, 2.711111111122828, 2.7333333333333334, 0.7333333333333334, 0.7333333333333334, 0.7333333333333334]\n"]}]},{"cell_type":"code","source":["# To access the reward for a specific step:\n","# for i, feedback in enumerate(recalibrated_rewards_list):\n","#    human_recalibrated_reward_for_step = recalibrated_rewards_list[i]\n","#    print(f\"Recalibrated reward for step {i}: {human_recalibrated_reward_for_step}\")"],"metadata":{"id":"9ghTAsxHrRBv"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["SECTION A.5: MODEL TRAINING(HUMAN FEEDBACK DIRECT- IDEAL CASE SCENARIO)\n","*   Step A.5.1: CUSTOM REWARD FUNCTION\n","*   Step A.5.2: LOAD THE SAVED INITIALLY TRAINED PPO MODEL FROM GOOGLE DRIVE\n","*   Step A.5.3: TRAIN/UPDATE PPO MODEL WITH RECALIBRATED REWARD\n","*   Step A.5.4: SAVE THE TRAINED MODEL(HF_IDEAL) FOR TESTING"],"metadata":{"id":"XBMjLEJEo-Ah"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"7q52Lb46CuhD"},"outputs":[],"source":["# Step A.5.1: CUSTOM REWARD FUNCTION\n","def custom_reward(self, env, state, action, next_state, reward, done):\n","    # Access and recalculate the reward using human_feedback_data or recalibrate_rewards_human function\n","    global step_counter\n","    try:\n","        step_counter\n","    except NameError:\n","        step_counter = 0\n","\n","    reward = recalibrated_rewards_list[step_counter]\n","    step_counter += 1\n","    return reward\n","\n","# Create a new environment class that wraps your original environment and overrides the default reward function with your custom function\n","class CustomRewardWrapper(gym.Wrapper):\n","    def __init__(self, env):\n","        super(CustomRewardWrapper, self).__init__(env)\n","\n","    def step(self, action):\n","        next_state, reward, terminated, truncated, info = self.env.step(action)\n","        done = terminated or truncated\n","        reward = custom_reward(self, self.env, self.last_obs, action, next_state, reward, done)\n","        # custom_reward should be defined and accessible to your class\n","        self.last_obs = next_state\n","        return next_state, reward, terminated, truncated, info\n","\n","    def reset(self, **kwargs):\n","        global step_counter\n","        step_counter = 0\n","        self.last_obs = self.env.reset(**kwargs)[0]  # Assuming Gymnasium env returns (obs, info)\n","        return self.last_obs, {}  # Assuming Gymnasium env requires (obs, info)\n","# Create and wrap the environment with your custom reward wrapper\n","# env_human = CustomRewardWrapper(gym.make('highway-v0'))"]},{"cell_type":"markdown","source":["PPO training and Training logs"],"metadata":{"id":"aUlSLNAygDX7"}},{"cell_type":"code","source":["drive_log_dir = \"/content/drive/MyDrive/05_zero_shot_llm_3/02_data/00_training_logs/1_log_dir/1_ppo_highway_hf_direct_ideal\"                            # Update directory location 3"],"metadata":{"id":"KsCNlGiAfJC8"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Train PPO with Custom Rewards\n","def train_ppo_with_custom_rewards(log_dir=drive_log_dir, total_timesteps=10000):\n","    os.makedirs(log_dir, exist_ok=True)\n","    env = CustomRewardWrapper(gym.make(\"highway-v0\"))\n","    env = Monitor(env, log_dir)\n","    model = PPO(\"MlpPolicy\", env, verbose=1, tensorboard_log=log_dir)\n","    model.learn(total_timesteps=total_timesteps)\n","    model.save('/content/drive/MyDrive/05_zero_shot_llm_3/02_data/01_trained_models/1_ppo_highway_hf_direct_ideal')                     # Update directory location 4\n","    env.close()\n","    return model, log_dir"],"metadata":{"id":"ZXXdaBvnfI_b"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# log_path = os.path.join(drive_log_dir, \"monitor.csv\")\n","# df = pd.read_csv(log_path, skiprows=1)\n","## Ensure episodes are logged correctly\n","# df.reset_index(inplace=True)\n","# df.rename(columns={\"index\": \"episode\", \"r\": \"reward\", \"l\": \"length\", \"t\": \"time_step\"}, inplace=True)"],"metadata":{"id":"YO8Irua25u4m"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# data_table.enable_dataframe_formatter()\n","# data_table.DataTable(df)"],"metadata":{"id":"4_xpniZv53d3"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Execute Training and Convergence Tracking\n","model, log_dir = train_ppo_with_custom_rewards(total_timesteps=10000)\n"],"metadata":{"id":"BxEO_bghfI59","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1750206070051,"user_tz":-330,"elapsed":5126930,"user":{"displayName":"Saif Nazir","userId":"15029834638479146606"}},"outputId":"dec32e7e-ae87-410e-b768-8c3eac775ee8"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Using cpu device\n","Wrapping the env in a DummyVecEnv.\n","Logging to /content/drive/MyDrive/05_zero_shot_llm_3/02_data/00_training_logs/1_log_dir/1_ppo_highway_hf_direct_ideal/PPO_1\n","---------------------------------\n","| rollout/           |          |\n","|    ep_len_mean     | 12.9     |\n","|    ep_rew_mean     | 10.2     |\n","| time/              |          |\n","|    fps             | 1        |\n","|    iterations      | 1        |\n","|    time_elapsed    | 1036     |\n","|    total_timesteps | 2048     |\n","---------------------------------\n","------------------------------------------\n","| rollout/                |              |\n","|    ep_len_mean          | 17.3         |\n","|    ep_rew_mean          | 16.5         |\n","| time/                   |              |\n","|    fps                  | 1            |\n","|    iterations           | 2            |\n","|    time_elapsed         | 2077         |\n","|    total_timesteps      | 4096         |\n","| train/                  |              |\n","|    approx_kl            | 0.0142727215 |\n","|    clip_fraction        | 0.194        |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -1.6         |\n","|    explained_variance   | 0.0102       |\n","|    learning_rate        | 0.0003       |\n","|    loss                 | 23           |\n","|    n_updates            | 10           |\n","|    policy_gradient_loss | -0.0203      |\n","|    value_loss           | 49.2         |\n","------------------------------------------\n","-----------------------------------------\n","| rollout/                |             |\n","|    ep_len_mean          | 21.7        |\n","|    ep_rew_mean          | 23.5        |\n","| time/                   |             |\n","|    fps                  | 1           |\n","|    iterations           | 3           |\n","|    time_elapsed         | 3087        |\n","|    total_timesteps      | 6144        |\n","| train/                  |             |\n","|    approx_kl            | 0.015654124 |\n","|    clip_fraction        | 0.133       |\n","|    clip_range           | 0.2         |\n","|    entropy_loss         | -1.57       |\n","|    explained_variance   | -0.00308    |\n","|    learning_rate        | 0.0003      |\n","|    loss                 | 44.1        |\n","|    n_updates            | 20          |\n","|    policy_gradient_loss | -0.0155     |\n","|    value_loss           | 96          |\n","-----------------------------------------\n","----------------------------------------\n","| rollout/                |            |\n","|    ep_len_mean          | 26.1       |\n","|    ep_rew_mean          | 30.7       |\n","| time/                   |            |\n","|    fps                  | 1          |\n","|    iterations           | 4          |\n","|    time_elapsed         | 4108       |\n","|    total_timesteps      | 8192       |\n","| train/                  |            |\n","|    approx_kl            | 0.01486641 |\n","|    clip_fraction        | 0.13       |\n","|    clip_range           | 0.2        |\n","|    entropy_loss         | -1.51      |\n","|    explained_variance   | 0.014      |\n","|    learning_rate        | 0.0003     |\n","|    loss                 | 44.6       |\n","|    n_updates            | 30         |\n","|    policy_gradient_loss | -0.0153    |\n","|    value_loss           | 120        |\n","----------------------------------------\n","-----------------------------------------\n","| rollout/                |             |\n","|    ep_len_mean          | 27.2        |\n","|    ep_rew_mean          | 34          |\n","| time/                   |             |\n","|    fps                  | 2           |\n","|    iterations           | 5           |\n","|    time_elapsed         | 5116        |\n","|    total_timesteps      | 10240       |\n","| train/                  |             |\n","|    approx_kl            | 0.013577908 |\n","|    clip_fraction        | 0.065       |\n","|    clip_range           | 0.2         |\n","|    entropy_loss         | -1.44       |\n","|    explained_variance   | 0.035       |\n","|    learning_rate        | 0.0003      |\n","|    loss                 | 68.3        |\n","|    n_updates            | 40          |\n","|    policy_gradient_loss | -0.00996    |\n","|    value_loss           | 165         |\n","-----------------------------------------\n"]}]}]}